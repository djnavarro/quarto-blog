---
title: "How to build an Arrow Flight server"
description: "The waitress thing makes sense, honest"
date: "2022-09-23"
categories: [Apache Arrow, Networking, R, Python]
image: "img/hennie-stander-aWwFbn0ZW6A-unsplash.jpg"
---

<!-- 
rendering from terminal:
  cd ~/GitHub/sites/quarto-blog/posts/2022-09-23_flight
  
-->

<!-- 
cover image: https://unsplash.com/photos/aWwFbn0ZW6A
credit: Hennie Stander
licence: open via unsplash licence
-->

<!--------------- my typical setup ----------------->

```{r setup, include=FALSE}
long_slug <- "2022-08-23_visualising-a-billion-rows"
#renv::use(lockfile = "renv.lock")
```

<!--------------- post begins here ----------------->


## The what and why of Arrow Flight


Let's start with a little background. If I want you to read through a whole post on Arrow Flight, I'd better explain why it's is worth your while. What exactly *is* Arrow Flight -- henceforth just "flight" -- and what is it *for*? Why might you as a data scientist or data engineer care about flight?

The central idea behind flight is deceptively simple: it provides a standard protocol for transferring Arrow data over a network. But to understand why this is a Big Deal, you need to have a good sense of what the Arrow ecosystem is all about. For that, I found it helpful to go all the way back^[All the way back to October 2019, which is like ancient history by Arrow standards. Sigh. This project moves too damned fast to keep pace with it all.] to the [original announcement of flight by Wes McKinney](https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/). Here's how he explained the motivation: 

> Our design goal for Flight is to create a new protocol for data services that uses the Arrow columnar format as both the over-the-wire data representation as well as the public API presented to developers. In doing so, we reduce or remove the serialization costs associated with data transport and increase the overall efficiency of distributed data systems. Additionally, two systems that are already using Apache Arrow for other purposes can communicate data to each other with extreme efficiency.

To put this in context, it helps to have a little recap of how the project has grown: Arrow was originally introduced to provide an efficient and language-agnostic [standard for representing tabular data in-memory](https://arrow.apache.org/docs/format/Columnar.html), but as the project has grown it has necessarily expanded in scope. For example, storing data in-memory is not entirely useful if you can't manipulate it, so Arrow now supplies a powerful [compute engine](https://arrow.apache.org/docs/cpp/compute.html) that underpins both the [arrow package in R](https://arrow.apache.org/docs/r/index.html) and the [pyarrow library in Python](https://arrow.apache.org/docs/python/index.html), and several others besides. In other words, the compute engine has been developed to solve a practical data science problem. 

Arrow Flight evolved from a similar practical concern. It's pretty trivial to point out that we live in a networked world now, and as consequence it is hard to avoid situations where the data to be analysed are stored on a different machine than the one that does the analysis. In my earlier posts on [reticulate](https://blog.djnavarro.net/posts/2022-09-09_reticulated-arrow/) and [rpy2](https://blog.djnavarro.net/posts/2022-09-16_arrow-and-rpy2/) I talked about how to efficiently share an Arrow data set between *languages*, but I implicitly assumed in those posts that the R process and the Python process were running on the same *machine*. The moment we have processes running on different machines, those tricks don't work anymore! 

Flight is designed to solve this problem. It's not a fancypants protocol with lots of different parts. It exists for one purpose: it makes it super easy to transfer Arrow-formatted data. That's it. It's pretty flexible though, and you can build other stuff on top of flight (more on that later), but the design of flight is deliberately simple. It's *meant* to be pretty minimal, so you can "just use it" without having to think too hard or do any of the obnoxious implementation work yourself. 

<br>

### Prerequisites

There are a couple of prerequisites for this post. Specifically I'll assume you have the arrow and reticulate packages installed in your R environment, and similarly that your Python environment has pyarrow installed. If you're only interested in the Python side, you probably don't need either of the R packages, but R users do need the pyarrow installation because the R flight implementation builds on pyarrow.


<br>

## An R example

The implementation of Arrow Flight varies a little across languages. In this post I'm going to focus on the two languages I use most -- R and Python -- but there's nothing stopping you from using other languages. For example, the book [In-Memory Analytics with Apache Arrow](https://www.packtpub.com/product/in-memory-analytics-with-apache-arrow/9781801071031) by [Matt Topol](https://twitter.com/zeroshade) has worked examples using C++ and Go, in addition to Python. 

For the purposes of this post I'm going to start with R because the arrow package in R exposes a "high-level" interface that will allow us to start using a flight server without having to dive deeply into how it all works. However, as we'll see, there are some limitations to this approach -- not least of which is the fact that the R implementation turns out to secretly be a Python implementation under the hood -- and as the post progresses I'll pivot to Python in order to unpack some of the lower-level functionality. 

To do this I'll need access to the arrow and reticulate packages, and I'll need to make certain that the Python environment is one that has pyarrow installed. For my machine, the commands to do this look like this:

```{r, message=FALSE}
library(arrow)
library(reticulate)
use_miniconda("base")
```

It may be a little different for you depending on your configuration. For more information on this, take a look at the [reticulate post](https://blog.djnavarro.net/posts/2022-09-09_reticulated-arrow/) I wrote recently.

<br>

### Starting the demo server

Okay, so let's get started by thinking about the simplest possible scenario for using a flight server. In this set up all we want the server to do is to act as a "cache" for Arrow tables. Clients can upload tables to the server, download tables from the server, and so on. That's all we're really trying to accomplish, and happily for us this use case is supported out of the box in R. 

Here's how it works. As I mentioned earlier, R doesn't actually implement the flight protocol itself: it's just a wrapper around the Python tools. What that means is the underlying flight server is actually written in Python, and if we want to start that server running from R we have to call the `load_flight_server()` function that will allow us access to this server from R. Conveniently, the arrow R package comes bundled with a "demo" server that already provides the server side functionality that we want, and I can import it like this:

```{r, filename = "[R code]", eval=FALSE}
server_class <- load_flight_server("demo_flight_server")
```

When I do this, all I've done is obtain access to the relevant Python code. I haven't created a server yet and I haven't started it running either. Create an instance of the "demo server", I call the `DemoFlightServer()` method attached to the `server_class()` object:

```{r, filename = "[R code]", eval=FALSE}
server <- server_class_object$DemoFlightServer(port = 8089)
```

We have now defined a server that, once started, will run on port 8089. The `server` object has a `serve()` method that I can call to start it running:

```{r, filename = "[R code]", eval=FALSE}
server$serve()
```

I've written a short script called [start_demo_server.R](./start_demo_server.R) that bundles all these operations together, and the easiest way to start a server running in its very own R process (i.e., an R session that isn't the one you're currently working in) would be to type this at the terminal:

```{bash, filename="[terminal]", eval=FALSE}
Rscript start_demo_server.R &
```

This will start an R process as a background job that will create a server and start it running. As an alternative, if you're comfortable with using the [callr](https://callr.r-lib.org/) package, you can use `callr::r_bg()` to create a child R process from your current one. The child process will run in the background, and  we can start start the server within that R session without blocking the current one. Here's some code that will do exactly that:

```{r, filename="[R code]", eval=FALSE}
r_process <- callr::r_bg(function() {
  reticulate::use_miniconda("base")  
  demo <- arrow::load_flight_server("demo_flight_server")
  server <- demo$DemoFlightServer(port = 8089)
  server$serve()
})
```

Regardless of what method you've chosen, I'll now assume that the demo server is now running in the background on port 8089.

<br>

### Connecting with a client

Now that I have this server running quietly in the background on port 8089, I can define a flight client in my current R session that can interact with it. To do that, I call  `flight_connect()`:

```{r, filename="[R console]"}
client <- flight_connect(port = 8089)
```

Perhaps unsurprisingly, the R object `client` is a wrapper around a Python flight client. It comes with various methods that implement low-level flight operations, but I'm going to hold off talking about those for a moment because we won't need to use the low-level interface in this initial example.

Let's start by using the client to as ask a simple question: what is stored on the server? The way that data source are conceptualised in Arrow flight is as a set of "flights". Each individual "flight" corresponds to a data stream from which the client can download data. The precise implementation of this idea (e.g., what data structures are stored in a single flight) varies from server to server, but in both examples in this post each flight stores a single Arrow table. 

In any case, to find out what flights are currently available on our server, we can call the `list_flights()` function:

```{r, filename="[R console]"}
list_flights(client)
```

Hm, okay, there's nothing there. That makes sense because I haven't actually uploaded anything to the server yet! Okay, well, let's suppose I want to store a copy of the `airquality` data as an Arrow table on my server. As R users are probably aware, this is a data set that comes bundled with R, but just so we're all on the same page here's the first few rows of the data set:

```{r, filename="[R code]"}
head(airquality)
```

This object is a regular data frame in R, not an Arrow table, and strictly speaking what we want our client to do is send an Arrow table version of this data set to the server. Happily for us, the `flight_put()` function supplied by the arrow package will take care of the conversion for us, and we can cache a copy of the data as an Arrow table on the server in one line of code: 

```{r, filename="[R console]"}
flight_put(client, data = airquality, path = "pollution_data")
```

In this code, the `flight_put()` function uses the `client` object to communicate with the server, it uses the `data` argument to find the local copy of the data set, and the `path` argument is used to provide a name for the data set on the server (i.e., on the server this data set will be called `pollution_data`). Now that we've done the upload, if we try calling `list_flights()` again we get this as the result:

```{r, filename="[R console]"}
list_flights(client)
```

Yay! 

Now, just to prove to you that I'm not cheating, let's check to make sure that there is no object called `pollution_data` stored locally within my R session:^[One of my favourite things about having a quarto blog is that every post is a notebook. It's technically possible to "cheat" by including hidden code chunks that execute different code than that shown in the post, but it's something I do very sparingly and only when there's some weirdness involved. I'm not doing that here. When this post is rendered, it does start a new instance of the demo server in a different R session: every flight server demonstrated here is in fact running in the background so that the post renders, and server side data are all stored by those other processes. There really is no copy of the `pollution_data` object in the R session used to render this post. It's somewhere else, as it bloody well should be.]

```{r, filename="[R console]", error=TRUE}
pollution_data
```

Clearly there is no object called `pollution_data` available in my current R session. That data set is stored only on the server. To get access to the data cached on the server, I use the `flight_get()` function:

```{r, filename="[R console]", message=FALSE}
flight_get(client, "pollution_data")
```

What has just happened is our client contacted the server and downloaded a copy of the Arrow table stored remotely. It works! 

At the very least we have proof-of-concept that we can start a flight server and use it to upload and download data. But there's a lot that hasn't really been explained properly here. The time has come to start digging a little deeper, so we can really get a sense of what's going on under the hood and how this simple example can be extended.

<br>

## Unpacking the data exchange process

One thing that I like about the flight functionality exposed through `flight_connect()`, `flight_put()`, `flight_get()`, etc is that it operates at a high level of abstraction. In my day-to-day data analysis work I really don't want to spend my time thinking about low-level operations. When I tell R to "put" a data set onto the server I *want* it to happen with one line of code. This high level API is super useful to me on an everyday basis, but it also masks some of the details about how flight works. To give you a sense of what's being hidden, we can take a closer look at the `client` object. Here's a list of some of the methods that are available through the object itself:

``` r
client$do_put()
client$do_get()
client$do_action()
client$list_action()
client$list_flights()
client$get_flight_info()
```

Each of these methods describes a low level operation available to the flight client, and because the R implementation is built on top of the Python version, these are all Python methods that are available in R thanks to the magic of [reticulate](https://rstudio.github.io/reticulate/). What we're seeing exposed here are the actual Arrow flight methods, and it's helpful to unpack things a little so we can see how these methods are related to the functions I've been calling in R. 

As you might expect, the `do_put()` method for the client is very closely related to the `flight_put()` function that I called earlier! However, they aren't the same. The `do_put()` method doesn't actually upload any data, it merely opens a connection to the server, which we can then use to stream data from the client to the server. If you were calling the `do_put()` method directly, you would need to take care of that yourself. But it's tiresome to write that code over and over, so the  `flight_put()` function provides a convenient high-level wrapper that abstracts over all that. 

If you're the analyst working with the data, this is fabulous. But if you're looking to implement your very own flight server, you probably need to understand what these low level operations are. So that's where we're headed next...

<br>

### Unpacking flight_put()

Let's start by taking a look at what happens when we call the R function `flight_put()`. Our goal is to transmit the data to the server, and there's an Arrow Flight method called `do_put()` that can do this for us. However, the structure of the interaction is a little more complicated than simply calling `do_put()`. It's a multi-step operation that unfolds as shown below:

![](img/do_put.png)

The first step in the process occurs when the client calls `do_put()`, a flight method that takes two arguments: a **flight descriptor** object that is used to identify the specific data stream that the client wants to be sent -- and later on I'll talk what the descriptor actually looks like -- and the [schema](https://arrow.apache.org/docs/r/reference/Schema.html) for the flight data.^[Optionally, you can also pass a third "options" argument.] Setting aside the particulars of the syntax -- which might be different in every language -- here's what the `do_put()` fuction call looks like on the client side:

``` python
do_put(descriptor, schema)
```

Passing the schema on the client side serves a particular purpose: it allows the client to create **stream writer** and **stream reader** objects that are returned to the client-side user, and are also passed along to the server. The writer object is the thing that will take care of streaming data to the server, and the reader object is responsible for reading any metadata response that the server happens to send.^[The examples in this post are simple ones where the server doesn't actually send a response, so the reader object isn't used for anything]

Now let's have a look at the server side, where the `do_put()` method expects three inputs: the flight descriptor, the writer, and the reader. So here's the signature on the server side: 

``` python
do_put(descriptor, reader, writer)
```

As long as these methods are written appropriately for both the client and the server, we now have a situation where both machines agree on the description of the data and have objects that can take care of the streaming process.

We now move to step two in the communication, in which the client streams the data to the server. Once the data arrive on the server side, the `do_put()` method for the server stores the data along with an appropriate descriptor, so that it can be found later. Optionally, this is followed by a third stage in which the server sends a response containing metadata to the client. In the example server I'll build in the next section, I won't bother with that step! 

<br>

### Unpacking flight_get()

Next let's look at `flight_get()`. When I called this function earlier, it triggered two separate interactions between the client and server. First, the client calls the `get_flight_info()` method, and the server responds with some information about the data source that includes -- among other things -- a **ticket**. Again, the ticket is a particular data structure that I'll talk more about later, but for now it's enough to note that it's a token that uniquely specifies which flight is requested. 

Once in possession of this ticket, the client can call `do_get()` to request that the server send the data that matches the ticket, which the server then streams. So the whole exchange looks like this:

![](img/do_get.png)

So, in the previous example when I called `flight_get()`, the process looked like this. On the client side, we used the `"pollution_data"` path to construct a descriptor object and the client used `get_flight_info()` to request that information about this "flight" from the server:

``` python
get_flight_info(descriptor)
```

On the server side, once the descriptor is received, a **flight info** object is constructed. The flight info object is comprised of five parts: 

- The schema for the data stored by the flight, 
- The flight descriptor object
- A list of one or more endpoints that specify where the data are available for streaming. Each end point includes a location from which to stream, and the associated ticket for that location
- The total number of records (i.e. rows) stored 
- The total number of bytes to be streamed (i.e., the size of the data)

This flight info is then returned to the client. 

It may seem like this arrangement is overly elaborate: why does the client need this much information if only the ticket is needed to request the data? To be honest, for the simple server-client examples I've used in this post, this level of complexity is not really needed. However, it's extremely useful that it's structured like this when we want to start adopting a more sophisticated setup. One thing it allows, for example, is an arrangement where both the server and client can be distributed across multiple machines, with different endpoints streaming different subsets of the data. Matt Topol discusses some examples where this architecture is employed in [In-Memory Analytics with Apache Arrow](https://www.packtpub.com/product/in-memory-analytics-with-apache-arrow/9781801071031).

Once this flight information has been received by the client, we can extract the ticket from the relevant endpoint (there will be only one endpoint in the server I build in the next section). The client now calls:

``` r
do_get(ticket)
```

The server then sends a **stream reader** object that the client can use to receive the stream of data from the server. 

<br>

## A Python example

Now that we have a basic understanding of what is happening at a lower level, we can build a flight server of our very own. To do this I'll switch over to Python. R doesn't currently have a direct implementation of flight, and relies on Python. Given this, it's easiest to switch completely to Python for the rest of this post.

<br> 

### A tiny flight server

```{r, include=FALSE, cache=FALSE}
knitr::read_chunk("tiny_flight.py")
```

Our goal in this section is to write our own flight server in Python that does the same job as the one we saw earlier in the R example: it's a server that allows you to cache copies of Arrow tables. To do so, we'll start our Python script the way one usually does, with some imports:

```{python imports, filename="tiny_flight.py", eval = FALSE}
```

What I'll do now is define a Python class called `TinyServer`. The job of this class is to provide server side flight methods for `do_get()`, `do_put()`, and others. We'll be able to use this class to create specific server instances and set them running, in more or less the exact same fashion that we did previously in the R example. 

I'll explain the code in more detail in a moment after I've shown you both the server and the client, but let's start just by looking at the code. You can find all the code in the [tiny_flight.py](tiny_flight.py) script that accompanies this post. Here's the complete code used to define the `TinyServer` class:

```{python tiny-server, filename = "tiny_flight.py", eval = FALSE}
```

Hopefully some of this makes sense already, but it will become a little clearer in a moment. In order to do that, it's helpful to see what the code for the client looks like:

<br>

### A tiny flight client

To accompany a `TinyServer`, we'll need a `TinyClient` that knows how to talk to it. With that in mind, here's the entire source code used to define the `TinyClient` class:

```{python tiny-client, filename="tiny_flight.py", eval = FALSE}
```

These two classes are designed to work in concert: the `do_put()` method for `TinyServer` is aligned with the `do_put()` method for `TinyClient`, and so on. That's the reason I started by showing you all the source code for both parts before explaining any of the specific methods -- now that we've seen the code, we can examine `TinyServer.do_put()` and `TinyClient.do_put()` together

<br>

### Our flight methods

Blah blah


<br> 

### Using our server

Conveniently, the [tiny_flight.py](tiny_flight.py) script is bundled with this post, so I can import it as a module:

```{python, filename="[Python commands]"}
import threading
import tiny_flight as tiny

server = tiny.TinyServer(port = 9001)
thread = threading.Thread(target=lambda: server.serve(), daemon=True)
thread.start()
```



Now let's start our client...


```{python, filename="[Python commands]"}
client = tiny.TinyClient(port = 9001)
```

Let's create some tables on the client side and cache them on the server:

```{python, filename="[Python commands]"}
import pyarrow
mario = pyarrow.table([["Mario", "Luigi", "Peach"]], names=["Character"])
riots = pyarrow.table([["Stonewall", "Comptons", "Mardi Gras"]], names=["Riot"])

client.put_table("mario", mario)
client.put_table("riots", riots)
```

Now let's ask the server to tell us what it's storing:

```{python, filename="Python commands]"}
client.list_tables()
```

Wait, we don't want the mario table anymore:

```{python, filename="Python commands]"}
client.drop_table("mario")
client.list_tables()
```

<br>

## Further down the rabbit hole

A little bit of detail about RPC vs REST, about gRPC and protobuf. Not a lot is needed here, just enough to understand what flight is built on top of...

<br>

## Where to next?

Compared to the rest of the Apache Arrow project, it's not so easy to find tutorials and documentation about flight. It's still a little piecemeal. With that in mind, here's an annotated reading list that will be helpful if you want to explore flight further:

- [The original announcement of flight](https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/) by Wes McKinney on the Apache Arrow blog gives a very good overview of the motivation for why flight was introduced. 
- [Data transfer at the speed of flight](https://voltrondata.com/news/data-transfer-at-the-speed-of-flight/) by Tom Drabas, Fernanda Foertter, and David Li. This is a blog post on the Voltron Data blog that provides a concrete example of a working flight server written in Python. The Python code I've discussed in this post is an elaboration of the content in that post. It's a good starting point
- [Apache Arrow Flight: A Primer](https://voltrondata.com/news/apache-arrow-flight-primer/) by David Li and Tom Drabas. This is another blog post on the Voltron Data website. This one doesn't have any working code for you to look at, but it provides a good summary of the technologies that Arrow Flight is built upon. It's a little intense for novices but is pretty handy for intermediate level users who want to take a peek under the hood. 
- [The Python documentation flight vignette](https://arrow.apache.org/docs/python/flight.html) is pretty readable and goes into a moderate amount of detail, but be aware it implicitly assumes some familiarity with remote procedure calls.
- [The Python cookbook for Arrow](https://arrow.apache.org/cookbook/py/flight.html) contains the most thorough worked example I've seen anywhere. It's a little dense for novice users, but it's still the one of the most comprehensive resources I've seen, and the only one that talks about issues like authentication (which I have not discussed at all here!) 
- [The R documentation flight vignette](https://arrow.apache.org/docs/r/articles/flight.html) has a succinct overview of how you can use the high-level interface provided by `flight_put()`, `flight_get()`, etc. What it doesn't do (yet?) is discuss the low-level features. At the moment you won't find a discussion of say `client$do_get()` and how it relates to `flight_get()`.
- Along similar lines there are some examples in the [R cookbook](https://arrow.apache.org/cookbook/r/flight.html), but they are also quite minimal.
- It's not publicly accessible without purchase, but if you're willing to spend some money I thoroughly recommend the chapter on Arrow flight in Matt Topol's book [In-Memory Analytics with Apache Arrow](https://www.packtpub.com/product/in-memory-analytics-with-apache-arrow/9781801071031). I found it really helpful for cementing my own understanding. In addition to the worked examples in  Python, C++, and Go, the chapter provides some historical context for understanding the difference between RPC frameworks and REST frameworks, and is also the only resource I'm aware of that goes into detail about how more sophisticated network architectures are supported by flight.

Additionally, when digging around in source code, I found it handy to take a look at these parts of the code base:

- [Source code for the R demo server](https://github.com/apache/arrow/blob/master/r/inst/demo_flight_server.py)
- [A Python example server](https://github.com/apache/arrow/blob/master/python/examples/flight/server.py)
- [Source code for the pyarrow flight implementation](https://github.com/apache/arrow/blob/master/python/pyarrow/_flight.pyx)

Finally, while neither one is ideal as a place to start, once I started getting the hang of what I was doing, I have found it handy to browse through the [Python flight API reference pages](https://arrow.apache.org/docs/python/api/flight.html), and to occasionally dip into the official [Arrow flight RPC specification](https://arrow.apache.org/docs/format/Flight.html). Regarding the latter, my experience was that the images showing how each of the flight methods operates were handy, and the [comments](https://arrow.apache.org/docs/format/Flight.html#protocol-buffer-definitions) shown in the in the "protocol buffer definitions" are nice because they're maybe the clearest verbal description of what each of the flight methods expects as input and what objects they will return.

Happy hunting! 




```{r, echo=FALSE, results='hide'}
client$do_action("shutdown")
```


<!--------------- appendices go here ----------------->


