---
title: "Passing Arrow data between R and Python with reticulate"
description: "In a multi-language 'polyglot' data science world, it becomes important that we are able to pass large data sets efficiently from one language to another without making unnecessary copies of the data. This post is the story of how I learned to love using reticulate to pass data between R and Python, especially when used together with Apache Arrow which prevents wasteful copying when the handover takes place"
date: "2022-09-09"
categories: [Apache Arrow, R, Python]
image: "img/cover.jpg"
engine: knitr
---

<!-- 
cover img: https://unsplash.com/photos/yrcaXCWe0VY
artist: David Clode
licence: unsplash free-to-use 
-->

<!--------------- my typical setup ----------------->

```{r setup, include=FALSE}
long_slug <- "2022-09-09_reticulated-arrow"
#renv::use(lockfile = "renv.lock")

# save the built-in output hook
hook_output <- knitr::knit_hooks$get("output")

# set a new output hook to truncate text output
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
      # truncate the output
      x <- c(head(x, n), "...\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})
```

As the 21st century gears up for its quarter-life crisis, the trend in data science is toward multi-language tools. I use [quarto](https://quarto.org/) to write this blog, a document preparation system that supports code evaluation in R, Python, Julia, and more. My work revolves around [Apache Arrow](https://arrow.apache.org/), a toolbox for data analysis and interchange with implementations in multiple languages. You get the idea. In one sense this new development is fantastic -- your language of choice is much more likely to be supported in the future than it ever was in the past. In another sense it is daunting -- it sometimes feels like we need to learn *all the things* in order to get by in this brave new world. Meanwhile we all have our actual jobs to do and we don't have the time. In the [immortal words of Bob Katter](https://www.youtube.com/watch?v=1i739SyCu9I),

> I mean, you know, people are entitled to their sexual proclivities. Let there be a thousand blossoms bloom as far as I'm concerned, you know... 
>
> &nbsp; &nbsp; &nbsp; [*pauses, expression turns dark*]
>
> ...but I ain't spending any time on it because, in the meantime, every three months a person is torn to pieces by a crocodile in North Queensland

I mean, he makes a good point?^[A good point about data science, that is. I'm not convinced it was a stellar contribution to the discussion of LGBT rights in the antipodes. Although frankly it wasn't the worst comment on same sex marriage I saw an Australian politician make at the time, not by a loooooong margin.] There's a lot going on in the data science world, none of us can keep pace with all of it, and we're all trying our best not to be eaten by crocodiles. 

```{r packages, filename="[R code]", message=FALSE}
library(tidyverse)
library(tictoc)
```

<br><br>

:::{.column-body-outset}
![A reticulated python. Not -- strictly speaking or even informally speaking -- a crocodile. My sincerest apologies to Bob Katter, but this post is not in fact about crocodile-related deaths in northern Queensland. [Original image](https://unsplash.com/photos/yrcaXCWe0VY) freely available courtesy of David Clode via Unsplash.](img/david-clode-yrcaXCWe0VY-unsplash.jpg)
:::

<br><br>  

## Data interchange in a polyglot world

In the spirit of saving you from at least one reptilian threat, this post is a primer on how to efficiently pass control of a large data set between R and Python *without* making any wasteful copies of the data.

The idea to write this post emerged from a recent discussion on Twitter started by [Cass Wilkinson SaldaÃ±a](https://twitter.com/mxcatnap/status/1559991199494279169) about passing control of a data set from R to Python, and a comment in that discussion by [Jon Keane](https://twitter.com/jonkeane/status/1560016227824721920) mentioning that with the assistance of Apache Arrow this handover can be made very smooth, and incredibly efficient too. Unfortunately, to be able to do this you need to know the trick, and as they regretfully mentioned in the thread, the trick isn't well documented yet. 

In time the documentation will of course improve, but in the here and now it seems like a good idea to explain how the magic trick works...

<br><br>  

### The reticulate trick

The "trick" is simple: if your data are stored as an Arrow Table, and you use the [reticulate](https://rstudio.github.io/reticulate/) package to pass it from R to Python (or vice versa), only the metadata changes hands. Because an Arrow Table has the *same* structure in-memory when accessed from Python as it does in R, the data set itself does not need to be touched at all. The only thing that needs to happen is the language on the receiving end needs to be told *where* the data are stored. Or, to put it another way, we just pass a pointer across. This all happens invisibly, so if you know how to use reticulate,^[Something to note here is that the reticulate solution implicitly assumes R is your "primary" language and Python is the "secondary" language. That is, reticulate is an R package that calls Python, not a Python module that calls R. Simularly, this quarto document uses the [knitr engine](https://quarto.org/docs/computations/r.html) (also an R package) to integrate code from the two languages. Yes the tools are multi-language, but the setup is pretty R-centric. Arguably this is typical for how an R user would set up a multi-language project, and since R is my primary language it's my preferred solution. However, it's not a particularly Pythonic way of approaching the problem. But fear not, Python fans. In the next post I'm going to describe an approach that solves the same problem in a Python-centric way.] you already know almost everything you need to know and can skip straight to the [section on passing Arrow objects](#data-interchange-with-arrow-in-the-polyglot-world). If you're like Danielle-From-Last-Week and have absolutely no idea how reticulate works, read on... 

<br><br>   

### Managing the Python environment from R

If reticulate is not already on your system, you can install it from CRAN with `install.packages("reticulate")`. Once installed, you can load it in the usual fashion:

```{r load-reticulate, filename="[R code]"}
library(reticulate)
```

What happens next depends a little on whether you already have a Python set up. If you don't have a preferred Python configuration on your machine and would like to let reticulate manage everything for you, then you can do something like this:

```{r reticulate-fresh-python, eval=FALSE, filename="[R code]"}
install_python()
install_miniconda()
```

This will set you up with a default Python build, managed by a copy of [Miniconda](https://docs.conda.io/en/latest/miniconda.html) that it installs in an OS-specific location that you can discover by calling `miniconda_path()`. This is a perfectly sensible way to use reticulate, but in the end the approach I took was slightly different. 

If you're like me and already have Python and Miniconda configured, you probably *don't* want reticulate installing new versions on your machine.^[Okay, in the spirit of total honesty when I first started using reticulate I actually did let reticulate install its own version of Miniconda and everything was a total mess there for a while. My bash profile was set to find my original version of Miniconda, but reticulate was configured to look for the version it had installed. Hijinx ensued. As amusing as that little episode was, I'm much happier now that reticulate and bash are in agreement as to where Miniconda lives.] You probably want to use your existing set up and ensure that reticulate knows where to find everything. If that's the case, what you want to do is edit your `.Renviron` file^[The easiest way to edit this file, if you don't already know how, is to call `usethis::edit_r_environ()` at the R console.] and set the RETICULATE_MINICONDA_PATH variable. Add a line like this one,

```{bash set-miniconda-path, filename="[within .Renviron]", eval=FALSE}
RETICULATE_MINICONDA_PATH=/home/danielle/miniconda3/
```

where you should specify the path to your Miniconda installation, not mine ðŸ˜

Regardless of which method you've followed, you can use `conda_list()` to display a summary of all your Python environments^[Well, all the Conda environments anyway]. Somehow, despite the fact that I went to the effort of setting everything up, I haven't used Python much on this machine, so my list of environments is short:

```{r list-conda-env, filename="[R code]", eval=FALSE}
conda_list()
```
```{r list-conda-env-except-reptilia, echo=FALSE}
conda_list() |> dplyr::filter(name != "reptilia")
```

For the purposes of this post I'll create a new environment that -- in honour of Bob Katter and the reptilian terror in the north -- I will call "reptilia". To keep things neat I'll install^[You can also use `conda_install()` to install into an existing conda environment.] the pandas and pyarrow packages that this post will be using at the same time:

```{r create-environment, filename="[R code]", eval=FALSE}
conda_create(
  envname = "reptilia",
  packages = c("pandas", "pyarrow")
)
```

When I list my conda environments I see that the reptilia environment exists,

```{r list-conda-env-new, filename="[R code]"}
conda_list()
```

and I can ensure that reticulate uses that environment when rendering this post by calling the `use_miniconda()` function and specifying the environment name:

```{r, filename="[R code]"}
use_miniconda("reptilia")
```

Our set up is now complete!

<br><br>   


:::{.column-body-outset}
![A boa constrictor, at least according to the image caption. I'll admit my personal skills at identifying snakes are limited. [Original image](https://unsplash.com/photos/p1SKuYXxqec) freely available courtesy of Jan KopÅ™iva via Unsplash.](img/jan-kopriva-p1SKuYXxqec-unsplash.jpg)
:::


<br><br>   

### Using reticulate to call Python from R

Now that my environment is set up I'm ready to use Python. When calling Python code from within R, some code translation is necessary due to the differences in syntax across languages. As a simple example, let's say I have my regular Python session open and I want to check my Python version and executable. To do this I'd import the sys library:

```{python check-version, filename="[python code]"}
#| results: hold
import sys
print(sys.version)
print(sys.executable)
```

To execute these commands from R, the code needs some minor changes. The `import()` function replaces the `import` keyword, and `$` replaces `.` as the accessor: 

```{r import-sys, filename="[R code]"}
#| results: hold
sys <- import("sys")
sys$version
sys$executable
```

The code looks more R-like, but Python is doing the work.^[As an aside it's worth noting that reticulate exports an object called `py`, from which Python objects can be accessed: the `sys` object can also be referred to as `py$sys`.]

<br><br>   

### Copying data frames between languages

Okay, now that we understand the basics of reticulate, it's time to tackle the problem of transferring data sets between R and Python. For now, let's leave Arrow out of this. All we're going to do is take an ordinary R data frame and transfer it to Python. 

First, let's load some data into R. Sticking to the reptilian theme we've got going here, the data are taken from [The Reptile Database](http://www.reptile-database.org/) (accessed August 31 2022), an open and freely available catalog of reptile species and their scientific classifications.^[Note that the website does not explicitly specify a particular licence, but [journal articles documenting the database](https://www.researchgate.net/publication/352462027_A_Quarter_Century_of_Reptile_and_Amphibian_Databases) written by the maintainers do refer to it as "open and freely available". With that in mind I take it that the use of the data in this post is permitted. Naturally, should I discover that it is not I'll immediately remove it!]

```{r read-taxa, filename="[R code]", message=FALSE}
taxa <- read_csv2("taxa.csv")
taxa
```

Currently this object is stored in-memory as an R data frame and we want to move it to Python. However, because Python data structures are different from R data structures, what this actually requires us to do is make a copy of the whole data set inside Python, using a Python-native data structure (in this case a Pandas DataFrame). Thankfully, reticulate does this seamlessly with the `r_to_py()` function:

```{r r-to-panda, filename="[R code]"}
py_taxa <- r_to_py(taxa)
py_taxa
```

Within the Python session, an object called `r` has been created: the Pandas DataFrame object is stored as `r.py_taxa`, and we can manipulate it using Python code in whatever fashion we normally might. 

It helps to see a concrete example. To keep things simple, let's pop over to our Python session and give ourselves a simple data wrangling task. Our goal is to count the number of entries in the data set for each reptilian family using Pandas syntax:

```{python panda-from-r, filename="[python code]"}
counts = r. \
  py_taxa[["family", "taxon_id"]]. \
  groupby("family"). \
  agg(len)
  
counts
```

Naturally I could have done this in R using dplyr functions, but that's not the point of the post. What matters for our purposes is that `counts` is a Pandas DataFrame that now exists in the Python session, which we would like to pull back into our R session. 

This turns out to be easier than I was expecting. The reticulate package exposes an object named `py` to the user, and any objects I created in my Python session can be accessed that way:

```{r back-to-r, filename="[R code]"}
#| out.lines: 10
py$counts
```

What's especially neat is that the data structure has been automatically translated for us: the `counts` object in Python is a Pandas DataFrame, but when accessed from R it is automatically translated into a native R data structure: `py$counts` is a regular data frame:

```{r check-data-frame-class, filename="[R code]"}
class(py$counts)
```


<br><br>

:::{.column-body-outset}
![A chameleon. I suppose there is some logic for this image, at least insofar as reticulate allows R to mimic Python, and while Arrow does a lot of the work in the next section it blends seamlessly into the background. Like a chameleon. Get it? I'm so clever. [Original image](https://unsplash.com/photos/GU2DpW-H89M) freely available courtesy of David Clode via Unsplash.](img/david-clode-GU2DpW-H89M-unsplash.jpg)
:::



<br><br>   

## Data interchange with Arrow in the polyglot world

So far we have not touched Arrow, and you might be wondering if it's even necessary to do so given that reticulate seems so smooth and seamless. Appearances are a little deceiving however. The example from the last section only looks smooth and seamless because the data set is small. As I'll show later in the post, cracks in the facade start to appear when you have to pass large data sets across for the very simply reason that an Pandas DataFrame is a different data structure to an R data frame. It's not possible for the two languages to share a single copy of the same data object because they don't agree on what constitutes a data object. The only way to do the handover is to make a copy of the data set and convert it to a more appropriate format. When the data set is small, this is not a problem. But as your data set grows, it becomes ever more burdensome. These copy-and-convert operations are not cheap. 

Wouldn't it be nice if R and Python could both agree to represent the data as, oh let's say.... an Arrow Table? On the R side we could interact with it using the arrow R package, and on the Python side we could interact with it using the pyarrow module. But regardless of which language we're using, the thing in memory would be *exactly* the same... handing over the data set from one language to the other would no longer require any copying. A little metadata would change hands, and that's all. 

That sounds much nicer. 

<br><br>   

### Setting up arrow

I'm not going to talk much about setting up arrow for R in this post, because I've written about it before! In addition to the [installation instructions on the arrow documentation](https://arrow.apache.org/docs/r/) there's a [getting started with arrow](https://blog.djnavarro.net/posts/2021-11-19_starting-apache-arrow-in-r/) post on this blog. But in any case, it's usually pretty straightfoward: you can install the arrow R package from CRAN in the usual way using `install.packages("arrow")` and then load it in the usual fashion:

```{r load-arrow, filename="[R code]", message=FALSE}
library(arrow)
```

From there we're good to go. Let's start by reading the reptiles data directly from file into an Arrow Table:

```{r read-taxa-arrow, filename="[R code]"}
taxa_arrow <- read_delim_arrow(
  file = "taxa.csv", 
  delim = ";", 
  as_data_frame = FALSE
)
taxa_arrow
```


<br><br>   

### Setting up pyarrow

Okay, what's our next step? Well, in the previous example, the R data frame was handled on the Python side by the Pandas module. And as a consequence, you'd imagine that it was pretty important that my Python environment has Pandas installed right? The same is true when passing an Arrow Table: you need to have pyarrow installed on the Python side as well as arrow installed on the R side. So let's do that.

As a convenience, the arrow package supplies a helper function called `install_pyarrow()` that calls the relevant reticulate functions for you, but for the purposes of this post I'll show you the reticulate functions. The python environment I'm using in this post is managed by miniconda, so I'll use `conda_install()` to do the work: 

```{r, eval=FALSE, filename="[R code]"}
conda_install(
  packages = "pyarrow", 
  envname = "/home/danielle/miniconda3", 
  conda = "/home/danielle/miniconda3/bin/conda"
)
```

In this code, `packages` is the name of the to-be-installed python module, `envname` is the path to the conda environment, and `conda` is the path to the conda executable. As a general rule you don't need to be this explicit: reticulate will find the environment and conda executable for you.

Next let's import pyarrow on the Python side and check the version:^[As an aside -- because I'm on on linux and life on linux is dark and full of terrors -- this didn't actually work for me the first time I tried it, and naturally I was filled with despair. Instead, I received this: `libstdc++.so.6: version 'GLIBCXX_3.4.22' not found`. As usual, googling the error message solved the problem. I updated with `sudo apt-get install libstdc++6`, and another catastrophe was thereby averted by copy/pasting into a search engine ðŸ™ƒ]




```{python check-pyarrow, filename="[python code]"}
import pyarrow
pyarrow.__version__
```


<br><br>   

### Handover to Python

After all that set up, it's almost comically easy to do the transfer itself. It's literally the same as last time: we call `r_to_py()`. The `taxa_arrow` variable refers to an Arrow Table on the R side, so now all I have to do is use `r_to_py()` to create `py_taxa_arrow`, a variable that refers to the same Arrow Table from the Python side:

```{r, filename="[R code]"}
py_taxa_arrow <- r_to_py(taxa_arrow)
```

Since we're in Python now, let's just switch languages and take a peek, shall we? Just like last time, objects created by reticulate are accessible on the Python side via the `r` object, so we access this object in Python with `r.py_taxa_arrow`:

```{python, filename="[python code]"}
r.py_taxa_arrow
```

The output is formatted slightly differently because the Python pyarrow library is now doing the work. You can see from the first line that this is a *pyarrow* Table, but nevertheless when you look at the rest of the output it's pretty clear that this is the same table.

Easy!

<br><br>   

### Handover to R

Right then, what's next? Just like last time, let's do a little bit of data wrangling on the Python side. In the code below I'm using pyarrow to do the same thing I did with Pandas earlier: counting the number of entries for each reptile family.

```{python, filename="[python code]"}
counts_arrow = r.py_taxa_arrow. \
  group_by("family"). \
  aggregate([("taxon_id", "count")]). \
  sort_by([("family", "ascending")])
  
counts_arrow
```

Flipping back to R, the `counts_arrow` object is accessible via the `py` object. Let's take a look:

```{r, filename="[R code]"}
py$counts_arrow
```

The output is formatted a little differently because on this side it is the R arrow package printing the output, but it's the same Table. 

Mission accomplished! 

But... was it all worthwhile?

<br><br>

:::{.column-body-outset}
![A baby crocodile, just so that Bob Katter doesn't feel like I completely forgot about his worries. It doesn't look like it's about to tear anyone to pieces but what would I know? I'm not an expert on such matters. [Original image](https://unsplash.com/photos/0W8PfUdXqhk) freely available courtesy of David Clode via Unsplash.](img/david-clode-0W8PfUdXqhk-unsplash.jpg)
:::



<br><br>   

## Does Arrow really make a big difference?

At the end of all this, you might want to know if using Arrow makes much of a difference. As much as I love learning new things for the sheer joy of learning new things, I prefer to learn useful things when I can! So let's do a little comparison. First, I'll define a `handover_time()` function that takes two arguments. The first argument `n` specifies the number of rows in the to-be-transferred data set. The second argument `arrow` is a logical value: setting `arrow = FALSE` means that an R data frame will be passed to Python as a Panda DataFrame, wheras `arrow = TRUE` means that an Arrow Table in R will be passed to Python and remain an Arrow Table. The actual data set is constructed by randomly sampling `n` rows from the `taxa` data set (with replacement):

```{r define-handover, filename="[R code]"}
handover_time <- function(n, arrow = FALSE) {
  data_in_r <- slice_sample(taxa, n = n, replace = TRUE)
  if(arrow) {
    data_in_r <- arrow_table(data_in_r)
  }
  tic()
  data_in_python <- r_to_py(data_in_r)
  t <- toc(quiet = TRUE)
  return(t$toc - t$tic)
}
```

Now that I've defined the test function, let's see what happens. I'll vary the number of rows from 10000 to 1000000 for both the native data frame version and the Arrow Table version, and store the result as `times`:

```{r speed-test-2, filename="[R code]", cache=TRUE}
times <- tibble(
  n = seq(10000, 1000000, length.out = 100),
  data_frame = map_dbl(n, handover_time),
  arrow_table = map_dbl(n, handover_time, arrow = TRUE),
)
```

Now let's plot the data:

```{r plot-speed, filename="[R code]"}
times |> 
  pivot_longer(
    cols = c("data_frame", "arrow_table"), 
    names_to = "type", 
    values_to = "time"
  ) |> 
  mutate(
    type = type |> 
      factor(
        levels = c("data_frame", "arrow_table"),
        labels = c("Data Frames", "Arrow Tables")
      )
  ) |>
  ggplot(aes(n, time)) + 
  geom_point() + 
  facet_wrap(~type) + 
  theme_bw() + 
  labs(
    x = "Number of Rows",
    y = "Handover Time (Seconds)", 
    title = "How long does it take to pass data from R to Python?"
  )
```

Okay yeah. I'll be the first to admit that this isn't a very sophisticated way to do benchmarking, but when the difference is this stark you really don't have to be sophisticated. Without Arrow, the only way to hand data from R to Python is to copy and convert the data, and that's time consuming. The time cost gets worse the larger your data set becomes. With Arrow, the problem goes away because you're not copying the data at all. The time cost is tiny and it stays tiny even as the data set gets bigger. 

Seems handy to me?

<br><br>   



<!--------------- appendices go here ----------------->

```{r, echo=FALSE}
source("appendix.R")
```



