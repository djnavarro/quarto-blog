---
title: "Shattered landscapes"
author:
  - name: Danielle Navarro
    url: https://djnavarro.net
    affiliation: I'm on smoko
    affiliation-url: https://www.youtube.com/watch?v=j58V2vC9EPc
    orcid: 0000-0001-7648-6578
description: "Using ambient and rayshader to create weird, broken landcape images in R"
date: "2023-02-27"
categories: [Art, R]
---

<!--------------- my typical setup ----------------->

```{r setup, include=FALSE}
long_slug <- "2023-02-27_shattered-landscapes"
wide <- 136
narrow <- 76
options(width = narrow)
cache_images <- TRUE
```

<!--------------- post begins here ----------------->

> Magic doesn't come from talent. It comes from pain. <br>
> &nbsp; &nbsp; -- [Eliot Waugh](https://www.youtube.com/watch?v=WBeLX3O_mEU)^[Also Lev Grossman I guess, but honestly Hale Appleman's delivery is so good that I cannot possibly attribute the quote to anyone except Eliot.]

In the last few weeks I've been tinkering with a generative art system I ended up calling [broken lands](https://art.djnavarro.net/gallery/broken-lands/). It creates maps of bizarre and -- I expect -- impossible landscapes in R, using the [ambient](https://ambient.data-imaginist.com/) package to generate the topography, and [rayshader](https://www.rayshader.com/) to render shadows cast by a hypothetical light source. It creates images like these:

:::{.column-screen-inset}
:::{layout-ncol=3} 

![](https://djnavarro.net/series-broken-lands/3000/alien-floe_15_2406.png)

![](https://djnavarro.net/series-broken-lands/3000/alien-floe_15_2416.png)

![](https://djnavarro.net/series-broken-lands/3000/alien-floe_15_2496.png)

:::
:::

To my eye, at least, these images are both beautiful and tragic. I cannot help but interpret them as coastal landscapes in an alien geography of some kind, a land that has suffered some cataclysm like the [Doom of Valyria](https://awoiaf.westeros.org/index.php/Doom_of_Valyria) or the [Fall of Istar](https://dragonlancenexus.com/the-rise-and-demise-of-istar/). The contours feel too contorted to be the result of any terrestrial process, and -- again, by my interpretation -- there's a tension between the smoothness of the individual contours and the jagged, chaotic structure of the landscape overall. 

But what would I know? I wrote the code that makes the system work, but I don't have a monopoly of interpretation of the images. [Death of the author](https://en.wikipedia.org/wiki/The_Death_of_the_Author) and all that. Barthes would call me the "scriptor" rather than the author, I suppose, which honestly feels about right for generative art. So yeah. The pieces are what they are, quite separate from the artist and from the process by which the system was constructed.

That said, if you're familiar with the R ecosystem you can probably take an educated guess about the tools I used to make these pieces. The spatial noise patterns that form the basis of these pieces are created using the [ambient](https://ambient.data-imaginist.com/) package. The shadows and three-dimensional look are provided by  [rayshader](https://www.rayshader.com/). I wrote about both of these packages in my workshop on [generative art in R](https://art-from-code.netlify.app/) workshop (specifically: [ambient art](https://art-from-code.netlify.app/day-1/session-2/), [rayshader  art](https://art-from-code.netlify.app/day-1/session-4/)), and those tutorials are probably the place to begin if you've never used either of these packages for generative art before.

Let's set a random seed that we'll use for all the random components throughout the post:^[Why 14? No reason. I got to the end of the post after tinkering with lots of things and with lots of seeds, was happy with what I'd coded, and then asked my daughter to give me a random number that I could use for this post, because I didn't want it to seem like I'd engaged in "seed hacking" to make it look pretty.] ^[There's an obvious parallel between seed hacking in generative art and p-hacking in statistics, but I refuse to go down that path. I've had so many tediously overconfident men in oPeN sCIenCe lecture me at length on p-hacking, and berating me for my quEStionAbLe reSeArcH PRaCtiCe when I've suggested that in real world inference there are cases where statistics should not adhere strictly to the rules laid down by Jerzy Neyman that... well, quite frankly, at this point in my life I loathe the whole concept of $p$ and everyone who talks about it.] ^[Yes, *men*. Without fail, the people berating me for daring to know something about the limits of classical null hypothesis tests have been men. I'll let you know if that changes, but in my life experience to date, mansplaining seems to be an extremely gendered phenomenon.] 

```{r seed}
seed <- 14
```


<br>

## Starting simple

I'll start by building a simple system that doesn't go very far beyond what I covered in the *Art From Code* workshop. It's built using three functions. There's a `new_grid()` function used to define a grid of x and y coordinates, a `generate_simplex()` function used to create spatial noise patterns on such a grid, and a `render()` function used to create an image. First, the `new_grid()` function:

```{r, echo=FALSE}
library(tibble)
```

```{r new-grid}
new_grid <- function(n = 1000) {
  ambient::long_grid(
    x = seq(0, 1, length.out = n),
    y = seq(0, 1, length.out = n)
  )
}

new_grid()
```

The output appears to be a tibble that contains x and y coordinates.^[It's actually a slightly different kind of object called a "long grid" but for now I'll treat it like a tibble] This defines the spatial locations that we'll use to create the image, but we'll need to assign colours to each of those locations. 

<br>

### Painting a canvas with spatial noise

In order to do this, we'll write a function called `generate_simplex()` that generates interesting patterns of spatial noise:

```{r generate-simplex}
generate_simplex <- function(x, y, seed = NULL) {
  if(!is.null(seed)) {
    set.seed(seed)
  }
  ambient::fracture(
    noise = ambient::gen_simplex,
    fractal = ambient::billow,
    octaves = 10,
    freq_init = .02,
    frequency = ~ . * 2,
    gain_init = 1,
    gain = ~ . * .8,
    x = x,
    y = y
  )
}
```

The particular choices I've made here came about from trial and error. I played around with a lot of different settings when creating generative art in this style, and these were things I liked. I'm not going to dive into the details here: you can find out more by reading the [tutorial on spatial noise art]([ambient art](https://art-from-code.netlify.app/day-1/session-2/)) I linked to earlier. For the current post, all I want to highlight is that we can use this function to add a new column to the `canvas` that defines our artwork:

```{r show-canvas}
canvas <- new_grid() |> 
  dplyr::mutate(paint = generate_simplex(x, y, seed = seed))

canvas
```

This `canvas` object is structured like a lookup table: it's a data frame with columns specifying x and y coordinates, and it contains a third column that specifies the colour of "paint" that needs to be applied at each coordinate. However, it's a very structured data frame because the x and y values form a grid. This^[Or, more precisely, the fact that we created this object by calling `ambient::long_grid()` rather than `tidyr::expand_grid()` or the `expand.grid()` function in base R.] makes straightforward to flip from this format to a "bitmap" matrix format:^[I'd ordinarily refer to this as a raster format but it's not strictly a raster object in the R sense.]

```{r show-bitmap}
bitmap <- canvas |> as.array(value = paint)
bitmap[1:6, 1:6]
```

A grid of numbers isn't very pretty to look at, but we will need to create this matrix representation before passing the data to rayshader later. But I'm getting ahead of myself. For now, we can use the `image()` function to render an image from matrix-formatted data:

```{r echo=FALSE}
par(mar = c(0, 0, 0, 0))
```

```{r simple-render, cache=cache_images}
#| fig-width: 6
#| fig-height: 6
canvas |> 
  as.array(value = paint) |>
  image(axes = FALSE, asp = 1, useRaster = TRUE)
```

We're a long way from our goal, but at least we now have an output that looks like art rather than a matrix of numbers. It's a start!

<br>

### Casting shadows across the landscape

The next step in the process is to define a `render()` function that will take an "elevation" matrix as input, but instead of drawing a "heat map" like `image()` does, it renders it as a three-dimensional topographic map with shadows cast by a hypothetical light source. This is surprisingly easy to do using rayshader. Here's the function I'll use in this post:

```{r render}
render <- function(mat, shades = NULL, zscale = .005) {
  if(is.null(shades)) {
    n <- length(unique(mat))
    shades <- hcl.colors(n, "YlOrRd", rev = TRUE)
  }
  rayshader::height_shade(
    heightmap = mat,
    texture = shades
  ) |>
    rayshader::add_shadow(
      shadowmap = rayshader::ray_shade(
        heightmap = mat,
        sunaltitude = 50,
        sunangle = 80,
        multicore = TRUE,
        zscale = zscale
      ),
      max_darken = .2
    ) |>
    rayshader::plot_map()
}
```

I'm not going to go into the specifics: you can find out more by reading the [tutorial on rayshader art]([ambient art](https://art-from-code.netlify.app/day-1/session-4/)) I linked to earlier. For this post, I'm simply going to show you what it does. Taking the `canvas` data as input, we first use `as.array()` to switch from a "data frame style" representation to a "matrix style" representation, and then pass the matrix to `render()`:

```{r render-landscape, cache=cache_images}
canvas |>
  as.array(value = paint) |>
  render()
```

Again, still a long way from our desired goal, but we are making progress. Thanks to rayshader, we have output that looks like a shaded topographic map.

<br>

### Making islands from the landscape

<!--
> I cut my bangs with some rusty kitchen scissors <br>
I screamed his name 'til the neighbors called the cops <br>
I numbed the pain at the expense of my liver <br>
Don't know what I did next, all I know I couldn't stop <br>
&nbsp; &nbsp; -- Miranda Lambert
-->

At this point we have the ability to generate landscapes, but the images just look like a bunch of hills. They don't have the "coastal" feeling that the original images did. We can create islands by setting a "sea level". You can do this in a sophisticated way in rayshader using `detect_water()` and `add_water()`, but that's overkill for our purposes. All we really want to do is imagine setting a sea level such that about half the image is "water" and half the image is "land". To do that we just calculate the median value in the original data: 

```{r sealevel}
sea_level <- median(canvas$paint)
```

From there it's an exercise in using dplyr. Using `mutate()` we create a new "islands" column whose value is equal to the original value or the sea level, whichever is higher:

```{r render-islands, cache=cache_images}
canvas |> 
  dplyr::mutate(
    islands = dplyr::if_else(
      condition = paint < sea_level,
      true = sea_level, 
      false = paint
    )
  ) |>
  as.array(value = islands) |>
  render()
```

Et voilà! We have a generative art system that creates fictitious topographic maps of coastal islands. It's still not quite the same thing as the original, but it's kind of a nice system in itself. If you want to play with it, the complete source code for generating this image is included in the [islands.R](islands.R) script accompanying this post.

<br>

### Tweaking the spatial noise generator

If you do end up playing around, a really useful way to create variations on this system is to modify the function that generates the spatial noise patterns. For example, this `generate_fancy_noise()` function is awfully similar to the noise generator I used in the *Broken Lands* series:

```{r define-worley}
generate_fancy_noise <- function(x, y, seed = NULL) {
  if(!is.null(seed)) {
    set.seed(seed)
  }
  z <- ambient::fracture(
    noise = ambient::gen_worley,
    fractal = ambient::billow,
    octaves = 8,
    freq_init = .1,
    frequency = ~ . * 2,
    gain_init = 3,
    gain = ~ . * .5,
    value = "distance2",
    x = x,
    y = y
  )
  ambient::fracture(
    noise = ambient::gen_simplex,
    fractal = ambient::billow,
    octaves = 10,
    freq_init = .02,
    frequency = ~ . * 2,
    gain_init = 1,
    gain = ~ . * .8,
    x = x + z,
    y = y + z
  )
}
```

Here it is in action:

```{r island-fancy-noise, cache=cache_images}
new_grid() |>
  dplyr::mutate(
    height = generate_fancy_noise(x, y, seed = seed),
    islands = dplyr::if_else(
      condition = height < median(height),
      true = median(height),
      false = height
    )
  ) |>
  as.array(value = islands) |>
  render(zscale = .01)
```

Very pretty. I suspect that had I isolated this particular noise generator earlier in the artistic process -- rather than figuring out in hindsight that this was what I'd been using all along -- I might have stopped here, and not bothered with any of the other tricks that I actually used.^[Easter egg for the three people who know the reference: I rather suspect that what I've done in this section is create the artistic version of the "linear ballistic accumulator" model of human choice behaviour, where my original system was a full fledged diffusion model. Happily for all concerned, neither Scott nor Roger are going to read this post.] But of course this is a post-mortem deconstruction,^[Fortunately for me, this is an art post and not a reGIStEreD RepORt, so I'm allowed to talk freely about this deconstruction. In a former life I'd have spent about three months arguing with petty reviewers about the distinction between deconstruction and HARKing, and frankly life is too short for that bollocks.] not a description of the bizarrely tangled artistic process I actually followed, so there are more layers to come...

<br>

## Queering geography

The final image in the last section captures something about the overall structure of the broken lands images, but it feels wrong in the particulars. It's too smooth, too fluid, too... natural. It doesn't have the same feel as the originals. I don't have the same feeling of alienness that the original pieces have. Where does that not-quite-real feeling come from?  

The answer to this involves every generative artists favourite trick: curl fields. If you've read the tutorial articles I linked to earlier, you've encountered these before so I won't repeat myself by explaining yet again what a curl field is. What I'll do instead is write a `generate_curl()` function that takes the original grid of coordinates (in the "base" space) and transforms them to a new set of points (in an "embedding" space) using a curl transformation:^[Fine. Yes, if you look closely at the code you can see I'm doing more than simply applying a curl field. But please... allow me some latitude here. This is a blog post not a dissertation.]

```{r curl-transform}
generate_curl <- function(x, y, seed = NULL) {
  if(!is.null(seed)) {
    set.seed(seed)
  }
  ambient::curl_noise(
    generator = ambient::fracture,
    noise = ambient::gen_simplex,
    fractal = ambient::fbm,
    octaves = 3,
    frequency = ~ . * 2,
    freq_init = .3,
    gain_init = 1,
    gain = ~ . * .5,
    x = x,
    y = y
  )
}
```

Here's what happens when we apply this function:

```{r just-curl}
grid <- new_grid()
coords <- generate_curl(grid$x, grid$y, seed = seed)
head(coords)
```

The code here is slightly unpleasant, yes, but I'll do it in a slightly cleaner way in a moment. What matters right now is the fact that the `coords` data frame is a transformed version of the `grid` data. The original (x,y) coordinates in the base space have been transformed to some (x,y) coordinates in some new space. 

A slightly cleaner way of doing this -- keeping both the original coordinates and the transformed values -- would be as follows:

```{r keep-both}
canvas <- grid |>
  dplyr::mutate(
    curl_x = coords$x,
    curl_y = coords$y
  )

canvas
```

Okay that's nice, but what exactly are these "curl transformed" values? What do they look like? Fair question. Here's a plot showing what has happened to our nice rectangular grid after the transformation...


```{r plot-curl-transform, echo=FALSE, cache=cache_images}
grid <- new_grid()
coords <- generate_curl(grid$x, grid$y, seed = seed)

ggplot2::ggplot(coords, ggplot2::aes(x, y)) +
  ggplot2::geom_point(size = .1, alpha = .05) + 
  ggplot2::coord_equal() + 
  ggplot2::theme_void()
```

This image has an evocative feel, right? Like I've taken a regular square sheet of fabric and folded or transformed it in some strange way to create an "embedded" manifold? Well, yeah. That's precisely what I've done.

Our noise operations will be specified on this transformed/embedded manifold, but -- to reveal the ending slightly too soon -- the final image will be defined on the base space. The code below shows how to apply the noise operations in the embedding space:

```{r noise-in-curl-space}
canvas <- canvas |>
  dplyr::mutate(
    height = generate_fancy_noise(curl_x, curl_y, seed = seed),
    islands = dplyr::if_else(
      condition = height < median(height),
      true = median(height),
      false = height
    )
  )

canvas
```

Just to give you a sense of what that looks like in the embedding space, here's what happens when we redraw the "manifold" plot from above, with each point coloured using the value of the "islands" variable:

```{r demo-worley-distance, echo=FALSE, cache=cache_images}
ggplot2::ggplot(
  canvas,
  ggplot2::aes(curl_x, curl_y, colour = islands)
) +
  ggplot2::geom_point(size = .1, show.legend = FALSE) + 
  ggplot2::coord_equal() + 
  ggplot2::theme_void() + 
  ggplot2::scale_colour_gradientn(
    colours = hcl.colors(12, "YlOrRd", rev = TRUE)
  )
```

You can sort of see what's going on here. We have a spatial noise pattern that generated the topography that I showed in the last section, but it's defined on the *embedding* space. Our *base* space is like a rectangular fabric that has been laid and folded over and over onto this embedding space, and then we've spray painted this pattern onto the fabric.^[Presumably using some magic spray paint that coats every layer of the folded fabric, not just the topmost layer!] ^[Okay yes the metaphor is a bit strained, but it's the best I can think of when what I'm actually doing is constructing a surjective mapping from the base space to the embedding space, adding noise to the mapped values, and then using "magic" to pull back to the base space because I'm a good girl who doesn't throw away the original values when she performs a many-to-one trick.] ^[Yes I'm aware that the "many to one" jokes write themselves at this point but as I mentioned previously I am a good girl so I shan't continue this line of thought.] When we unfold the spray painted fabric and lay it flat again, this is what we get:

```{r unfolded-fabric, cache=cache_images}
#| fig-width: 6
#| fig-height: 6
canvas |> 
  as.array(value = islands) |>
  image(axes = FALSE, asp = 1, useRaster = TRUE)
```

It's a bit like tie-dyeing I guess? That's what it feels like to me. I'm taking something regular, scrunching it up in a strange way, and then applying the colours to the scrunched up object before unfolding it. 

In any case, we can use our `render()` add shadows rayshader using the `render()`:

```{r plot-worley-distance, cache=cache_images}
canvas |> 
  as.array(value = islands) |>
  render(zscale = .05)
```

Okay now *that* feels like an alien geography to me! It still doesn't look at all like our final images, but it has the right feel to it. Yes, it's still a geography of sorts, but it feels stretched and twisted in an unnatural way. It feels... well, it feels *painful*. Nothing like this can occur naturally without the action of some catastrophic process. That's what it feels like to me. The "brokenness" of the original images is created by this transformation: natural-ish patterns imposed on a twisted space create bizarre and alien patterns when those contortions are unfolded. It feels weird... it feels strange... it feels queer.^[There is an obvious metaphor for the queer experience of living in a world defined by cisheteronormativity here, but I'll let you flesh out the rest of the mapping on your own. You're a clever person, you know how to read between the lines, right?]

## Artistic trickery

### Be discre[et|te]

```{r discretise}
discretise <- function(x, n) {
  round(ambient::normalise(x) * n) / n
}
```

```{r discrete-plot}
grid <- new_grid() 
coords <- generate_curl(grid$x, grid$y, seed = seed)

canvas <- grid |> 
  dplyr::mutate(
    curl_x = coords$x |> discretise(50), 
    curl_y = coords$y |> discretise(50),
    height = generate_fancy_noise(curl_x, curl_y, seed = seed) |> 
      discretise(50),
    islands = dplyr::if_else(
      condition = height < median(height),
      true = median(height),
      false = height
    )
) 

canvas
```

```{r unfolded-fabric-discrete, cache=cache_images}
#| fig-width: 6
#| fig-height: 6
canvas |> 
  as.array(value = islands) |>
  image(axes = FALSE, asp = 1, useRaster = TRUE) 
```

Rayshade and render:

```{r rayshaded, cache=cache_images}
canvas |> 
  as.array(value = islands) |>
  render(zscale = .01) 
```


### Be smooth

```{r mixed-method, cache=cache_images}
grid <- new_grid() 
coords <- generate_curl(grid$x, grid$y, seed = seed)

canvas <- grid |> 
  dplyr::mutate(
    curl_x = coords$x |> discretise(50), 
    curl_y = coords$y |> discretise(50),
    noise_curl = generate_fancy_noise(curl_x, curl_y, seed = seed),
    noise_base = generate_simplex(x, y, seed = seed),
    height = (noise_curl + noise_base) |> discretise(50),
    islands = dplyr::if_else(
      condition = height < median(height),
      true = median(height),
      false = height
    )
) 

canvas |> 
  as.array(value = islands) |>
  render(zscale = .01) 
```


### Be jagged

```{r manual-colour, cache=cache_images}
shades <- hcl.colors(50, "TealGrn")
shades[1] <- "#ffffff"

canvas |> 
  as.array(value = islands) |>
  render(shades = shades) 
```


```{r manual-colour-shuffled, cache=cache_images}
generate_shades <- function(palette = "TealGrn", n = 50, seed = NULL) {
  if(!is.null(seed)) {
    set.seed(seed)
  }
  shades <- hcl.colors(n, palette)
  shades <- sample(shades)
  shades[1] <- "#ffffff"
  shades  
}

canvas |> 
  as.array(value = islands) |>
  render(shades = generate_shades(seed = seed)) 
```

## Goodnight, sweet dreams

> One day we're gonna wake up laughing <br>
Put on your dancing shoes <br>
You won't believe the tales I tell <br>
That time, Danielle, ain't mine to choose <br>
Danielle, Danielle, Danielle <br>
&nbsp; &nbsp; -- [Tex Perkins](https://youtu.be/RClo-JU-8P4?t=79) (and others, but whatever...)^[A note for foreigners: if you are an Australian male-attracted person of a certain age, you immediately understand. It doesn't matter if you're bisexual, a straight woman, or a gay man. It doesn't matter if you got hooked by Beasts of Bourbon, or by Cruel Sea, or the solo acts. There's nothing specific to it except... Tex Perkins.]

Much like the broken lands system itself, this post has a strange genesis. If you read the [strange year](https://blog.djnavarro.net/posts/2022-12-26_strange-year/) post I wrote a few months ago, you'd be unsurprised to hear that I am attempting to [square a few circles](https://en.wikipedia.org/wiki/Squaring_the_circle) right now. Something broke -- rather badly -- and I'm trying to work out how to put the pieces together even knowing that the shattered parts can't go back together in the shape they were before. Aspects to my life that were once central to my sense of self are scattered, and there are little slivers of glass laid everywhere -- when I attempt to pick up one of the pieces from the floor I get cut deeply by those sharp little transparent needles. 

This post is one of those attempts. One of the pieces I need to pick up is my writing. The tiny cataclysm of 2022 broke my writing. I didn't become a bad writer, it was something worse. I lost my sense of ownership over my writing. I wrote because someone else owned the words. Someone else set the direction. Someone else chose what I'd say or not say, and I didn't even notice it happening. Having once before -- once upon a time in a land far away -- surrendered my autonomy utterly to another, I never thought I'd find myself having done so again (even in a smaller way). But it happens. It happens because the vector of approach is different every time, and I didn't see it coming. 

<!--------------- appendices go here ----------------->


