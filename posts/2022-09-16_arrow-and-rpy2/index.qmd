---
title: "Data transfer between Python and R with rpy2 and Apache Arrow"
description: "A Pythonic approach for sharing Arrow Tables between Python and R. This is the second in a two-part series on data transfer. In this post I discuss how the rpy2 Python library allows you to call R from Python, and the rpy2-arrow extension enables zero-copy transfer of Arrow Tables between languages."
date: "2022-09-16"
categories: [Apache Arrow, R, Python]
image: "img/cover.jpg"
jupyter: python3
---

<!-- 
cover img: https://unsplash.com/photos/C4sxVxcXEQg
artist: Reuben Juarez
licence: unsplash free-to-use 
-->

<!-- 
# bash commands to build this post
conda activate continuation
export LD_LIBRARY_PATH="$(python -m rpy2.situation LD_LIBRARY_PATH)":${LD_LIBRARY_PATH}
cd ~/GitHub/sites/quarto-blog/posts/2022-09-16_arrow-and-rpy2
quarto render index.qmd --execute-daemon-restart
-->


In the [last post on this blog](/posts/2022-09-09_reticulated-arrow/) I showed how [Apache Arrow](https://arrow.apache.org/) makes it possible to hand over data sets from R to Python (and vice versa) without making wasteful copies of the data. 

The solution I outlined there was to use the [reticulate](https://rstudio.github.io/reticulate/) package to conduct the handover, and rely on Arrow tools both sides to manage the data. In one sense it's a perfectly good solution to the problem... but it's a solution tailor made for R users who need access to Python. When viewed from the perspective of a Python user who needs access to R, it's a little awkward to have an R package (reticulate) governing the handover.^[Relatedly, if you're a Python user blogging in quarto, you are very unlikely to be using the [knitr engine](https://quarto.org/docs/reference/cells/cells-knitr.html) to execute code like I did in the last blog post. Instead you're almost certainly using the [jupyter engine](https://quarto.org/docs/reference/cells/cells-jupyter.html). With that in mind, and with the goal of making this post a little more Pythonic, I'm using Jupyter this time.] Perhaps we can find a more Pythonic way to approach this?

A solution to our problem is provided by the [rpy2 library](https://rpy2.github.io/) that provides an interface to R from Python, and the [rpy2-arrow extension](https://rpy2.github.io/rpy2-arrow/version/main/html/index.html) that allows it to support Arrow objects. Let's take a look, shall we?

<br><br>

:::{.column-body-outset}
![This was the masthead image displayed atop the front page of [The Arrow](https://en.wikipedia.org/wiki/The_Arrow_(newspaper)), a newspaper published in Sydney between 1896 and 1936. It seems an appropriate way to start this post given that I'm talking about Apache Arrow, and I'm using a data set that lists works of fiction published in Australian newspapers in the 19th and early 20th centuries.^[A note on image copyright. As far as I can tell all images in this post are public domain. They're all sourced from Trove and are all over a century old, meaning that they are all covered by the "plus 50 years" rule in Australian copyright law (the current "plus 70" rule does not apply retroactively). The original illustrator is difficult to determine, and given the age of the images so too is any potential copyright holder, but it seems extremely unlikely that any are still covered by any copyright. As always, I will remove any image if I discover that I am incorrect in this.]](img/cover.jpg)
:::

<br><br>

## Setting up the Python environment

For the purposes of this post I'll create a fresh conda environment that I'll call "continuation", partly because this post is a continuation of the previous one and partly because the data set I'll use later is taken from a database of serialised fiction called [To Be Continued...](https://cdhrdatasys.anu.edu.au/tobecontinued/). 

I was able install most packages I need through conda-forge, but for rpy2 and rpy2-arrow I was only able to do so from pypi so I had to use pip for that. So the code for setting up my Python environment, executed at the terminal, was as follows:

``` bash
conda create -n continuation
conda install -n continuation pip pyarrow pandas jupyter
conda activate continuation
pip install rpy2 rpy2-arrow
```

As long as I render this post with the "continuation" environment active everything works smoothly.^[Ha ha. Just kidding. Aaaaaaaaactualllllllly, it will *probably* work smoothly for most people. But there are exceptions, and because I am a foolish tinkerer and have a nonstandard R configuration I am one of them. I have recently made the decision to use the [rig manager](https://github.com/r-lib/rig) to configure multiple concurrent R installations on my laptop. This introduces a some complexity, because rig necessarily installs R to non standard locations. Now, rig does the right thing and correctly sets the PATH environment variable so that rpy2 (and bash) can find R, but it does lead to some peculiar behaviour where rpy2 doesn't find some of the C libraries need. In the rpy2 readme there's a discussion of this issue. In such cases you need to tweak the LD_LIBRARY_PATH environment variable before starting Python: `export LD_LIBRARY_PATH="$(python -m rpy2.situation LD_LIBRARY_PATH)":${LD_LIBRARY_PATH}`]


<br><br>

## Introducing rpy2

The purpose of the rpy2 library is to allow users to call R from Python, typically with the goal of allowing access to statistical packages distributed through [CRAN](https://cran.r-project.org/). I'm currently using version 3.5.4, and while this blog post won't even come close to documenting the full power of the library, the [rpy2 documentation](https://rpy2.github.io/doc/v3.5.x/html/index.html#) is quite extensive. To give you a bit of a flavour of it, let's import the library:

```{python import-rpy2}
import rpy2
rpy2.__version__
```

This does not in itself give us access to R. That doesn't happen until we explicitly import either the `robjects` module (a high level interface to R) or import the `rinterface` model (a low level interface) and call `rinterface.initr()`. This post won't cover `rinterface` at all; we can accomplish everything we need to using only the high level interface provided by `robjects`. So let's import the module and, in doing so, start R running as a child process:

```{python import-robjects}
import rpy2.robjects as robjects
```

You'll notice that this prints a little startup message. If you're following along at home you'll probably see something different on your own machine: most likely you'll see the standard R startup message here. It's shorter in this output because I modified my `.Rprofile` to make R less chatty on start up.^[As an aside, it's worth noting that rpy2 has run R with my default configuration (notwithstanding the fact that my defaults are configured using rig). It hasn't loaded any specific R environment. It did occur to me that a complete discussion of this topic would also describe how a Python user could use rpy2 to configure the R environment using the [renv](https://rstudio.github.io/renv/index.html) package for instance, but to be honest that started to feel a little beyond the scope of the post. About the only thing I *will* mention here is that in this particular use case (namely, passing Arrow objects between R and Python) I would not recommend trying to configure the Python environment and the R environment within the same conda environment. Because that thought occurred to me too. I tried it and oh my... the number of unsolvable conflicts was truly impressive.]    

Anyway, our next step is to load some packages. In native R code we'd use the `library()` function for this, but rpy2 provides a more Pythonic approach. Importing the packages submodule gives us access to `importr()`, which is allows us to load packages. The code below illustrates how you can expose the base R package and the utils R package (both of which come bundled with any minimal R installation) to Python:

```{python import rpackages}
import rpy2.robjects.packages as pkgs

base = pkgs.importr("base")
utils = pkgs.importr("utils")
```

Once we have access to utils we can call the R function `install.packages()` to install additional packages from CRAN. However, at this point we need to talk a little about how names are translated by rpy2. As every Python user would immediately notice, `install.packages()` is not a valid function name in Python: the dot is a special character and not permitted within the name of a function. In contrast, although not generally recommended in R except in special circumstances,^[The dot is typically used to denote an [S3](https://adv-r.hadley.nz/s3.html) method in R, but because R embraces chaos this is not universally adhered to and in any case S3 is... look, I love S3 but as Hadley Wickham once observed it's an object oriented programming system that absolutely allows you to shoot yourself in the foot if you want to. Anyway. This is not the post for ramblings about the chaotic splendour of R.] function names containing dots are syntactically valid in R and there are functions that use them. So how do we resolve this? 

In most cases, the solution is straightforward: rpy2 will automatically convert dots in R to underscores in Python, and so in this instance the function name becomes `install_packages()`. For example, if I want to install the [fortunes](https://cran.r-project.org/package=fortunes) package using rpy2, I would use the following command:^[Depending on how blank your R configuration is, you may need to specify which CRAN mirror you want to download the package from before attempting the installation. To do that, include a command like `utils.chooseCRANmirror(ind=1)` to select the first mirror on the list of known servers.]

``` python
utils.install_packages("fortunes")
```

There are some subtleties around function name translation, however. I won't talk about them in this post, other to mention that the documentation discusses this in the section on [calling functions](https://rpy2.github.io/doc/v2.9.x/html/robjects_functions.html).

In any case, now that I have successfully installed the fortunes package I can import it, allowing me to call the `fortune()` function:

```{python use-fortunes}
ftns = pkgs.importr("fortunes")
ftn7 = ftns.fortune(7)
print(ftn7)
```

I'm rather fond of this quote, and it seems very appropriate to the spirit of what polyglot data science is all about. Whatever language or tools we're working in, we've usually chosen them for good reason. But there is no tool that works all the time, nor any language that is ideal for every situation. Sometimes we need something very different, and when we do it is very helpful if our tools able to talk fluently to each other.

We're now at the point that we can tackle the problem of transferring data from Python to R, but in order to do that we'll need some data...

<br><br>

:::{.column-body-outset}
![This was the header illustration to a story entitled "The Trail of the Serpent" by M. E. Braddon. It was published in the *Molong Express and Western District Advertiser* on 4 August 1906. The moment I saw it I knew I had to include it here. I can hardly omit a serpent reference in a Python post, now can I? That would be grossly irresponsible of me as a tech blogger. [Trove article 139469044](https://trove.nla.gov.au/newspaper/article/139469044)](img/serpent.jpg)
:::

<br><br>

## About the data 

I've given you so many teasers about the data set for this post that it almost feels a shame to spoil it by revealing the data, but all good things must come to an end I suppose. The data I'm using are taken from the [To Be Continued...](https://cdhrdatasys.anu.edu.au/tobecontinued/) database of fiction published in Australian newspapers during the 19th and early 20th century. Originally collected using the incredibly cool [Trove](https://trove.nla.gov.au/) resource run by the National Library of Australia, the *To Be Continued...* data are released under a CC-BY-4.0 licence and maintained by Katherine Bode and Carol Hetherington. I'm not using the full data set here, only the metadata. In the complete database you can find full text of published pieces, and in the Trove links you can find the digitised resources from which they were sourced, but I don't need that level of detail here. All I need is an interesting data table that I can pass around between languages. For that, the metadata alone will suffice!

To give you a sense of what the data set (that is, the restricted version I'm using here) looks like, let's fire up [pandas](https://pandas.pydata.org/) and take a peek at the structure of the table. It's stored as a CSV file, so I'll call `read_csv()` to import the data: 

```{python panda-read-csv}
import pandas

fiction = pandas.read_csv("fiction.csv", low_memory = False)
fiction.head()
```

Okay, that's helpful. We can see what all the columns are and what kind of data they contain. I'm still pretty new to data science workflows in Python, but it's not too difficult to do a little bit of data wrangling with Pandas. For instance, we can take a look at the distribution of nationalities among published authors. The table shown below counts the number of distinct publications (Trove IDs) and authors for each nationality represented in the data:

```{python panda-aggregate}
fiction[["Nationality", "Trove ID", "Publication Author"]]. \
  groupby("Nationality"). \
  nunique()
```

It would not come as any surprise, at least not to anyone with a sense of Australian history, that there were far more British authors than Australian authors published in Australian newspapers during that period. I was mildly surprised to see so many American authors represented though, and I have nothing but love for the lone Italian who published 12 pieces. 

Now that we have a sense of the data, let's add Arrow to the mix!

<br><br>

:::{.column-body-outset}
![An illustration from "The Lass That Loved a Miner" by J. Monk Foster. Published in *Australian Town and Country Journal*, 14 April 1894. The story features such fabulous quotes as "Presently the two dark figures slid slowly, noiselessly, along the floor towards the scattered gold dust and he canisters filled with similar precious stuff. Inch by inch, foot by foot the two thieves crept like snakes nearer and nearer to the to the treasure they coveted". Admit it, you're hooked already, right? [Trove article 71212612](https://trove.nla.gov.au/newspaper/article/71212612)](img/darlington.jpg)

:::

<br><br>

## Pandas to Arrow Tables

To give ourselves access to Apache Arrow from Python we'll use the [PyArrow](https://arrow.apache.org/docs/python/index.html) library. Our immediate goal is to convert the `fiction` data from a Pandas DataFrame to an Arrow Table. To that end, pyarrow supplies a `Table` object with a `from_pandas()` method that we can call:
 
```{python arrow-fiction}
import pyarrow

fiction2 = pyarrow.Table.from_pandas(fiction)
fiction2
```

<br>

The `fiction2` object contains the same data as `fiction` but it is structured as an Arrow Table, and the data is stored in memory allocated by Arrow. Python itself only stores some metadata and the C++ pointer that refers to the Arrow Table. This isn't exciting, but it will be important (and powerful!) later in a moment we transfer the data to R. 

Speaking of which, we have arrived at the point where we get to do the fun part... seamlessly handing the reins back and forth between Python and R without needing to copy the Arrow Table itself. 

<br><br>

## Passing Tables from Python to R

To pass Arrow objects between Python and R, rpy2 needs a little help because it doesn't know how to handle Arrow data structures. That's where the [rpy2-arrow module](https://rpy2.github.io/rpy2-arrow/version/main/html/index.html) comes in. As the documentation states:

> The package allows the sharing of Apache Arrow data structures (Array, ChunkedArray, Field, RecordBatch, RecordBatchReader, Table, Schema) between Python and R within the same process. The underlying C/C++ pointer is shared, meaning potentially large gain in performance compared to regular arrays or data frames shared between Python and R through the conversion rules included in rpy2. 

I won't attempt to give a full tutorial on rpy2-arrow in this post. Instead, I'll just show you how to use it to solve the problem at hand. Our first step is to import the conversion tools from rpy_arrow:

```{python import pyra}
import rpy2_arrow.pyarrow_rarrow as pyra
```

Having done that, the `pyarrow_table_to_r_table()` function allows us to pass an Arrow Table from Python to R:

```{python use-rpy2-arrow}
fiction3 = pyra.pyarrow_table_to_r_table(fiction2)
fiction3
```

The printed output isn't the prettiest thing in the world, but nevertheless it does represent the object of interest. On the Python side we have `fiction2`, a data structure that points to an Arrow Table and enables various compute operations supplied through pyarrow. On the R side we have now created `fiction3`, a data structure that points to the *same* Arrow Table and enables compute operations supplied by the R arrow package. In the same way that `fiction2` only stores a small amount of metadata in Python, `fiction3` stores a small amount of metadata in R. Only this metadata has been copied from Python to R: the data itself remains untouched in Arrow.

<br><br>

:::{.column-body-outset}
![Header illustration to "Where flowers are Rare" by Val Jameson. Published in *The Sydney Mail*, 8 December 1909. I honestly have no logical reason for including this one. But I was listening to Kylie Minogue at the time I was browsing the database and the title made me think of [Where the Wild Roses Grow](https://www.youtube.com/watch?v=lDpnjE1LUvE), and anyway both the song and the story have death in them. So then I simply had to include the image because... it's *Kylie*. Obviously. Sheesh. [Trove article 165736425](https://trove.nla.gov.au/newspaper/article/165736425)](img/flowers.jpg)
:::

<br><br>

## Accessing the Table from the R side

We're almost done, but the tour isn't really complete until we've stepped out of Python entirely, manipulated the object on the R side, and then passed something back to Python. So let's do that next.

In order to pull off that trick within this [quarto](https://quarto.org/) document -- which is running [jupyter](https://jupyter.org/) under the hood -- we'll need to employ a little notebook magic, again relying on rpy2 to supply all the sparkly bits. To help us out in this situation, the rpy2 library supplies an [interface for interactive work](https://rpy2.github.io/doc/latest/html/interactive.html) that we can invoke in a notebook context like this: 

```{python py-dplyr}
%load_ext rpy2.ipython
```

Now that we've included this line, all I have to do is preface each cell with `%%R` and the subsequent "Python" code will be passed to R and interpreted there.^[Okay, that brings me to something I didn't really cover in my last post. Some R users might be wondering about what was going on in the last post where I was flipping back and forth between R and Python without apparently doing anything like this. The answer is that when using [knitr](https://yihui.org/knitr/) as the engine rather than jupyter, python code is automatically interpreted with the help of reticulate. However, that feature is exposed by default in the knitr engine so I didn't need to invoke it explicitly the way I'm doing here in jupyter.] To start with I'll load the dplyr and arrow packages, using the `suppressMessages()` function to prevent them being chatty: 

```{python call-r}
%%R

suppressMessages({
  library(dplyr)
  library(arrow)
})
```

Having loaded the relevant packages, I'll use the dplyr/arrow toolkit to do a little data wrangling on the `fiction3` Table. I'm not doing anything fancy, just a little cross-tabulation counting the joint distribution of genders and nationalities represented in the data using the `count()` function, and using `arrange()` to sort the results: 

```{python more-r, results='asis'}
%%R -i fiction3

gender <- fiction3 |> 
  count(Gender, Nationality) |>
  arrange(desc(n)) |>
  compute()
  
gender
```

The output isn't very informative, but don't worry, by the end of the post there will be a gender reveal I promise.^[I'm sorry. The joke was too obvious, yet too hard to resist.] Besides, the actual values of `gender` aren't important right now. In truth, the part that we're most interested in here is the first line of code. By using `%%R -i fiction3` to specify the cell magic, we're able to access the `fiction3` object from R within this cell and perform the required computations.

Oh, and also we now have a new `gender` object in our R session that we probably want to pull back into Python!

<br><br>

## The journey home: A tale of four genders

Okay. So we now have an object in the embedded R session that we might wish to access from the Python session and convert to a Python object. First we'll pass the Arrow Table from R to Python and then convert to a Pandas DataFrame. Here's how that process works. If you recall from earlier in the post, we imported `robjects` to start the embedded R session. When we did so, we also exposed `robjects.r`, which provides access to all objects within that R session. To create a Python object `gender2` that refers to the R data structure we created in the last section, here's what we do:

```{python return-r-to-python}
gender2 = robjects.r('gender')
gender2
```

Importantly, notice that this is the same object. The `gender2` variable still refers to the Arrow Table in R: it's *not* a pyarrow table. If we want to convert it to a data structure that pyarrow understands, we can again use the rpy-arrow conversion tools. In this case, we can use the  `rarrow_to_py_table()` function:

```{python convert-gender}
gender3 = pyra.rarrow_to_py_table(gender2)
gender3
```

Just like that, we've handed over the Arrow Table from R back to Python. Again, it helps to remember that `gender2` is an R object and `gender3` is a Python object, but both of them point to the same underlying Arrow Table. 

In any case, now that we have `gender3` on the Python side, we can use the `to_pandas()` method from `pyarrow.Table` to convert it to a pandas data frame:

```{python pygender-to-panda}
gender4 = pyarrow.Table.to_pandas(gender3)
gender4
```

And with that our transition home is complete!

<br><br>

## Summary

TO BE ADDED

<br><br>

:::{.column-body-outset}
![Header illustration to "The Black Motor Car" by J. B. Harris Burland. Published in -- just to bring us full circle -- *The Arrow*, 25 November 1905. I cannot properly do justice to this work of art so I will merely quote: "Again he took her in his arms, and this time she did not try to free herself from his embrace. But she looked up at him with pleading eyes. He bent down his face and kissed her tenderly on the forehead. His whole nature cried out for the touch of her lips, but he was man enough to subdue the passion that burnt within him." [Trove article 103450814](https://trove.nla.gov.au/newspaper/article/103450814)   ](img/motorcar.jpg)
:::



## Acknowledgements {.appendix}

In writing this post I am heavily indebted to Isabella Velásquez, whose fabulous post on [calling R from Python with rpy2](https://rviews.rstudio.com/2022/05/25/calling-r-from-python-with-rpy2/) helped me immensely. The [documentation on integrating PyArrow with R](https://arrow.apache.org/docs/python/integration/python_r.html) was extremely helpful too! Thank you to [Kae Suarez](https://twitter.com/kae_suarez) for reviewing this post.


