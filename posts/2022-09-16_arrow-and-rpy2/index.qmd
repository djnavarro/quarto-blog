---
title: "Data transfer between Python and R with rpy2 and Apache Arrow"
description: "A Pythonic approach for sharing Arrow Tables between Python and R. This is the second in a two-part series on data transfer. In this post I discuss how the rpy2 Python library allows you to call R from Python, and the rpy2-arrow extension enables zero-copy transfer of Arrow Tables between languages."
date: "2022-09-16"
categories: [Apache Arrow, R, Python]
image: "img/cover.jpg"
jupyter: python3
---

<!-- 
cover img: https://unsplash.com/photos/C4sxVxcXEQg
artist: Reuben Juarez
licence: unsplash free-to-use 
-->

<!-- 
# bash commands to build this post
conda activate continuation
export LD_LIBRARY_PATH="$(python -m rpy2.situation LD_LIBRARY_PATH)":${LD_LIBRARY_PATH}
cd ~/GitHub/sites/quarto-blog/posts/2022-09-16_arrow-and-rpy2
quarto render index.qmd --execute-daemon-restart
-->


In the [last post on this blog](/posts/2022-09-09_reticulated-arrow/) I showed how [Apache Arrow](https://arrow.apache.org/) makes it possible to hand over data sets from R to Python (and vice versa) without making wasteful copies of the data. 

The solution I outlined there was to use the [reticulate](https://rstudio.github.io/reticulate/) package to conduct the handover, and rely on Arrow tools both sides to manage the data. In one sense it's a perfectly good solution to the problem... but it's a solution tailor made for R users who need access to Python. When viewed from the perspective of a Python user who needs access to R, it's a little awkward to have an R package (reticulate) governing the handover.^[Relatedly, if you're a Python user blogging in quarto, you are very unlikely to be using the [knitr engine](https://quarto.org/docs/reference/cells/cells-knitr.html) to execute code like I did in the last blog post. Instead you're almost certainly using the [jupyter engine](https://quarto.org/docs/reference/cells/cells-jupyter.html). With that in mind, and with the goal of making this post a little more Pythonic, I'm using Jupyter this time.] Perhaps we can find a more Pythonic way to approach this?

A solution to our problem is provided by the [rpy2 library](https://rpy2.github.io/) that provides an interface to R from Python, and the [rpy2-arrow extension](https://rpy2.github.io/rpy2-arrow/version/main/html/index.html) that allows it to support Arrow objects. Let's take a look, shall we?

<br><br>

:::{.column-body-outset}
![This was the masthead image displayed atop the frony page of [The Arrow](https://en.wikipedia.org/wiki/The_Arrow_(newspaper)), a newspaper published in Sydney between 1896 and 1936. It seems an appropriate way to start this post given that I'm talking about Apache Arrow, and I'm using a data set that lists works of fiction published in Australian newspapers in the 19th and early 20th centuries.^[A note on image copyright. As far as I can tell all images in this post are public domain. They're all sourced from Trove and are all over a century old, meaning that they are all covered by the "plus 50 years" rule in Australian copyright law (the current "plus 70" rule does not apply retroactively). The original illustrator is difficult to determine, and given the age of the images so too is any potential copyright holder, but it seems extremely unlikely that any are still covered by any copyright. As always, I will remove any image if I discover that I am incorrect in this.]](img/cover.jpg)
:::

<br><br>

## Setting up the Python environment

For the purposes of this post I'll create a fresh conda environment that I'll call "continuation", partly because this post is a continuation of the previous one and partly because the data set I'll use later is taken from a database of serialised fiction called [To Be Continued...](https://cdhrdatasys.anu.edu.au/tobecontinued/). 

I was able install most packages I need through conda-forge, but for rpy2 and rpy2-arrow I was only able to do so from pypi so I had to use pip for that. So the code for setting up my Python environment was as follows:

``` bash
conda create -n continuation
conda install -n continuation pip pyarrow pandas jupyter
conda activate continuation
pip install rpy2 rpy2-arrow
```

<br><br>

## Introducing rpy2

The purpose of the rpy2 library is to allow users to call R from Python, typically with the goal of allowing access to statistical packages distributed through [CRAN](https://cran.r-project.org/). I'm currently using version 3.5.4, and while this blog post won't even come close to documenting the full power of the library, the [rpy2 documentation](https://rpy2.github.io/doc/v3.5.x/html/index.html#) is quite extensive. To give you a bit of a flavour of it, let's import the library:

```{python import-rpy2}
import rpy2
rpy2.__version__
```

This does not in itself give us access to R. That doesn't happen until we explicitly import either the `robjects` module (a high level interface to R) or import the `rinterface` model (a low level interface) and call `rinterface.initr()`. This post won't cover `rinterface` at all; we can accomplish everything we need to using only the high level interface provided by `robjects`. So let's import the module and, in doing so, start R running as a child process:

```{python import-robjects}
import rpy2.robjects as robjects
```

You'll notice that this prints a little startup message. If you're following along at home you'll probably see something different on your own machine: most likely you'll see the standard R startup message here. It's shorter in this    output because I modified my `.Rprofile` to make R less chatty on start up.^[As an aside, it's worth noting that rpy2 has run R with my standard configuration. It hasn't loaded any specific environment. I was half tempted to talk about how you a Python user could use rpy2 to configure the R environment using the [renv](https://rstudio.github.io/renv/index.html) package for instance, but that felt a little beyond the scope of the post. The only thing I will mention is that in this particular use case (passing Arrow objects between R and Python) I would not recommend trying to configure the Python environment and the R environment within the same conda environment. I tried this and oh my... the number of unsolvable conflicts was truly impressive. Additionally, while I am mentioning painful details, during the process of writing this post I decided to start using [rig](https://github.com/r-lib/rig) to manage multiple installations of R on my machine. This is fine, in the sense that rig manages the PATH to the default R version and rpy2 finds it... but there is an issue in the fine print (it's in the rpy2 readme but naturally I did not read it until I encountered the problem). Sometimes this leads to a situation where some C libraries can't be found, and you need to run the following line of code at the terminal before starting Python: `export LD_LIBRARY_PATH="$(python -m rpy2.situation LD_LIBRARY_PATH)":${LD_LIBRARY_PATH}`] 

Anyway, our next step is to load some packages. In native R code we'd use the `library()` function for this, but rpy2 provides a more Pythonic approach. Importing the packages submodule gives us access to `importr()`, which is allows us to load packages. The code below illustrates how you can expose the base R package and the utils R package (both of which come bundled with any minimal R installation) to Python:

```{python import rpackages}
import rpy2.robjects.packages as pkg

base = pkg.importr("base")
utils = pkg.importr("utils")
```

Of particular note is that once we have access to utils we can call the native R function `install.packages()` to install additional packages from CRAN. However, at this point we need to talk a little about how names are translated by rpy2. As every Python user would immediately notice, the dot is special and is not used within the name of a function. In contrast, although not generally recommended in R except in special circumstances,^[The dot is typically used to denote an [S3](https://adv-r.hadley.nz/s3.html) method in R, but because R embraces chaos this is not universally adhered to and in any case S3 is... look, I love S3 but as Hadley Wickham once observed it's an object oriented programming system that absolutely allows you to shoot yourself in the foot if you want to. Anyway. This is not the post for ramblings about the chaotic splendour of R.] function names containing dots are syntactically valid in R.^[This issue holds more generally. R permits a lot more flexibility in function names than Python. The rpy2 documentation discusses how this and related issue are handled in the section on [calling functions](https://rpy2.github.io/doc/v2.9.x/html/robjects_functions.html).] To address this, rpy2 will automatically convert dots to underscores. So if I want to install the [fortunes](https://cran.r-project.org/package=fortunes) package -- a simple package that contains quotes vaguely related to R -- using rpy2, this is how I'd do it:^[Depending on how blank your R configuration is, you may need to specify which CRAN mirror you want to download the package from before attempting the installation. To do that, include a command like `utils.chooseCRANmirror(ind=1)` to select the first mirror on the list of known servers.]

``` python
utils.install_packages("fortunes")
```

Once installed the fortunes package can be imported, allowing me to call the `fortune()` function from the package:

```{python use-fortunes}
fortunes = pkg.importr("fortunes")
fortune = fortunes.fortune(7)
print(fortune)
```

I'm rather fond of this quote, and it seems very appropriate to the spirit of what polyglot data science is all about. Whatever language or tools we're working in, we've usually chosen them for good reason. But there is no tool that works all the time, nor any language that is ideal for every situation. Sometimes we need something very different, and when we do it is very helpful if our tools able to talk fluently to each other.

Anyway, that's enough rambling. We're now at the point that we can tackle the problem of transferring data from Python to R, but in order to do that we'll need some data...

<br><br>

:::{.column-body-outset}
![This was the header illustration to a story entitled "The Trail of the Serpent" by M. E. Braddon. It was published in the *Molong Express and Western District Advertiser* on 4 August 1906. The moment I saw it I knew I had to include it here. I can hardly omit a serpent reference in a Python post, now can I? That would be grossly irresponsible of me as a tech blogger. [Trove article 139469044](https://trove.nla.gov.au/newspaper/article/139469044)](img/serpent.jpg)
:::

<br><br>

## About the data 

The data set for this post comes from the [To Be Continued](https://cdhrdatasys.anu.edu.au/tobecontinued/) database of fiction published in Australian newspapers during the 19th and early 20th century. Originally collected using the incredibly cool [Trove](https://trove.nla.gov.au/) resource run by the National Library of Australia, it's released under a CC-BY-4.0 licence and maintained by Katherine Bode and Carol Hetherington. The data set I'm using here only contains metadata: the complete database includes full text of all the published pieces, but I don't really need that much data for this simple illustration. 

Let's use [pandas](https://pandas.pydata.org/) to load the data set and inspect the first few rows:

```{python panda-read-csv}
import pandas

fiction = pandas.read_csv("fiction.csv", low_memory = False)
fiction.head()
```

We can take a look at the distribution of nationalities among published authors too. The table below counts the number of distinct publications (Trove IDs) and authors for each nationality represented in the data:

```{python panda-aggregate}
fiction[["Nationality", "Trove ID", "Publication Author"]]. \
  groupby("Nationality"). \
  nunique()
```

Now that we have a sense of the data, let's add Arrow to the mix!

<br><br>

:::{.column-body-outset}
![An illustration from "The Lass That Loved a Miner" by J. Monk Foster. Published in *Australian Town and Country Journal*, 14 April 1894. The story features such fabulous quotes as "Presently the two dark figures slid slowly, noiselessly, along the floor towards the scattered gold dust and he canisters filled with similar precious stuff. Inch by inch, foot by foot the two thieves crept like snakes nearer and nearer to the to the treasure they coveted". Admit it, you're hooked already, right? [Trove article 71212612](https://trove.nla.gov.au/newspaper/article/71212612)](img/darlington.jpg)

:::

<br><br>

## Pandas to Arrow Tables

I'm relatively new to working with Arrow data on the Python side, but I'm pleased to discover that it's straightforward to construct an Arrow Table from a Pandas DataFrame with the help of [PyArrow](https://arrow.apache.org/docs/python/index.html). Here's how we do that:
 
```{python arrow-fiction}
import pyarrow

pyarrow_fiction = pyarrow.Table.from_pandas(fiction)
pyarrow_fiction
```

The output looks about right to me. It's formatted slightly differently from what I expect when I'm working with Arrow Tables in R, but this is most definitely an Arrow Table, displayed according to pyarrow conventions. 

Now that we have our data represented as an Arrow Table, we can move onto the really fun part... seamlessly handing the reins back and forth between Python and R without ever making copies of the data object. 

<br><br>

## Passing Tables from Python to R

To pass Arrow objects between Python and R, rpy2 needs a little help because it doesn't know how to handle Arrow data structures on its own. That's where the [rpy2-arrow module](https://rpy2.github.io/rpy2-arrow/version/main/html/index.html) comes in handy. I'll quote from the package documentation here:

> The package allows the sharing of Apache Arrow data structures (Array, ChunkedArray, Field, RecordBatch, RecordBatchReader, Table, Schema) between Python and R within the same process. The underlying C/C++ pointer is shared, meaning potentially large gain in performance compared to regular arrays or data frames shared between Python and R through the conversion rules included in rpy2. 

As with rpy2 itself, I'm not going to attempt a proper tutorial in this post, and instead just restrict myself to showing you how to solve the problem at hand. We want to first import the conversion tools from rpy_arrow:

```{python import pyra}
import rpy2_arrow.pyarrow_rarrow as pyra
```

Having done that, we use the `pyarrow_table_to_r_table()` function to pass an Arrow Table from Python to R, like so:

```{python use-rpy2-arrow}
rarrow_fiction = pyra.pyarrow_table_to_r_table(pyarrow_fiction)
rarrow_fiction
```

The printed output isn't the prettiest thing in the world, but nevertheless it does represent the object of interest. On the Python side we have `pyarrow_fiction`, a data structure that points to an Arrow Table and enables various compute operations supplied through pyarrow. On the R side we now have `rarrow_fiction`, a data structure that points to the *same* Arrow Table and enables compute operations supplied by the R arrow package. 

<br><br>

:::{.column-body-outset}
![Header illustration to "Where flowers are Rare" by Val Jameson. Published in *The Sydney Mail*, 8 December 1909. [Trove article 165736425](https://trove.nla.gov.au/newspaper/article/165736425)](img/flowers.jpg)
:::

<br><br>

## Accessing the Table from the R side

We're almost done, but the tour isn't really complete until we've stepped out of Python entirely, manipulated the object on the R side, and then passed something back to Python. So let's do that next.

In order to pull off that trick within this quarto document -- which is running jupyter under the hood -- we'll need to use a little notebook magic. The rpy2 module supplies an [interface for interactive work](https://rpy2.github.io/doc/latest/html/interactive.html) that we can enable in a notebook context like this: 

```{python py-dplyr}
%load_ext rpy2.ipython
```

Now that we've done this, all I have to do is preface each cell with `%%R` and the subsequent "Python" code will be passed to R and interpreted there.^[Okay, so some R users might be wondering about what was going on in the last post where I was flipping back and forth between R and Python without apparently doing anything like this. The answer is that when using knitr as the engine (rather than jupyter), python code is automatically interpreted with the help of reticulate. That's already a feature in knitr, so I didn't need to invoke it explicitly.] To start with I'll load the dplyr and arrow packages, using `suppressMessages()` to prevent them being chatty and warning me about namespace masking: 

```{python call-r}
%%R
suppressMessages({
  library(dplyr)
  library(arrow)
})
```

Now that I've done that, I'll use the dplyr/arrow toolkit to do a little data wrangling on the `rarrow_fiction` Table. I'm not doing anything fancy, just a little cross-tabulation counting the joint distribution of genders and nationalities represented in the data using the `count()` function, and using `arrange()` to sort the results. The part that actually matters for our purposes is the first line:

```{python more-r, results='asis'}
%%R -i rarrow_fiction
gender <- rarrow_fiction |> 
  count(Gender, Nationality) |>
  arrange(desc(n)) |>
  compute()
  
gender
```

By using `%%R -i rarrow_fiction` to specify the cell magic, we're able to access the `rarrow_fiction` object from R within this cell and perform the required computations. 

<br><br>

## The journey home

We now have an object in the embedded R session that we might wish to access from the Python session and convert to a Python object: first an Arrow Table and then possibly a Pandas DataFrame. Here's how that process works. If you recall from earlier in the post, we imported `robjects` to start the embedded R session. When we did so, we also exposed `robjects.r`, which provides access to all objects within that R session. For instance, to create a Python object `r_gender` that refers to the R data structure we created in the last section, here's what we'd do:

```{python return-r-to-python}
r_gender = robjects.r('gender')
r_gender
```

Notice that this is the same object. The `r_gender` variable refers to the Arrow Table in R: it's not a pyarrow table. If we want to convert it to a data structure that pyarrow understands, we can use pyra to make the conversion. It supplies an `rarrow_to_py_table()` function that is suitable for our purposes:

```{python convert-gender}
py_gender = pyra.rarrow_to_py_table(r_gender)
py_gender
```

Just like that, we've handed over the Arrow Table from R back to Python. If we really want to, we can now convert this back to a Pandas DataFrame using pyarrow:

```{python pygender-to-panda}
panda_gender = pyarrow.Table.to_pandas(py_gender)
panda_gender
```

And with that the journey is complete!


<br><br>

:::{.column-body-outset}
![Header illustration to "The Black Motor Car" by J. B. Harris Burland. Published in -- just to bring us full circle -- *The Arrow*, 25 November 1905. [Trove article 103450814](https://trove.nla.gov.au/newspaper/article/103450814)   ](img/motorcar.jpg)
:::



## Acknowledgements {.appendix}

In writing this post I am heavily indebted to Isabella Vel√°squez, whose fabulous post on [calling R from Python with rpy2](https://rviews.rstudio.com/2022/05/25/calling-r-from-python-with-rpy2/) helped me immensely. The [documentation on integrating PyArrow with R](https://arrow.apache.org/docs/python/integration/python_r.html) was extremely helpful too!

