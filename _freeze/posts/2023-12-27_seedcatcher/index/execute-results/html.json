{
  "hash": "1efe216b6d0de703b825c9768ffc3e56",
  "result": {
    "markdown": "---\ntitle: \"Fine-grained control of RNG seeds in R\"\ndescription: \"Like, why is 'seedcatcher' not already an R package?\"\ndate: \"2023-12-27\"\n--- \n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\nAh fuck it. So. Earlier this morning I [posted on mastodon](https://hachyderm.io/@djnavarro/111655059799138922) about the sense of sadness I have about the death of turn-of-the-century-yes-this-century blog culture:\n\n> I was reading a thread about how the norms around blog posts have changed over the years, where “writing something up a blog post” now has a kind of formality to it that it didn’t have 20 years ago (yes, I did in fact have a blog in 2003), which in turn makes blogging feel more like work than joy. This seems like a genuine cultural loss. \n\nOnce upon a much happier time, we had a blogging culture where writing a blog post didn't have to be \"A Very Serious Blog Post By A Very Serious Person\". The craft of blogging wasn't built around the idea that blog posts are miniature journal articles. Back then it was understood that a blog post was an inherently ephemeral and rarely serious thing. You'd have an idle thought, spend a small amount of time developing the idea, write it up, and **ET FUCKING VOILA BITCHES I HAVE A BLOG POST**.\n\nI kind of loved that culture. It's precisely in that spirit that I decided, in my last post, to cobble together an absolutely-cursed rethinking of the [blogdown](https://bookdown.org/yihui/blogdown/) R package and write an unapologetically-unhinged [post](https://knitr-11ty.djnavarro.net/posts/the-blogdown-of-theseus/) about it. The \"eleventy plus knitr\" system I built in an afternoon -- following the [Bob Katter principle](https://www.youtube.com/watch?v=1i739SyCu9I) of \"I ain't spending any time on it, because in the meantime, every three months a person's torn to pieces by a crocodile in North Queensland\" -- was a fun toy, and nothing more than that. This is *exactly* what blogs are for, and precisely the reason why the subtitle on that post is \"Because you know what? I *am* here to [fuck spiders](https://www.urbandictionary.com/define.php?term=Not%20here%20to%20Fuck%20Spiders)\". The entire purpose of blogging is to have some fun and build a community^[One of the most cursed things that has happened to public tech culture is the idea of corporate-style \"community\". Oh look at me, I'm a tHouGHt lEaDer iN tEcH blah blah blah. Honey, if I wanted to masturbate in public there are much easier ways to make men pay to watch me do it.] of people who want to have fun writing.\n\nSo let's fuck some spiders.\n\n## Managing computational state when generating pseudo-random numbers\n\nThe spider I'm thinking about today relates to the problem of generating pseudo-random numbers in a reproducible way. Generating a sequence of numbers that satisfy formal definitions of randomness is an inherently tricky business and programming languages have a very, ummmmm, mixed track record in finding ways to do it sanely. The core of the problem lies in the fact that computers are Turing machines, and as such are deterministic systems. You can't make a deterministic system behave \"randomly\" without doing quite a bit of mathematical work to (a) decide what \"randomly\" means in this context and, (b) constructing algorithms that produce behaviour that we are willing to describe as \"random\". Fortunately for us, this part of the problem was solved a long time ago, and I have no desire whatsoever to use this post to discuss the [Mersenne Twister](https://en.wikipedia.org/wiki/Mersenne_Twister) in relation to [Martin-Löf randomness](https://en.wikipedia.org/wiki/Algorithmically_random_sequence).^[No seriously. I spent a solid six months of my mid-20s life reading journal articles about algorithmic randomness and its relationships to Kolmogorov complexity and Bayesian inference, when instead I could have spent that time going full femboy and it was a terrible fucking decision.] The algorithm is good enough for my purposes, it's implemented as a random number generator (usually one of many) in various language, and that is *fine*.\n\nThe tricky part, from a practical perspective, is that pseudo-random number generators are [stateful](https://en.wikipedia.org/wiki/State_(computer_science)) entities that depend on a \"random number generator seed\", and -- by design! -- they are spectacularly sensitive to the seed. If you do even the tiniest thing in your code that touches the RNG seed, *every* subsequent action that uses that RNG will be changed in fundamental ways. If you want to program carefully around random number generators, you need to be super careful with managing the RNG seed.\n\nAh fuck it. [Dua Lipa](https://www.youtube.com/watch?v=suAR1PYFNYA) already said it better:\n\n> I come and I go <br>\nTell me all the ways you need me <br>\nI'm not here for long <br>\nCatch me or I go Houdini <br>\nI come and I go <br>\nProve you got the right to please me <br>\nEverybody knows <br>\nCatch me or I go Houdini\n\nFrom a reproducible computing perspective, you'd better catch the RNG state and work carefully with it, or else it will be gone forever. \n\n## How do different languages manage RNG state? A half-arsed review of bad solutions to a hard problem\n\n\n## \"Solving\" the problem in 19 lines of code\n\nThe R6 package is a goddamn delight:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSeed <- R6::R6Class(\"Seed\",\n  public = list(\n    initialize = function(...) {\n      old <- .Random.seed\n      set.seed(...)\n      self$state <- eval(.Random.seed, envir = .GlobalEnv)\n      assign(\".Random.seed\", old, envir = .GlobalEnv)\n    },\n    state = NULL,\n    use = function(expr, envir = parent.frame()) {\n      old <- .Random.seed\n      assign(\".Random.seed\", self$state, envir = .GlobalEnv)\n      x <- eval(substitute(expr), envir = envir)\n      self$state <- eval(.Random.seed, envir = .GlobalEnv)\n      assign(\".Random.seed\", old, envir = .GlobalEnv)\n      return(x)\n    }\n  )\n)\n```\n:::\n\n\nLo and fucking behold bitch...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nold <- .Random.seed\nx <- Seed$new(1)\ny <- Seed$new(1)\nx$use(sample(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  9  4  7  1  2  5  3 10  6  8\n```\n:::\n\n```{.r .cell-code}\ny$use(sample(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  9  4  7  1  2  5  3 10  6  8\n```\n:::\n\n```{.r .cell-code}\nx$use(sample(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  3  1  5  8  2  6 10  9  4  7\n```\n:::\n\n```{.r .cell-code}\ny$use(sample(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  3  1  5  8  2  6 10  9  4  7\n```\n:::\n\n```{.r .cell-code}\nall.equal(old, .Random.seed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}