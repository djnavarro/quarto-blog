{
  "hash": "60d07e74d16b84777bf364b33454d2a3",
  "result": {
    "markdown": "---\ntitle: \"Population pharmacokinetic models\"\ndescription: \"In which the author works her way through an online tutorial and takes notes\"\ndate: \"2023-06-05\"\ncategories: [\"Statistics\", \"Pharmacokinetics\", \"R\"]\nimage: cover.png\nimage-alt: \"A 4x4 grid of scatter plots, each showing data that rise and then fall, with grey lines showing model predictions\"\n---\n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\nThe [Population Approach Group of Australia and New Zealand](https://www.paganz.org/) host some useful [resources](https://www.paganz.org/resources/) for folks interested in pharmacometric modelling. Specifically they have a series of workshops are pretty handy. There's a beginner workshop in 2019 that covers the core approach, and then two intermediate workshops in 2021 and 2022. I'll work through the [2019 workshop materials](https://www.paganz.org/wp-content/uploads/2016/06/PAWs-Beginners-2019.zip) in this blog post, translating the code from NONMEM to Stan and R as needed.\n\n## The warfarin data set\n\n### Parsing the data\n\nLoad the data. The csv file uses `\".\"` to specify missing values, which I'll need to state explicitly when reading the data into R, thereby ensuring numeric variables end up as numeric:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwarfpk <- readr::read_csv(\"warfpk.csv\", na = \".\", show_col_types = FALSE)\nwarfpk\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 289 × 10\n   `#ID`  time    wt   age   sex   amt  rate  dvid    dv   mdv\n   <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 0       0    66.7    50     1   100    -2     0  NA       1\n 2 0       0.5  66.7    50     1    NA    NA     1   0       0\n 3 0       1    66.7    50     1    NA    NA     1   1.9     0\n 4 0       2    66.7    50     1    NA    NA     1   3.3     0\n 5 0       3    66.7    50     1    NA    NA     1   6.6     0\n 6 0       6    66.7    50     1    NA    NA     1   9.1     0\n 7 0       9    66.7    50     1    NA    NA     1  10.8     0\n 8 0      12    66.7    50     1    NA    NA     1   8.6     0\n 9 0      24    66.7    50     1    NA    NA     1   5.6     0\n10 0      36    66.7    50     1    NA    NA     1   4       0\n# ℹ 279 more rows\n```\n:::\n:::\n\n\nThe first column name is a little awkward for R, and ordinarily I'd use `janitor::clean_names()` to tidy them, but in this case it's just one column to rename so I'll use dplyr:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwarfpk <- warfpk |> dplyr::rename(id = `#ID`)\nwarfpk\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 289 × 10\n   id     time    wt   age   sex   amt  rate  dvid    dv   mdv\n   <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 0       0    66.7    50     1   100    -2     0  NA       1\n 2 0       0.5  66.7    50     1    NA    NA     1   0       0\n 3 0       1    66.7    50     1    NA    NA     1   1.9     0\n 4 0       2    66.7    50     1    NA    NA     1   3.3     0\n 5 0       3    66.7    50     1    NA    NA     1   6.6     0\n 6 0       6    66.7    50     1    NA    NA     1   9.1     0\n 7 0       9    66.7    50     1    NA    NA     1  10.8     0\n 8 0      12    66.7    50     1    NA    NA     1   8.6     0\n 9 0      24    66.7    50     1    NA    NA     1   5.6     0\n10 0      36    66.7    50     1    NA    NA     1   4       0\n# ℹ 279 more rows\n```\n:::\n:::\n\n\nThere's one slightly puzzling thing here: the `id` column looks like it's supposed to be a numeric id for the study participants, but it's been parsed as a character vector. That's usually a sign that there's a problem somewhere in the data. A bit of digging reveals there's something peculiar going on with subject 12:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwarfpk |> dplyr::filter(id |> stringr::str_detect(\"12\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 × 10\n   id     time    wt   age   sex   amt  rate  dvid    dv   mdv\n   <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 12      0    75.3    32     1   113    -2     0  NA       1\n 2 12      1.5  75.3    32     1    NA    NA     1   0.6     0\n 3 #12     3    75.3    32     1    NA    NA     1   2.8     0\n 4 12      6    75.3    32     1    NA    NA     1  13.8     0\n 5 12      9    75.3    32     1    NA    NA     1  15       0\n 6 12     24    75.3    32     1    NA    NA     1  10.5     0\n 7 12     36    75.3    32     1    NA    NA     1   9.1     0\n 8 12     48    75.3    32     1    NA    NA     1   6.6     0\n 9 12     72    75.3    32     1    NA    NA     1   4.9     0\n10 12     96    75.3    32     1    NA    NA     1   2.4     0\n11 12    120    75.3    32     1    NA    NA     1   1.9     0\n```\n:::\n:::\n\n\nIt's easy enough to remove the `#` character and convert the id variable to numeric:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwarfpk <- warfpk |> \n  dplyr::mutate(\n    id = id |> \n      stringr::str_remove_all(\"#\") |> \n      as.numeric()\n  )\nwarfpk\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 289 × 10\n      id  time    wt   age   sex   amt  rate  dvid    dv   mdv\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     0   0    66.7    50     1   100    -2     0  NA       1\n 2     0   0.5  66.7    50     1    NA    NA     1   0       0\n 3     0   1    66.7    50     1    NA    NA     1   1.9     0\n 4     0   2    66.7    50     1    NA    NA     1   3.3     0\n 5     0   3    66.7    50     1    NA    NA     1   6.6     0\n 6     0   6    66.7    50     1    NA    NA     1   9.1     0\n 7     0   9    66.7    50     1    NA    NA     1  10.8     0\n 8     0  12    66.7    50     1    NA    NA     1   8.6     0\n 9     0  24    66.7    50     1    NA    NA     1   5.6     0\n10     0  36    66.7    50     1    NA    NA     1   4       0\n# ℹ 279 more rows\n```\n:::\n:::\n\n\nThat said... even more digging revealed that the `#` character appears to be serving a specific function when used as a prefix in this data file. Later on, it turns out that the NONMEM control file used to specify the model for these data uses the following line to specify the data:\n\n``` fortran\n$DATA ..\\warfpk.csv IGNORE=#\n```\n\nThis instruction indicates that lines with the prefix `#` are ignored. What I'm guessing here is that this observation was dropped from the data set in the tutorial for some reason. It's not obvious to me why that was the case. It's possible, then, that what I should be doing instead is filtering out that row in the data. \n\n### Interpreting the data\n\nThe csv file doesn't say give much information about the variables. However, digging into the output files included in the workshop reveals the citations for the original papers. The data originate in papers by O'Reilly and colleagues, published in 1963 and 1968. Both papers are available online in full text, and after reading through them, we can reverse engineer (most of!) a data dictionary:\n\n- `id`: Numeric value specifying the arbitrary identifier for each person\n- `time`: Time elapsed since dose was administered (in hours)\n- `wt`: Weight of each person (in kilograms)\n- `age`: Age of each person (in years)\n- `sex`: Biological sex of each person (0 = female, 1 = male)^[Technically I'm guessing the code here, but there's a lot more 1s in the data than 0s, and a lot more of male subjects reported by O'Reilly & Aggeler, so it seems a safe bet!]\n- `amt`: Dose administered to this person at this time point (in milligrams)\n- `rate`: Uncertain what this refers to, but it has value -2 when drug is administered and missing otherwise\n- `dvid`: Appears to be a dummy variable indicating whether the dependent variable was measured at this time point (0 = false, 1 = true)\n- `dv`: Measured value of the dependent variable (plasma warfarin concentration, in mg/L)\n- `mdv`: Appears to be a dummy variable that is the reverse of `dvid`, and is presumably an indicator variable whose meaning is \"missing dependent variable\" (0 = false, 1 = true)\n\nWe can see the dosing information by filtering the data on `dvid`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwarfpk |> dplyr::filter(dvid == 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 32 × 10\n      id  time    wt   age   sex   amt  rate  dvid    dv   mdv\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     0     0  66.7    50     1   100    -2     0    NA     1\n 2     1     0  66.7    50     1   100    -2     0    NA     1\n 3     2     0  66.7    31     1   100    -2     0    NA     1\n 4     3     0  80      40     1   120    -2     0    NA     1\n 5     4     0  40      46     0    60    -2     0    NA     1\n 6     5     0  75.3    43     1   113    -2     0    NA     1\n 7     6     0  60      36     0    90    -2     0    NA     1\n 8     7     0  90      41     1   135    -2     0    NA     1\n 9     8     0  50      27     0    75    -2     0    NA     1\n10     9     0  70      28     1   105    -2     0    NA     1\n# ℹ 22 more rows\n```\n:::\n:::\n\n\nSimilarly we can see the data from a single person by filtering on `id`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwarfpk |> dplyr::filter(id == 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 10\n     id  time    wt   age   sex   amt  rate  dvid    dv   mdv\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1     1     0  66.7    50     1   100    -2     0  NA       1\n2     1    24  66.7    50     1    NA    NA     1   9.2     0\n3     1    36  66.7    50     1    NA    NA     1   8.5     0\n4     1    48  66.7    50     1    NA    NA     1   6.4     0\n5     1    72  66.7    50     1    NA    NA     1   4.8     0\n6     1    96  66.7    50     1    NA    NA     1   3.1     0\n7     1   120  66.7    50     1    NA    NA     1   2.5     0\n```\n:::\n:::\n\n\n### Plotting the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nwarfpk |> \n  dplyr::filter(\n    dvid == 1, # only include measured times\n    !is.na(dv) # ignore missing dv cases\n  ) |>\n  ggplot(aes(x = time, y = dv, group = id)) + \n    geom_line(color = \"grey50\") +\n    geom_point() +\n    labs(\n      x = \"Time since dose (hours)\", \n      y = \"Plasma concentration (mg/L)\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/warfarin-data-1.png){width=672}\n:::\n:::\n\n\n## Deciphering NONMEM specifications\n\n### Notation from NONMEM\n\nThe original workshop is designed to be conducted using [NONMEM](https://www.iconplc.com/solutions/technologies/nonmem/), and I've been told to expect that notation used by NONMEM is pretty standard in the field, so I'll try my very best to stick to that notation. The two tutorial papers by Bauer (2019) were helpful for me in figuring this out, as was the older paper by Bauer et al (2007) that is a little more explicit about the statistical formulation of the models. As far as I can tell from the notation in the 2007 paper, the following structural conventions are applied:\n\n- Italicised lower case Greek symbols refer to scalar parameters: $\\theta$, $\\omega$, $\\sigma$, etc\n- Boldfaced upper case Greek symbols denote parameter vectors: $\\boldsymbol\\theta$, $\\boldsymbol\\omega$, $\\boldsymbol\\sigma$, etc\n- Boldfaced upper case Greek symbols denote parameter matrices: $\\boldsymbol\\Theta$, $\\boldsymbol\\Omega$, $\\boldsymbol\\Sigma$, etc\n\nThere is also a convention assigning meaning to the different Greek letters:\n \n- Population mean parameters are denoted $\\theta$\n- Population variance parameters are denoted $\\omega$\n- Individual departures from population mean and for $i$-th individual, $\\eta_i$\n- Standard deviation of error terms is denoted $\\sigma$ (i.e., variance $\\sigma^2$)\n- Difference between individual subject expected value and observation, $\\epsilon_{ij}$`\n\nAs an example, consider a simple one-compartment IV bolus model with first-order elimination, given dose $D$. If we let the function $f(t, k, V)$ denote the function describing how drug concentration changes as a function of time $t$, elimination rate $k$, and volume of distribution $V$. For this model, \n\n$$\nf(t, k, V, D) = \\frac{D}{V} \\exp(-kt)\n$$\n\nIn this model, the measurement time $t$ and dose $D$ (administered at $t = 0$) are both part of the study design. The other two quantities $k$ and $V$, are model parameters that can be different for every person. At a population level, then we will have a parameter vector $\\boldsymbol{\\theta} = (\\theta_1, \\theta_2)$ where I'll somewhat arbitrarily say that $\\theta_1$ is the typical value for $k$, and $\\theta_2$ is the typical value for $V$. Since these quantities can vary from person to person, we would also -- assuming for the sake of simplicity that there is no population correlation between them^[If we wanted to consider this correlation then we'd have a full variance-covariance matrix denoted $\\boldsymbol\\Omega$, but I'm not going to go there in this post] -- have a variance vector $\\boldsymbol{\\omega} = (\\omega_1, \\omega_2)$. \n\nIn this scenario, then, the parameters for the i-th participant would be some function of the typical values $\\theta$ and the random effects $\\eta$. For the moment I'll just use $g_1()$ and $g_2()$ to denote these transformation functions:\n\n$$\n\\begin{array}{rcl}\nk_i &=& g_1(\\theta_1, \\eta_{i1}) \\\\\nV_i &=& g_2(\\theta_2, \\eta_{i2})\n\\end{array}\n$$\nwhere the random effect terms $\\eta_{ik}$ are presumed to be normally distributed:\n\n$$\n\\eta_{ik} \\sim \\mbox{Normal}(0, \\omega_k) \n$$\n\nNext we have our pharmacokinetic function $f()$ that specifies how the plasma concentration changes as a function of time, dose, and the model parameters. Earlier I wrote out the specific form of this function for a particular model, but we could refer to it generically as $f(t, \\boldsymbol\\eta_i, \\boldsymbol\\theta, D_i)$.\n\nIf measurement errors are assumed to be additive (I'll come back to that in a moment), the observed concentration $y_{ij}$ for the i-th person at the j-th time point:\n\n$$\ny_{ij} = f(t_j, \\boldsymbol\\eta_i, \\boldsymbol\\theta, D_i) + \\epsilon_{ij}\n$$\n\nwhere $\\epsilon_{ij}$ is the error associated with person i and time j, and\n\n$$\n\\epsilon_{ik} \\sim \\mbox{Normal}(0, \\sigma^2) \n$$\n\nWith that as preliminary exposition, I think I can now make sense of how the model specification in NONMEM works...\n\n\n### Reading a NONMEM control file\n\nLooking at the control file for the model (i.e., the `.ctl` file), there's a bit of effort required for me -- as someone who doesn't use NONMEM -- to work out what structure of the underlying model is. The key line in the control file is the one specifying the subroutines:\n\n``` fortran\n$SUBR ADVAN2 TRANS2\n```\n\nThe workshop notes helpfully explain this. In NONMEM terminology, this refers to two different modules: ADVAN provides a library of pharmacokinetic models that are bundled with the software, and TRANS specifies parameter transformation. Of particular importance: ADVAN2 refers to a one-compartment model with a first order absorption process. Okay that's super handy because I've implemented one of those from scratch in Stan previously! \n\nThe file continues, specifying the pharmacokinetic model (PK) and the error model (ERROR):\n\n``` fortran\n$PK\n\n   ; COVARIATE MODEL\n   TVCL=THETA(1)\n   TVV=THETA(2)\n   TVKA=THETA(3)\n\n   ; MODEL FOR RANDOM BETWEEN SUBJECT VARIABILITY\n   CL=TVCL*EXP(ETA(1))\n   V=TVV*EXP(ETA(2))\n   KA=TVKA*EXP(ETA(3))\n\n   ; SCALE CONCENTRATIONS\n   S2=V\n\n$ERROR\n   Y=F+EPS(1)\n   IPRED=F\n```\n\nMy goal is to re-write this model in Stan, but to do that I need to first express that as a statistical model rather as NONMEM syntax. So let's start at the population level. We have three parameters here:\n\n- A population typical value for the clearance rate CL, denoted TVCL\n- A population typical value for the distribution volume V, denoted TVV\n- A population typical value for the absorption rate KA, denoted TVKA\n\nThe mapping here is straightfoward:\n\n$$\n\\begin{array}{rcl}\n\\mbox{TVCL} &=& \\theta_1 \\\\\n\\mbox{TVV} &=& \\theta_2 \\\\\n\\mbox{TVKA} &=& \\theta_3\n\\end{array}\n$$\n\nNow we consider the individual-subject level. At this level we have three parameters per person. For the i-th person, these parameters are:\n\n- The clearance rate CL$_i$\n- The distribution volume V$_i$\n- The absorption rate KA$_i$\n\nAs usual, the random effect terms $\\eta$ are normally distributed with mean zero and variance $\\omega$, and the $\\theta$ values are considered fixed effects. However, the population level and subject level parameters do not combine additively, they combine multiplicatively. Specifically, the $g(\\theta, \\eta)$ functions for this model are as follows:\n\n$$\n\\begin{array}{rcl}\n\\mbox{CL}_i &=& \\theta_1 \\exp(\\eta_{1i}) \\\\\n\\mbox{V}_i &=& \\theta_2 \\exp(\\eta_{2i}) \\\\\n\\mbox{KA}_i &=& \\theta_3 \\exp(\\eta_{3i})\n\\end{array}\n$$\n\nSo far, so good. This makes sense of most of the model specification, but there are a still some confusing parts that require a bit more digging around to decipher. First off, this strange invocation:\n\n``` fortran\n   ; SCALE CONCENTRATIONS\n   S2=V\n```\n\nThis doesn't make sense unless you know something about the way that NONMEM has implemented the underlying model. In the 1-compartment IV bolus model that I used as my motivating example (previous section), the pharmacokinetic function $f()$ has a closed form expression for the drug *concentration* in the central (only) compartment. However, when you implement a pharmacokinetic model using a system of ordinary differential equations (like I did in an earlier post), the values produced by solving the ODE typically refer to the *amount* of drug in the relevant compartment. To convert these amounts to concentrations you need to scale them, generally by dividing by the volume of said compartment. And thus we have our explanation of the mysterious `S2=V` instruction. The `S2` parameter is the NONMEM scaling parameter for the central compartment. We set this equal to `V`, i.e., the estimated volume parameter for each subject.^[Honestly, I wasn't 100% certain that my interpretation was correct, but eventually I managed to find copies of the NONMEM user manuals online and they explain it there.] \n\nAt last we come to the error model:\n\n``` fortran\n$ERROR\n   Y=F+EPS(1)\n   IPRED=F\n```\n\nThe relevant part here is the line specifying the relationship between the pharmacokinetic function `F`, the error terms `EPS`, and the observed data `Y`. In this case it's additive, exactly in keeping with what I assumed in my toy example:\n\n$$\ny_{ij} = f(t_j, \\boldsymbol\\eta_i, \\boldsymbol\\theta, D_i) + \\epsilon_{ij}\n$$\n\nIt doesn't have to be. In fact, the hands-on exercise in Lecture 2 of the tutorial I'm working through prepares three versions of this model, one with additive error, one with multiplicative error, and one with a hybrid error model that incorporates additive and multiplicative components. But I'll get to that later. \n\nYay! At long last I think I know the model I need to implement...\n\n## Implementation in Stan\n\nLast time around I wrote my ODEs using notation that made sense to me. This time around I'll try to bring my notation a little closer to the terminology used in the NONMEM control file I was working from. There are two drug amounts that we need to keep track of, the amount $\\mbox{A}_g$ in the gut that has not yet been absorbed into systemic circulation, and the amount $\\mbox{A}_c$ currently in circulation (in the central/only compartment). The derivatives of these two quantities with respect to time form a system of differential quations:\n\n\n$$\n\\begin{array}{rcl}\n\\displaystyle \\frac{d\\mbox{A}_g}{dt} &=& -\\mbox{KA} \\times \\mbox{A}_{g} \\\\ \\\\\n\\displaystyle \\frac{d\\mbox{A}_c}{dt} &=& \\displaystyle \\mbox{KA} \\times \\mbox{A}_{g} - \\frac{\\mbox{CL}}{\\mbox{V}} \\ \\mbox{A}_{c}\n\\end{array}\n$$\n\nWhen we implement the full model in Stan what we actually want to model is the drug *concentration* in the central compartment as a function of time, and for that we'll need to solve for $\\mbox{A}_c$. The first step, however, is to write a Stan function that calculates these derivatives:\n\n``` stan\nvector amount_change(real time,\n                     vector state,\n                     real KA,\n                     real CL,\n                     real V) {\n\n    real Ag = state[1]; // gut amount\n    real Ac = state[2]; // central amount\n\n    // compute derivatives\n    vector[2] dadt;\n    dadt[1] = - (KA * Ag);\n    dadt[2] = (KA * Ag) - (CL / V) * Ac;\n\n    return dadt;\n  }\n```\n\nLater, we can pass the `amount_change()` function to one of the Stan ODE solvers.\n\n\n### Handling ragged arrays in Stan\n\nhttps://mc-stan.org/docs/stan-users-guide/ragged-data-structs.html\n\nhttps://mc-stan.org/docs/2_26/functions-reference/slicing-and-blocking-functions.html\n\nFormatting the data for Stan:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwarfpk_obs <- warfpk[warfpk$mdv == 0, ]\nwarfpk_amt <- warfpk[!is.na(warfpk$rate), ]\n\nt_fit <- c(\n  seq(.1, .9, .1),\n  seq(1, 2.75, .25),\n  seq(3, 9.5, .5),\n  seq(10, 23, 1),\n  seq(24, 120, 3)\n)\n\ndat <- list(\n  n_ids = nrow(warfpk_amt),\n  n_tot = nrow(warfpk_obs),\n  n_obs = purrr::map_int(\n    warfpk_amt$id,\n    ~ nrow(warfpk_obs[warfpk_obs$id == .x, ])\n  ),\n  t_obs = warfpk_obs$time,\n  c_obs = warfpk_obs$dv,\n  dose = warfpk_amt$amt,\n  t_fit = t_fit,\n  n_fit = length(t_fit)\n)\n```\n:::\n\n\n\n\n### Building and fitting the model\n\nBlah blah fit model. Show scripts, don't run inside quarto doc...\n\n### Results\n\n\n::: {.cell}\n\n:::\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nres <- tibble::tibble(\n  y = dat$c_obs,\n  y_hat = out_summary$mean[grepl(\"c_pred\", out_summary$variable)],\n  time = warfpk_obs$time,\n  id = warfpk_obs$id\n)\n\nggplot(res, aes(y_hat, y, colour = factor(id))) +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey50\") +\n  geom_point(size = 4, show.legend = FALSE) +\n  facet_wrap(~ factor(id), nrow = 4)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/simple-plot-1.png){width=1536}\n:::\n:::\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\nprd <- tibble::tibble(\n  y = out_summary$mean[grepl(\"c_fit\", out_summary$variable)],\n  q5 = out_summary$q5[grepl(\"c_fit\", out_summary$variable)],\n  q95 = out_summary$q95[grepl(\"c_fit\", out_summary$variable)],\n  id = as.vector((replicate(dat$n_fit, warfpk_amt$id))),\n  time = as.vector(t(replicate(dat$n_ids, dat$t_fit)))\n)\n\nggplot(mapping = aes(time, y)) +\n  geom_ribbon(\n    data = prd, \n    mapping = aes(ymin = q5, ymax = q95),\n    fill = \"grey80\"\n  ) +\n  geom_line(data = prd) + \n  geom_point(\n    mapping = aes(colour = factor(id)), \n    data = res, \n    size = 4, \n    show.legend = FALSE\n  ) +\n  geom_label(\n    data = tibble::tibble(\n      time = 110, \n      y = 17, \n      id = warfpk_amt$id\n    ),\n    aes(label = id)\n  )+ \n  facet_wrap(~ factor(id), nrow = 4) + \n  theme_bw() + \n  theme(\n    strip.text = element_blank(), \n    strip.background = element_blank()\n  ) +\n  labs(\n    x = \"Time (hours)\",\n    y = \"Warfarin plasma concentration (mg/L)\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pk-profiles-1.png){width=1536}\n:::\n:::\n\n\n## Resources\n\n- Bauer, R. J., Guzy, S., & Ng, C. (2007). A survey of population analysis methods and software for complex pharmacokinetic and pharmacodynamic models with examples. *The AAPS Journal, 9*, E60-E83. [doi.org/10.1208/aapsj0901007](https://doi.org/10.1208/aapsj0901007)\n\n- Bauer, R. J. (2019). NONMEM tutorial part I: Description of commands and options, with simple examples of population analysis. *CPT: Pharmacometrics & Systems Pharmacology, 8*(8), 525-537. [doi.org/10.1002/psp4.12404](https://doi.org/10.1002/psp4.12404)\n\n- Bauer, R. J. (2019). NONMEM tutorial part II: Estimation methods and advanced examples. *CPT: Pharmacometrics & Systems Pharmacology, 8*(8), 538-556. [doi.org/10.1002/psp4.12422](https://doi.org/10.1002/psp4.12422)\n\n- Foster, D., Abuhelwa, A. & Hughes, J. (2019). *Population Analysis Using NONMEM Beginners Workshop*. Retrieved from: [www.paganz.org/resources/](https://www.paganz.org/resources/)\n\n- O'Reilly, R. A., & Aggeler, P. M. (1968). Studies on coumarin anticoagulant drugs: initiation of warfarin therapy without a loading dose. *Circulation, 38*(1), 169-177. [doi.org/10.1161/01.CIR.38.1.169](https://doi.org/10.1161/01.CIR.38.1.169)\n\n- O'Reilly, R. A., Aggeler, P. M., & Leong, L. S. (1963). Studies on the coumarin anticoagulant drugs: the pharmacodynamics of warfarin in man. *The Journal of Clinical Investigation, 42*(10), 1542-1551. [doi.org/10.1172%2FJCI104839](https://doi.org/10.1172%2FJCI104839)\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}