{
  "hash": "1a93496d279c3839be3fe5efcf52a469",
  "result": {
    "markdown": "---\ntitle: \"Extracting tables from pdf files with tabulizer\"\ndescription: \"Something nicer than the last post\"\ndate: \"2023-06-16\"\ncategories: [\"R\", \"Data Wrangling\"] \nimage: dimitra-peppa--abBaVOMsBk-unsplash.jpg\nimage-alt: Photo of many small white tables in an outdoor courtyard\n--- \n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\nIn the last post I talked about [something very grim](/dark-times/), and to be honest it's not at all what wanted to be writing about yesterday. My intention when I woke up yesterday was to write about [tabulizer](https://docs.ropensci.org/tabulizer/), an R package you can use to extract tables from a pdf document. This isn't my favourite of data wrangling tasks: pdf is not a very good format in which to store data, but it's awfully common to find yourself in a situation where the data you want to work with exists only as a table in a pdf document. Because this is a thing that happens, it's nice to have tools that make it a little easier. \n\n## To extract a table, we must first create the universe\n\nThe tabulizer package works by supplying bindings to [tabula-java](https://github.com/tabulapdf/tabula-java/), a java library for extracting tables from pdfs. So if you want tabulizer to work in R you need a working installation of Java, and you need to have the [rJava](https://github.com/s-u/rJava) package to provide the R-to-Java bindings. \n\nMy experience in the past has been that getting all this setup can be a bit finicky. Happily for me, I'm on Ubuntu and [Andrew Collier has a blog post](https://datawookie.dev/blog/2018/02/installing-rjava-on-ubuntu/) that walks you through the process step by step. Following his guide, my first step was to install the Java runtime environment and the Java development kit:\n\n``` bash\nsudo apt-get install -y default-jre default-jdk\n```\n\nThis worked smoothly, so I moved onto the next step and ensured that R knows where to find Java:\n\n``` bash\nsudo R CMD javareconf\n```\n\nOnly now is it possible to install the rJava package:\n\n``` r\ninstall.packages(\"rJava\")\n```\n\nAndrew's post suggests that you need to restart RStudio after doing this, so I did that too. Having done so, I could finally install the tabulizer package itself:\n\n``` r\nremotes::install_github(c(\"ropensci/tabulizerjars\", \"ropensci/tabulizer\"))\n```\n\n## Let there be tables\n\nNow that I have the tabulizer package installed, I'll load it along with the other packages I'll be using in this post:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tabulizer)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(janitor)\n```\n:::\n\n\nTo check that it works, I'll need a pdf file to work with. As a convenience, the tabulizer package comes with a bundled \"data.pdf\" file that we can use for this purpose:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npdf_data <- system.file(\"examples\", \"data.pdf\", package = \"tabulizer\")\n```\n:::\n\n\nI've embedded a copy of the \"data.pdf\" file in this post, and as you can see it's very simple test case (by design). The file contains four tables, and only those four tables:\n\n<br>\n<object data=\"data.pdf\" type=\"application/pdf\" width=\"100%\" height=\"500px\" style=\"padding:10px\">\n  <p>Unable to display PDF file. <a href=\"data.pdf\">Download</a> instead.</p>\n</object>\n<br>\n    \nWe can use this data file as a way to check that the package works and does what we expect. The workhorse function in the package is `extract_tables()`. We pass it the path to the pdf file as the first argument, and use the various other arguments to provide details about how the file should be processed. In this case, the only other argument I'll specify is `output = \"data.frame\"`, which tells the `extract_tables()` function to return a list of data frames rather than a list of matrices (the default behaviour). Let's see if it's working:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npdf_tables <- pdf_data |> \n  extract_tables(output = \"data.frame\") |>\n  map(as_tibble)\n\npdf_tables\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n# A tibble: 31 Ã— 10\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n   <dbl> <int> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int>\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4\n# â„¹ 21 more rows\n\n[[2]]\n# A tibble: 6 Ã— 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <chr>  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n3          4.7         3.2          1.3         0.2 setosa \n4          4.6         3.1          1.5         0.2 setosa \n5          5           3.6          1.4         0.2 setosa \n6          5.4         3.9          1.7         0.4 setosa \n\n[[3]]\n# A tibble: 6 Ã— 6\n      X Sepal.Length Sepal.Width Petal.Length Petal.Width Species  \n  <int>        <dbl>       <dbl>        <dbl>       <dbl> <chr>    \n1   145          6.7         3.3          5.7         2.5 virginica\n2   146          6.7         3            5.2         2.3 virginica\n3   147          6.3         2.5          5           1.9 virginica\n4   148          6.5         3            5.2         2   virginica\n5   149          6.2         3.4          5.4         2.3 virginica\n6   150          5.9         3            5.1         1.8 virginica\n\n[[4]]\n# A tibble: 14 Ã— 1\n   supp \n   <chr>\n 1 VC   \n 2 VC   \n 3 VC   \n 4 VC   \n 5 VC   \n 6 VC   \n 7 VC   \n 8 VC   \n 9 VC   \n10 VC   \n11 VC   \n12 VC   \n13 VC   \n14 VC   \n```\n:::\n:::\n\n\nThat looks nice. With very little effort we've extracted all four tables from the pdf file, and returned a list of tibbles containing the data. Yay! ðŸŽ‰\n\n## Wild caught pdf files are trickier to work with\n\nOkay, let's try a harder example. One of the two reports I referred to in yesterdays blog post is a survey of LGBTQ people conducted by [Data For Progress](https://www.dataforprogress.org/). Unlike the test file, it contains additional text that is not part of any table, and the tables within the report have a lot of fancier formatting that isn't present in the test file. I've cached a local copy of the pdf file as \"dfp_lgbtq_survey.pdf\", and you can take a look yourself to see what we're working with this time:\n\n<br>\n<object data=\"dfp_lgbtq_survey.pdf\" type=\"application/pdf\" width=\"100%\" height=\"500px\" style=\"padding:10px\">\n  <p>Unable to display PDF file. <a href=\"dfp_lgbtq_survey.pdf\">Download</a> instead.</p>\n</object>\n<br>\n\nThe data I used in that post comes from question 4, so I'll try to extract the data for that table from the pdf file. This turns out to be a little harder to do. My first attempt tried to automatically pull all the tables from the second page by setting `pages = 2`, and this is what happened: \n\n\n::: {.cell}\n\n```{.r .cell-code}\npdf_file <- \"dfp_lgbtq_survey.pdf\"\nextract_tables(pdf_file, pages = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]\n[1,] \"79\" \"85\" \"82\" \"70\" \"87\" \"89\" \"77\" \"79\" \"83\" \"69\"  \"80\" \n[2,] \"17\" \"12\" \"13\" \"29\" \"7\"  \"6\"  \"19\" \"14\" \"15\" \"27\"  \"17\" \n\n[[2]]\n     [,1]       [,2]      [,3]       [,4]       [,5]    [,6]     [,7]  \n[1,] \"Response\" \"Topline\" \"African\"  \"or\"       \"White\" \"Female\" \"Male\"\n[2,] \"\"         \"\"        \"\"         \"\"         \"\"      \"\"       \"\"    \n[3,] \"\"         \"\"        \"American\" \"Latino/aâ€‹\" \"\"      \"\"       \"\"    \n     [,8]     [,9]          [,10]         [,11] [,12] [,13] [,14] [,15]\n[1,] \"\"       \"\"            \"identify as\" \"\"    \"\"    \"\"    \"\"    \"65+\"\n[2,] \"binary\" \"transgender\" \"\"            \"24\"  \"39\"  \"54\"  \"64\"  \"\"   \n[3,] \"\"       \"\"            \"transgender\" \"\"    \"\"    \"\"    \"\"    \"\"   \n```\n:::\n:::\n\n\nOkay, that's definitely not the data we want. To make this work we're going to have to give `extract_tables()` a little more information. One way to do this is to explicitly specify the `area` of the pdf file that contains the table to be extracted. To that end, it's helpful to first call the `get_page_dims()` function, which gives us the dimensions of each page in the pdf document:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_page_dims(pdf_file)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 595 842\n\n[[2]]\n[1] 595 842\n\n[[3]]\n[1] 595 842\n```\n:::\n:::\n\n\nNow that we have the dimensions for each page we can specify a rectangular region as a vector containing the top, left, bottom and right coordinates of the rectangle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregion <- c(250, 0, 450, 595)\n```\n:::\n\n\nThe command we want looks like this:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmat <- extract_tables(\n  file = pdf_file, \n  pages = 2, \n  guess = FALSE,\n  area = list(region)\n)[[1]]\n```\n:::\n\n\nThis time around, in addition to setting `pages = 2`, we've set `guess = FALSE` in order to stop `extract_tables()` from trying to automatically detect regions containing tabular data, and also passed a list of regions (in this case just the one region) as the `area` argument, thereby telling `extract_tables()` to look in that specific part of the document. \n\nLet's take a look at the result:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmat\n```\n:::\n\n::: {.cell .column-page}\n::: {.cell-output .cell-output-stdout}\n```\n      [,1]                                [,2]      [,3]       [,4]       [,5]    [,6]     [,7]   [,8]     [,9]            [,10]         [,11] [,12] [,13] [,14] [,15]\n [1,] \"\"                                  \"\"        \"Black or\" \"Hispanic\" \"\"      \"\"       \"\"     \"\"       \"\"              \"Does not\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n [2,] \"\"                                  \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"Non-\"   \"Identifies as\" \"\"            \"18-\" \"25-\" \"40-\" \"55-\" \"\"   \n [3,] \"Response\"                          \"Topline\" \"African\"  \"or\"       \"White\" \"Female\" \"Male\" \"\"       \"\"              \"identify as\" \"\"    \"\"    \"\"    \"\"    \"65+\"\n [4,] \"\"                                  \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"binary\" \"transgender\"   \"\"            \"24\"  \"39\"  \"54\"  \"64\"  \"\"   \n [5,] \"\"                                  \"\"        \"American\" \"Latino/â€‹a\" \"\"      \"\"       \"\"     \"\"       \"\"              \"transgender\" \"\"    \"\"    \"\"    \"\"    \"\"   \n [6,] \"Yes, I have considered moving\"     \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"\"       \"\"              \"\"            \"\"    \"\"    \"\"    \"\"    \"\"   \n [7,] \"\"                                  \"27\"      \"24\"       \"28\"       \"27\"    \"26\"     \"20\"   \"44\"     \"43\"            \"24\"          \"41\"  \"28\"  \"18\"  \"17\"  \"17\" \n [8,] \"out of my community or state\"      \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"\"       \"\"              \"\"            \"\"    \"\"    \"\"    \"\"    \"\"   \n [9,] \"No, I have not considered\"         \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"\"       \"\"              \"\"            \"\"    \"\"    \"\"    \"\"    \"\"   \n[10,] \"moving out of my community or\"     \"61\"      \"57\"       \"59\"       \"64\"    \"60\"     \"75\"   \"37\"     \"40\"            \"65\"          \"43\"  \"60\"  \"74\"  \"80\"  \"70\" \n[11,] \"state\"                             \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"\"       \"\"              \"\"            \"\"    \"\"    \"\"    \"\"    \"\"   \n[12,] \"I have already moved out of my\"    \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"\"       \"\"              \"\"            \"\"    \"\"    \"\"    \"\"    \"\"   \n[13,] \"community or state as a result of\" \"5\"       \"6\"        \"4\"        \"3\"     \"3\"      \"3\"    \"13\"     \"8\"             \"4\"           \"8\"   \"4\"   \"2\"   \"1\"   \"9\"  \n[14,] \"anti-LGBTQ+ legislation\"           \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"\"       \"\"              \"\"            \"\"    \"\"    \"\"    \"\"    \"\"   \n[15,] \"Not sure\"                          \"7\"       \"14\"       \"8\"        \"6\"     \"11\"     \"3\"    \"6\"      \"8\"             \"7\"           \"9\"   \"8\"   \"7\"   \"2\"   \"4\"  \n[16,] \"Weighted N\"                        \"1,036\"   \"93\"       \"217\"      \"632\"   \"426\"    \"368\"  \"135\"    \"166\"           \"870\"         \"249\" \"425\" \"186\" \"93\"  \"83\" \n```\n:::\n:::\n\n\n\nIt's not quite organised the way we want, but it's definitely the right data.\n\nEven better, you don't actually have to do all this messing about trying to figure out the precise region containing the table. If you have the [Shiny](https://shiny.posit.co/) and [miniUI](https://github.com/rstudio/miniUI) packages installed, you can work interactively using a command like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_areas(\"dfp_lgbtq_survey.pdf\", pages = 2)\n```\n:::\n\n\nAfter using click and drag to select the region of the page containing the table, R returns the same data contained in the `mat` matrix shown earlier. \n\n\n## Cleaning the table\n\nOnce we have the data in this matrix form, it's slightly tedious to wrangle it into the format we want, but it's not conceptually difficult once we have a few helper functions to make our lives easier. The first step is to split the matrix into a list of matrices, each of which contains the data that should belong in a single row of the final data set. The `row_split()` function below takes a matrix as input, and splits it up into a list of matrices specified by the list argument `rows`, where each element of `rows` is a vector containing the indices of the rows that should be included in the relevant element of the output: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nrow_split <- function(x, rows) {\n  lapply(rows, \\(r) {\n    if(length(r) == 1) return(matrix(x[r, ], nrow = 1))\n    x[r, ]\n  })\n}\ngroups <- list(1:5, 6:8, 9:11, 12:14, 15, 16)\n\nmat_split <- row_split(mat, rows = groups)\nmat_split\n```\n:::\n\n::: {.cell .column-page}\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n     [,1]       [,2]      [,3]       [,4]       [,5]    [,6]     [,7]   [,8]     [,9]            [,10]         [,11] [,12] [,13] [,14] [,15]\n[1,] \"\"         \"\"        \"Black or\" \"Hispanic\" \"\"      \"\"       \"\"     \"\"       \"\"              \"Does not\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n[2,] \"\"         \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"Non-\"   \"Identifies as\" \"\"            \"18-\" \"25-\" \"40-\" \"55-\" \"\"   \n[3,] \"Response\" \"Topline\" \"African\"  \"or\"       \"White\" \"Female\" \"Male\" \"\"       \"\"              \"identify as\" \"\"    \"\"    \"\"    \"\"    \"65+\"\n[4,] \"\"         \"\"        \"\"         \"\"         \"\"      \"\"       \"\"     \"binary\" \"transgender\"   \"\"            \"24\"  \"39\"  \"54\"  \"64\"  \"\"   \n[5,] \"\"         \"\"        \"American\" \"Latino/â€‹a\" \"\"      \"\"       \"\"     \"\"       \"\"              \"transgender\" \"\"    \"\"    \"\"    \"\"    \"\"   \n\n[[2]]\n     [,1]                            [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]\n[1,] \"Yes, I have considered moving\" \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n[2,] \"\"                              \"27\" \"24\" \"28\" \"27\" \"26\" \"20\" \"44\" \"43\" \"24\"  \"41\"  \"28\"  \"18\"  \"17\"  \"17\" \n[3,] \"out of my community or state\"  \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n\n[[3]]\n     [,1]                            [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]\n[1,] \"No, I have not considered\"     \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n[2,] \"moving out of my community or\" \"61\" \"57\" \"59\" \"64\" \"60\" \"75\" \"37\" \"40\" \"65\"  \"43\"  \"60\"  \"74\"  \"80\"  \"70\" \n[3,] \"state\"                         \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n\n[[4]]\n     [,1]                                [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]\n[1,] \"I have already moved out of my\"    \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n[2,] \"community or state as a result of\" \"5\"  \"6\"  \"4\"  \"3\"  \"3\"  \"3\"  \"13\" \"8\"  \"4\"   \"8\"   \"4\"   \"2\"   \"1\"   \"9\"  \n[3,] \"anti-LGBTQ+ legislation\"           \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n\n[[5]]\n     [,1]       [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]\n[1,] \"Not sure\" \"7\"  \"14\" \"8\"  \"6\"  \"11\" \"3\"  \"6\"  \"8\"  \"7\"   \"9\"   \"8\"   \"7\"   \"2\"   \"4\"  \n\n[[6]]\n     [,1]         [,2]    [,3] [,4]  [,5]  [,6]  [,7]  [,8]  [,9]  [,10] [,11] [,12] [,13] [,14] [,15]\n[1,] \"Weighted N\" \"1,036\" \"93\" \"217\" \"632\" \"426\" \"368\" \"135\" \"166\" \"870\" \"249\" \"425\" \"186\" \"93\"  \"83\" \n```\n:::\n:::\n\n\nThe second helper function is `col_paste()` which takes a matrix with one or more rows as input and collapses it to a vector by pasting the contents of all cells in the same column together:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncol_paste <- function(x, ...) {\n  apply(x, 2, \\(y) {as.vector(paste(y, ...))})\n}\n```\n:::\n\n\nTo illustrate the idea, let's take `mat_split[[1]]`, a five-row matrix that contains the data that should eventually become our column names, and convert it to a character vector using `col_paste()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncol_paste(mat_split[[1]], collapse = \" \")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"  Response  \"                      \n [2] \"  Topline  \"                       \n [3] \"Black or  African  American\"       \n [4] \"Hispanic  or  Latino/â€‹a\"            \n [5] \"  White  \"                         \n [6] \"  Female  \"                        \n [7] \"  Male  \"                          \n [8] \" Non-  binary \"                    \n [9] \" Identifies as  transgender \"      \n[10] \"Does not  identify as  transgender\"\n[11] \" 18-  24 \"                         \n[12] \" 25-  39 \"                         \n[13] \" 40-  54 \"                         \n[14] \" 55-  64 \"                         \n[15] \"  65+  \"                           \n```\n:::\n:::\n\n\nFinally, we can use the `row_combine()` function below that takes a list of vectors and combines them into a matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrow_combine <- function(x, ...) {\n  matrix(unlist(x), nrow = length(x), byrow = TRUE)\n}\n```\n:::\n\n\nEquipped with these helpers, the following pipeline takes the raw output `mat` and converts it into a tibble `dat` containing the data in the format we want it to be:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- mat |> \n  row_split(groups) |>                         # split into list of matrices\n  map(\\(x) {col_paste(x, collapse = \" \")}) |>  # paste into character vector\n  row_combine() |>                             # combine vectors into one matrix\n  as_tibble(.name_repair = \"minimal\") |>       # convert to tibble\n  row_to_names(row_number = 1) |>              # use first row as names\n  clean_names() |>                             # clean the names\n  rename(                                      # shorten some names\n    \"black\" = \"black_or_african_american\",\n    \"hispanic\" = \"hispanic_or_latino_a\", \n    \"trans\" = \"identifies_as_transgender\",\n    \"not_trans\" = \"does_not_identify_as_transgender\"\n  ) |>\n  mutate(across(!response, \\(x) {as.numeric(gsub(\",\", \"\", x))})) # numeric data\n\ndat\n```\n:::\n\n::: {.cell .column-page}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã— 15\n  response                        topline black hispanic white female  male non_binary trans not_trans x18_24 x25_39 x40_54 x55_64   x65\n  <chr>                             <dbl> <dbl>    <dbl> <dbl>  <dbl> <dbl>      <dbl> <dbl>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>\n1 Yes, I have considered moving â€¦      27    24       28    27     26    20         44    43        24     41     28     18     17    17\n2 No, I have not considered moviâ€¦      61    57       59    64     60    75         37    40        65     43     60     74     80    70\n3 I have already moved out of myâ€¦       5     6        4     3      3     3         13     8         4      8      4      2      1     9\n4 Not sure                              7    14        8     6     11     3          6     8         7      9      8      7      2     4\n5 Weighted N                         1036    93      217   632    426   368        135   166       870    249    425    186     93    83\n```\n:::\n:::\n\n\nEt voilÃ !\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}