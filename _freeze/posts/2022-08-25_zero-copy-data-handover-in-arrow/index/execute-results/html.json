{
  "hash": "c391dc133e07783ca6a68d1d4a5f6d2a",
  "result": {
    "markdown": "---\ntitle: \"Passing Arrow Tables between R and Python with reticulate\"\ndescription: \"A neat trick\"\ndate: \"2022-08-28\"\ncategories: [Apache Arrow, R, Python]\nimage: \"img/cover.jpg\"\nengine: knitr\n---\n\n\n<!-- \ncover img: https://unsplash.com/photos/k39RGHmLoV8\nartist: Claudio Schwarz\nlicence: unsplash free-to-use \n-->\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n\n\n<!-- \nthe default python environment is this one:\n/home/danielle/.local/share/r-miniconda/envs/r-reticulate/bin/python\n--->\n\nAs the 21st century gears up for its quarter-life crisis, the trend in data science is toward multi-language tools. I use [quarto](https://quarto.org/) to write this blog, a document preparation system that supports code evaluation in R, Python, Julia, and more. My work revolves around [Apache Arrow](https://arrow.apache.org/), a toolbox for data analysis and interchange with implementations in multiple languages. You get the idea. In one sense this new development is fantastic -- your language of choice is much more likely to be supported in the future than it ever was in the past. In another sense it is daunting -- it sometimes feels like we need to learn *all the things* in order to get by in this brave new world. Meanwhile we all have our actual jobs to do and we don't have the time. In the [immortal words of Bob Katter](https://www.youtube.com/watch?v=1i739SyCu9I),\n\n> I mean, you know, people are entitled to their sexual proclivities. Let there be a thousand blossoms bloom as far as I'm concerned, you know... \n>\n> &nbsp; &nbsp; &nbsp; [*pauses, expression turns dark*]\n>\n> ...but I ain't spending any time on it because, in the meantime, every three months a person is torn to pieces by a crocodile in North Queensland\n\nI mean, he makes a good point?^[A good point about data science, that is. I'm not convinced it was a stellar contribution to the discussion of LGBT rights in the antipodes. Although frankly it wasn't the worst comment on same sex marriage I saw an Australian politician make at the time, not by a loooooong margin.] There's a lot going on in the data science world, none of us can keep pace with all of it, and we're all trying our best not to be eaten by crocodiles. \n\n## Data interchange in a polyglot world\n\nIn the spirit of saving you from at least one reptilian threat, this post is a quick primer on how to efficiently pass control of a large data set between R and Python *without* making any wasteful copies of the data. The idea to write this post came from a [twitter thread by Cass Wilkinson Saldaña](https://twitter.com/mxcatnap/status/1559991199494279169), and in particular a [reply by Jon Keane](https://twitter.com/jonkeane/status/1560016227824721920) who mentioned that Apache Arrow provides a handy toolkit for doing this that isn't as widely known as it perhaps deserves to be! \n\n\n## Using reticulate to call Python from R\n\nThe solution to the problem relies fundamentally on [the {reticulate} package](https://rstudio.github.io/reticulate/)...\n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\nlibrary(reticulate)\n```\n:::\n\n\nThe {reticulate} package has an elaborate lookup mechanism that it uses to find a python environment. In this post and the next I want to make sure that I'm always using the *same* python environment regardless of whether my underlying quarto engine is knitr or jupyter. This is tricky because -- thanks to the nightmare that is python environment management -- I've managed to accrue four different versions of python on my machine, and (don't ask me how) two separate copies of miniconda!\n\nRather than mess with paths, what I'm going to do in this post is be extremely specific. I'm going to make a point of *always* telling {reticulate} where to look in order to find python and miniconda. \n\nOkay, so the specific python environment I want to use is managed by miniconda, so I'm going to use the `use_miniconda()` command to tell {reticulate} to use it. To avoid all ambiguity I'm going to use the `condaenv` argument to explicitly specify the path to the python executable:\n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\nuse_miniconda(\n  condaenv = \"/home/danielle/miniconda3/bin/python\", \n  required = TRUE\n)\n```\n:::\n\n\nWhen calling python code from within R, some translation is necessary. As a simple example, let's say I have my regular python session open and I want to check what version of python I am running and show the path to the python executable. To do this in native python code I'd use the {sys} library:\n\n\n::: {.cell filename='[python code]'}\n\n```{.python .cell-code}\nimport sys\nprint(sys.version)\nprint(sys.executable)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3.9.12 (main, Apr  5 2022, 07:05:27) \n[GCC 7.5.0]\n/home/danielle/miniconda3/bin/python\n```\n:::\n:::\n\n\nTo do this in R, the code is essentially the same except that the `import()` function supplied by {reticulate} replaces the `import` keyword, and `$` replaces `.` as the accessor: \n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\nsys <- import(\"sys\")\nsys$version\nsys$executable\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"3.9.12 (main, Apr  5 2022, 07:05:27) \\n[GCC 7.5.0]\"\n[1] \"/home/danielle/miniconda3/bin/python\"\n```\n:::\n:::\n\n\nPython functions supplied through reticulate can be used in conjunction with regular R code. As a simple example, let's say I wanted to use the [python {art} library](https://pypi.org/project/art/) to generate text decorations. It contains a `decor()` function that creates cute glyphs like this:\n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\nart <- import(\"art\")\nart$decor(\"heart9\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"´*•.¸(*•.¸♥¸.•*´)¸.•*´\"\n```\n:::\n:::\n\n\nTo illustrate the interoperability between R and Python, let's say I want to create a modified version of the `decor()` function. The original `decor()` function takes a single string specifying the name of a glyph. That string could be `\"heart9\"`, `\"wave3\"`, or anything other pattern known to the `decor()` function. You can only pass one string: it does not accept vectors. What I'd like to do in a modified version is pass a numeric vector as input, and receive a vector of heart glyphs as output. Although the original `decor()` function is written in Python, I can do this entirely on the R side: I don't have to write any Python code.\n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\ndecor_heart <- function(x) {\n  purrr::map_chr(x, ~ art$decor(paste0(\"heart\", .x)))\n}\ndecor_heart(1:9)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"~~<💚>~~\"               \"~~><~~>💖\"              \"─═ڿڿۣڿ═─💖─═ڿڿۣڿ═─\"      \n[4] \"༺♥༻❀༺♥༻💕﻿\"              \"💗💜.¸¸.•´¯`☆ºஇ•´♥\"     \"-♥-♡--^[\"              \n[7] \"*•.¸♡\"                  \"╚»♡«╝\"                  \"´*•.¸(*•.¸♥¸.•*´)¸.•*´\"\n```\n:::\n:::\n\n\nPrettiness! 😍\n\n## R to Pandas\n\nOkay, now that we understand the basics of {reticulate}, let's move on to the task of transferring data between R and Python. \n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\npy_iris <- r_to_py(iris)\npy_iris\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width    Species\n0             5.1          3.5           1.4          0.2     setosa\n1             4.9          3.0           1.4          0.2     setosa\n2             4.7          3.2           1.3          0.2     setosa\n3             4.6          3.1           1.5          0.2     setosa\n4             5.0          3.6           1.4          0.2     setosa\n..            ...          ...           ...          ...        ...\n145           6.7          3.0           5.2          2.3  virginica\n146           6.3          2.5           5.0          1.9  virginica\n147           6.5          3.0           5.2          2.0  virginica\n148           6.2          3.4           5.4          2.3  virginica\n149           5.9          3.0           5.1          1.8  virginica\n\n[150 rows x 5 columns]\n```\n:::\n:::\n\n\nhttps://pandas.pydata.org/\n\nWithin the Python session, an object called `r` has been created: the Pandas DataFrame object is stored as `r.py_iris` \n\n\n::: {.cell filename='[python code]'}\n\n```{.python .cell-code}\niris_means = r.py_iris.groupby(\"Species\").mean()\niris_means\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\nSpecies                                                         \nsetosa             5.006        3.428         1.462        0.246\nversicolor         5.936        2.770         4.260        1.326\nvirginica          6.588        2.974         5.552        2.026\n```\n:::\n:::\n\n\nAs you might hope, this data is accessible from the R session. {reticulate} exposes an object named `py` to the user, and -- surprise, surprise -- objects created in the Python session can be accessed using that object...\n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\npy$iris_means\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n1        5.006       3.428        1.462       0.246\n2        5.936       2.770        4.260       1.326\n3        6.588       2.974        5.552       2.026\n```\n:::\n:::\n\n\n...and by the magic of {reticulate} the Pandas DataFrame is magically interpreted as an R data frame.\n\n## Let's bring Apache Arrow into the mix\n\nSo here's the thing about magic, at least when it comes to code. There comes a point where you need to modify the spell. The example in the previous section looks smooth and seamless because the data set is small. However, it is fundamentally inefficient for the simple reason that a Pandas DataFrame looks different in memory to an R data frame. It's not possible for the two languages to share a single copy of the data because they don't agree on what \"the data\" are. To handover data from R to Python (or vice versa) it is necessary to copy the data set and convert it to a more appropriate format. \n\nWhen the data set is small, this is not a problem. But as your data set grows, it becomes ever more burdensome. These copy-and-convert operations are not cheap. \n\nWouldn't it be nice if R and Python could both agree to represent the data as, oh let's say.... an Arrow Table? On the R side we could interact with it using the {arrow} package, and on the Python side we could interact with it using {pyarrow}. But regardless of which language we're using, the thing in memory would be *exactly* the same... handing over the data set from one language to the other would no longer require any copying. A little metadata would change hands, and that's all. \n\nThat sounds much nicer. \n\n## Installing pyarrow\n\nSo let's do this. \n\nIn the previous example, the R data frame was handled on the Python side by the Pandas module. And as a consequence, you'd imagine that it was pretty important that my Python environment has Pandas installed right? Well, the same is true when passing an Arrow Table: you need to have {pyarrow} installed on the Python side as well as {arrow} installed on the R side. \n\nAs a convenience, the {arrow} package supplies a helper function called `install_pyarrow()` that calls the relevant {reticulate} functions for you, but for the purposes of this post I'll show you the {reticulate} functions. The python environment I'm using in this post is managed by miniconda, so I'll use `conda_install()` to do the work: \n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\nconda_install(\n  packages = \"pyarrow\", \n  envname = \"/home/danielle/miniconda3\", \n  conda = \"/home/danielle/miniconda3/bin/conda\"\n)\n```\n:::\n\n\nIn this code, `packages` is the name of the to-be-installed python module, `envname` is the path to the conda environment, and `conda` is the path to the conda executable. As a general rule you don't need to be this explicit: {reticulate} will find the environment and conda executable for you. I'm being unusually particular in this post, for reasons that will be a little more obvious in the next post.\n\nNext let's import {pyarrow} and check the version:\n\n\n::: {.cell filename='[python code]'}\n\n```{.python .cell-code}\nimport pyarrow\npyarrow.__version__\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'8.0.0'\n```\n:::\n:::\n\n\nBecause life on linux is dark and full of terrors, this didn't actually work for me the first time I tried it and naturally I was filled with despair. Instead of the nice output above, I got an error saying:\n\n```\nlibstdc++.so.6: version `GLIBCXX_3.4.22' not found\n```\n\nAs usual, googling the error message led me to discover I needed to update the relevant library. It turned out to be an easy fix with this command: \n\n\n::: {.cell filename='[at the terminal]'}\n\n```{.bash .cell-code}\nsudo apt-get update\nsudo apt-get install libstdc++6\n```\n:::\n\n\n\n\n## Passing Tables to Python\n\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\n# R\narr <- arrow::arrow_table(iris)\narr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTable\n150 rows x 5 columns\n$Sepal.Length <double>\n$Sepal.Width <double>\n$Petal.Length <double>\n$Petal.Width <double>\n$Species <dictionary<values=string, indices=int8>>\n\nSee $metadata for additional Schema metadata\n```\n:::\n\n```{.r .cell-code}\npy_arr <- reticulate::r_to_py(arr)\npy_arr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npyarrow.Table\nSepal.Length: double\nSepal.Width: double\nPetal.Length: double\nPetal.Width: double\nSpecies: dictionary<values=string, indices=int8, ordered=0>\n----\nSepal.Length: [[5.1,4.9,4.7,4.6,5,...,6.7,6.3,6.5,6.2,5.9]]\nSepal.Width: [[3.5,3,3.2,3.1,3.6,...,3,2.5,3,3.4,3]]\nPetal.Length: [[1.4,1.4,1.3,1.5,1.4,...,5.2,5,5.2,5.4,5.1]]\nPetal.Width: [[0.2,0.2,0.2,0.2,0.2,...,2.3,1.9,2,2.3,1.8]]\nSpecies: [  -- dictionary:\n[\"setosa\",\"versicolor\",\"virginica\"]  -- indices:\n[0,0,0,0,0,...,2,2,2,2,2]]\n```\n:::\n:::\n\n::: {.cell filename='[python code]'}\n\n```{.python .cell-code}\n# python\nr.py_arr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npyarrow.Table\nSepal.Length: double\nSepal.Width: double\nPetal.Length: double\nPetal.Width: double\nSpecies: dictionary<values=string, indices=int8, ordered=0>\n----\nSepal.Length: [[5.1,4.9,4.7,4.6,5,...,6.7,6.3,6.5,6.2,5.9]]\nSepal.Width: [[3.5,3,3.2,3.1,3.6,...,3,2.5,3,3.4,3]]\nPetal.Length: [[1.4,1.4,1.3,1.5,1.4,...,5.2,5,5.2,5.4,5.1]]\nPetal.Width: [[0.2,0.2,0.2,0.2,0.2,...,2.3,1.9,2,2.3,1.8]]\nSpecies: [  -- dictionary:\n[\"setosa\",\"versicolor\",\"virginica\"]  -- indices:\n[0,0,0,0,0,...,2,2,2,2,2]]\n```\n:::\n:::\n\n\n## Passing Tables back to R\n\n\n::: {.cell filename='[python code]'}\n\n```{.python .cell-code}\nboring = pyarrow.array([1,2,3])\nboring\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<pyarrow.lib.Int64Array object at 0x7f2c2fb11d60>\n[\n  1,\n  2,\n  3\n]\n```\n:::\n:::\n\n::: {.cell filename='[R code]'}\n\n```{.r .cell-code}\nreticulate::py$boring\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArray\n<int64>\n[\n  1,\n  2,\n  3\n]\n```\n:::\n:::\n\n\n## Is there a more pythonic solution?\n\nOne thing you'll notice about the framing throughout this post is that \n\n<br><br>\n\n\n\n<!--------------- appendices go here ----------------->\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}