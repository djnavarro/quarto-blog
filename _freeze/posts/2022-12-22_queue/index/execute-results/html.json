{
  "hash": "40b6fd209f8a3aa506379c8cf4cfe80d",
  "result": {
    "markdown": "---\ntitle: \"Queue\"\nauthor:\n  - name: Danielle Navarro\n    url: https://djnavarro.net\n    affiliation: I'm on smoko\n    affiliation-url: https://www.youtube.com/watch?v=j58V2vC9EPc\n    orcid: 0000-0001-7648-6578\ndescription: \"Something something something\"\ndate: \"2022-12-22\"\ncategories: [Parallel Computing, R, Object-Oriented Programming]\nimage: \"\"\n---\n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\nOkay. So I wrote a simple package for [multi-threaded tasks queues in R](https://queue.djnavarro.net) this week. It wasn't intentional, I swear. I was just trying to teach myself how to use the [callr](https://callr.r-lib.org/) package, and making sure I had a solid grasp of encapsulated object-oriented programming with [R6](https://r6.r-lib.org/). Things got a little out of hand. Sorry.\n\nAnd let's be very clear about something at the outset. If you want to do parallel computing in R correctly, you go look at [futureverse.org](https://www.futureverse.org/). The [future](https://future.futureverse.org/) package by Henrik Bengtsson provides a fabulous way to execute R code asynchronously and in parallel. And there are many excellent packages built on top of that, so there's a whole lovely ecosystem there just waiting for you.^[Note to self: Learn [parallelly](https://www.jottr.org/2022/12/05/avoid-detectcores/)] Relatedly, if the reason you're thinking about parallel computing is that you've found yourself with a burning need to analyze terabytes of data with R then babe it might be time to start learning some R workflows using [Spark](https://therinspark.com/), [Arrow](https://blog.djnavarro.net/category/apachearrow), [Kubernetes](https://www.r-bloggers.com/2022/04/wtf-is-kubernetes-and-should-i-care-as-r-user/). It may be time to learn about some of those other eldritch words of power that have figured rather more prominently in my life than one might expect for a simple country girl.^[`kubectl auth can-i create occult-chaos`] \n\nMy little queue package is a personal project. I happen to like it, but you should not be looking at it as an alternative to serious tools.\n\nThat's been said now. Good. We can put aside all pretension.\n\n## What does it do?\n\nLet's say I have a generative art function called `donut()`, based loosely on a [teaching example from my art from code workshop](https://art-from-code.netlify.app/day-1/session-1/#composition). The `donut()` function takes an input `seed`, creates a piece of generative art using ggplot2, and writes the output to an image file. This process takes several seconds to complete on my laptop:\n\n\n\n\n::: {.cell hash='index_cache/html/my-first-donut_78cc3a9337022adc6a85a72fd51f194e'}\n\n```{.r .cell-code}\nlibrary(tictoc)\ntic()\ndonut(seed = 100)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.277 sec elapsed\n```\n:::\n:::\n\n\nHere's the piece, by the way:\n\n![](donut_100.png)\n\nThat's nice and I do like this piece, but generative art is an iterative process and I like to make many pieces at once to help me get a feel for the statistical properties of the system. Waiting five or six seconds for one piece to render is one thing: waiting 8-10 minutes for 100 pieces to render is quite another. So it's helpful if I can do this in parallel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(queue)\n```\n:::\n\n\nHere's how I might do that using queue. I designed the package using R6 classes -- more on that later -- so we'll be working in the \"encapsulated\" object oriented programming style that is more common in other programming languages. The first step is to initialise a [`Queue`](https://queue.djnavarro.net/reference/Queue.html) object, specifying the number of workers we want to use. I'll use six:\n\n\n::: {.cell hash='index_cache/html/my-first-queue_dfc1ff39dc3ddb607ec985d5339378c1'}\n\n```{.r .cell-code}\nqueue <- Queue$new(workers = 6)\n```\n:::\n\n\nWhen I do this, the queue package starts six R sessions for us, and all my computations will be done in those R sessions. Under the hood, all the hard work of managing the R sessions is being done by the wonderful callr package by Gábor Csárdi^[Longtime readers will have noticed that I have become a bit of a fangirl. I swear I'm not stalking him, but like, every time I think... gosh this is a really handy bit of infrastructure tooling, who do I have to thank for this... oh, of course it's bloody Gábor again. Anyway.] -- the only thing that queue does is provide a layer of abstraction and automation to the whole process. \n\nNext, I'll add some tasks to the queue. `Queue` objects have an `add()` method that take a function and a list of arguments, so I can do this to push a task to the queue:\n\n\n::: {.cell hash='index_cache/html/my-first-task_e9d06a818d4aab8856c997131ca80f42'}\n\n```{.r .cell-code}\nqueue$add(donut, args = list(seed = 100))\n```\n:::\n\n\nWhen the queue executes, it will be in a \"first in, first out\" order, so this task will be the first one to be assigned to a worker. Though of course that's no guarantee that it will be the first one to finish!\n\nAnyway, let's load up several more tasks. There's some weird aversion out there to using loops in R, but this isn't one of those situations where we need to worry about unnecessary copying, so I'm going to use a loop:\n\n\n::: {.cell hash='index_cache/html/load-several-tasks_5cc68af5a47beff90603fa0c398907e3'}\n\n```{.r .cell-code}\nfor(s in 101:108) queue$add(donut, list(seed = s))\n```\n:::\n\n\nSo now we have nine tasks loaded onto a queue with six workers. To start it running I call the `run()` method for the queue. By default, all you'd see while the queue is running is a spinner with a progress message telling you how many tasks have completed so far, how many are currently running, and how many are still waiting. But I'll ask it to be a bit more chatty. I'll call it setting `message = \"verbose\"` so that we can see a log showing the order in which the tasks completed and time each task took to complete, in addition to the total time elapsed on my system while the queue was running:\n\n\n::: {.cell hash='index_cache/html/run-my-queue_f0e1b58ef56570b65d67c0ec4ae0c11c'}\n\n```{.r .cell-code}\nout <- queue$run(message = \"verbose\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_5 finished in 3.18 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_2 finished in 5.78 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_6 finished in 5.78 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_4 finished in 7.34 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_3 finished in 8.09 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_1 finished in 9.46 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_7 finished in 7.76 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_9 finished in 6.09 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_8 finished in 6.92 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ Queue complete: 9 tasks done in 12.7 secs\n```\n:::\n:::\n\n\nHere are the nine pieces that popped off the queue in 13 seconds: \n\n::: {.column-screen-inset}\n\n::: {layout-ncol=3}\n\n![](donut_100.png)\n\n![](donut_101.png)\n\n![](donut_102.png)\n\n![](donut_103.png)\n\n![](donut_104.png)\n\n![](donut_105.png)\n\n![](donut_106.png)\n\n![](donut_107.png)\n\n![](donut_108.png)\n\n:::\n:::\n\nSo it's a three-step process: (1) create the queue, (2) load up the tasks, (3) execute the tasks. In practice I would probably simplify the code to this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqueue <- Queue$new(workers = 6)\nfor(s in 100:108) queue$add(donut, list(seed = s))\nout <- queue$run()\n```\n:::\n\n\nTrue, I could simplify it further. For example, if I know that I'm always calling the same function and always passing the same the same arguments -- just with different values -- this could be wrapped up in [purrr](https://purrr.tidyverse.org/) style syntax, but honestly I'm not sure why I would bother doing that when [furrr](https://furrr.futureverse.org/) already exists? I'm not planning to reinvent the wheel, especially not when Davis Vaughn already offers a fully-operational mass-transit system free of charge.\n\n## What does it store?\n\nThe output object `out` stores quite a lot of information about the tasks, the results, and the events that occurred during task execution, but most of it isn't immediately interesting to us (especially when things actually work!) So let's keep things simple for the moment and just look at the first five columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout[, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  task_id worker_id state        result       runtime\n1  task_1    577202  done donut_100.png 9.457713 secs\n2  task_2    577226  done donut_101.png 5.782191 secs\n3  task_3    577239  done donut_102.png 8.087054 secs\n4  task_4    577251  done donut_103.png 7.336802 secs\n5  task_5    577263  done donut_104.png 3.183247 secs\n6  task_6    577275  done donut_105.png 5.780861 secs\n7  task_7    577263  done donut_106.png 7.763061 secs\n8  task_8    577226  done donut_107.png 6.921016 secs\n9  task_9    577275  done donut_108.png 6.093996 secs\n```\n:::\n:::\n\n\nThe columns are pretty self-explanatory I think?\n\n- `task_id` is a unique identifier for the task itself\n- `worker_id` is a unique identifier for the worker that completed the task (it's also the process id for the R session)\n- `state` summarises the current state of the task (they're all `\"done\"` because the queue is finished)\n- `result` is a list column containing the output from each task\n- `runtime` is a difftime column telling you how long each task took to finish \n\nAs for the the full output... well... here it is...\n\n\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\nout\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  task_id worker_id state        result       runtime                                                                          fun args\n1  task_1    577202  done donut_100.png 9.457713 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  100\n2  task_2    577226  done donut_101.png 5.782191 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  101\n3  task_3    577239  done donut_102.png 8.087054 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  102\n4  task_4    577251  done donut_103.png 7.336802 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  103\n5  task_5    577263  done donut_104.png 3.183247 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  104\n6  task_6    577275  done donut_105.png 5.780861 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  105\n7  task_7    577263  done donut_106.png 7.763061 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  106\n8  task_8    577226  done donut_107.png 6.921016 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  107\n9  task_9    577275  done donut_108.png 6.093996 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  108\n              created              queued            assigned             started            finished code\n1 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:03  200\n2 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00  200\n3 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:02  200\n4 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:01  200\n5 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:57  200\n6 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00  200\n7 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:57 2022-12-23 12:27:57 2022-12-23 12:28:05  200\n8 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00 2022-12-23 12:28:00 2022-12-23 12:28:06  200\n9 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00 2022-12-23 12:28:00 2022-12-23 12:28:06  200\n                             message stdout stderr error\n1 done callr-rs-result-8ce3e320ef539                NULL\n2 done callr-rs-result-8ce3e6e032153                NULL\n3 done callr-rs-result-8ce3e5d32c7ba                NULL\n4  done callr-rs-result-8ce3e72346af                NULL\n5 done callr-rs-result-8ce3e4193129d                NULL\n6 done callr-rs-result-8ce3e42c3653c                NULL\n7 done callr-rs-result-8ce3e6ecedbfa                NULL\n8 done callr-rs-result-8ce3e41e0f9e6                NULL\n9 done callr-rs-result-8ce3e5a3c4630                NULL\n```\n:::\n:::\n\n\nOkay so there's a bit more to unpack here. Let's take a look...\n\n- The `fun` and `args` columns contain the functions and arguments that were originally used to specify the task\n- The `created`, `queued`, `assigned`, `started`, and `finished` columns contain POSIXct timestamps indicating when the task was created, added to a queue, assigned to a worker, started running on a worker, and returned from the worker\n- `code` is a numeric code returned by the callr R session: of particular note 200 means it returned successfully, 500 means the session exited cleanly, and 501 means the session crashed\n- `message` is a message returned by callr\n- `stdout` and `stderr` are the contents of the output and error streams from the worker session while the task was running\n- `error` currently is `NULL` because I haven't implemented that bit yet lol.\n\n\n\n\n\n\n## Surviving a crash\n\nI'm going to be honest. Sometimes^[Often] I write bad code when I am exploring a new generative art system. Code that crashes the R session unpredictably. So it would be nice if the queue had a little bit of robustness for that. To be honest, the queue package isn't very sophisticated in detecting sessions that have crashed,^[I mean, it was just a fun side project I did over the weekend because I found myself unexpectedly unemployed all of a sudden, and my self-confidence is utterly shattered at the moment, and Stella needs to get her groove back slowly okay?] but it does have some ability to recover when a task crashes its thread. Let's keep this simple. I'll define a perfectly safe function that waits for a moment and then returns, and another function that always crashes the R session as soon as it is called:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwait <- function(x) {\n  Sys.sleep(x)\n  x\n}\ncrash <- function(x) .Call(\"abort\")\n```\n:::\n\n\nNow let's define a queue that has only two workers, but has no less than three tasks that are guaranteed to crash the worker the moment the tasks are started:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqueue <- Queue$new(workers = 2)\nqueue$add(wait, list(x = .1))\nqueue$add(crash)\nqueue$add(crash)\nqueue$add(crash)\nqueue$add(wait, list(x = .1))\n```\n:::\n\n\nThe queue allocates task in a first-in first-out order, so the three \"crash tasks\" are guaranteed to be allocated before the final \"wait task\". Let's take a look at what happens when the queue runs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqueue$run()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ Queue complete: 5 tasks done in 3.3 secs\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 17\n  task_id worker_id state result    runtime        fun    args            \n  <chr>       <int> <chr> <list>    <drtn>         <list> <list>          \n1 task_1     581814 done  <dbl [1]> 0.1225462 secs <fn>   <named list [1]>\n2 task_2     581826 done  <NULL>    1.0791264 secs <fn>   <list [0]>      \n3 task_3     581814 done  <NULL>    2.0285015 secs <fn>   <list [0]>      \n4 task_4     581848 done  <NULL>    1.9837573 secs <fn>   <list [0]>      \n5 task_5     581865 done  <dbl [1]> 0.1597984 secs <fn>   <named list [1]>\n# … with 10 more variables: created <dttm>, queued <dttm>, assigned <dttm>,\n#   started <dttm>, finished <dttm>, code <dbl>, message <chr>,\n#   stdout <list>, stderr <list>, error <list>\n```\n:::\n:::\n\n\nIt's a little slower than we'd hope, but it does finish both valid tasks and returns nothing for the tasks that crashed their R sessions. What has happened in the background is that the queue runs a simple check to see if any of the R sessions have crashed, and attempts to replace them with a new worker whenever it detects that this has happened. It's not in any sense optimised, but it does sort of work.\n\n\n\n<!--------------- appendices go here ----------------->\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}