{
  "hash": "8e81be517054022e384a28be41b9b4bf",
  "result": {
    "markdown": "---\ntitle: \"Queue\"\ndescription: \"It is a truth universally acknowledged, that a post about multithreading must be in want of an async trick\"\ndate: \"2022-12-22\"\ncategories: [Parallel Computing, R, Object-Oriented Programming]\nimage: \"donut_100.png\"\n---\n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\nOkay. So I wrote a simple package for [multi-threaded tasks queues in R](https://queue.djnavarro.net) this week. It wasn't intentional, I swear. I was just trying to teach myself how to use the [callr](https://callr.r-lib.org/) package,^[Honestly, the whole reason this exists is that I was reading the callr blog post on writing [multi-worker task queues](https://www.tidyverse.org/blog/2019/09/callr-task-q/) and decided to try doing it myself...] and making sure I had a solid grasp of encapsulated object-oriented programming with [R6](https://r6.r-lib.org/). Things got a little out of hand. Sorry.\n\nAnd let's be very clear about something at the outset. If you want to do parallel computing in R correctly, you go look at [futureverse.org](https://www.futureverse.org/). The [future](https://future.futureverse.org/) package by Henrik Bengtsson provides a fabulous way to execute R code asynchronously and in parallel. And there are many excellent packages built on top of that, so there's a whole lovely ecosystem there just waiting for you.^[Note to self: Learn [parallelly](https://www.jottr.org/2022/12/05/avoid-detectcores/)] Relatedly, if the reason you're thinking about parallel computing is that you've found yourself with a burning need to analyse terabytes of data with R then babe it might be time to start learning some R workflows using [Spark](https://therinspark.com/), [Arrow](https://blog.djnavarro.net/category/apachearrow), [Kubernetes](https://www.r-bloggers.com/2022/04/wtf-is-kubernetes-and-should-i-care-as-r-user/). It may be time to learn about some of those other eldritch words of power that have figured rather more prominently in my life than one might expect for a simple country girl.^[`kubectl auth can-i create chaos`] \n\nMy little queue package is a personal project. I happen to like it, but you should not be looking at it as an alternative to serious tools.\n\nThat's been said now. Good. We can put aside all pretension.\n\n## What does it do?\n\nLet's say I have a generative art function called `donut()`, based loosely on a [teaching example from my art from code workshop](https://art-from-code.netlify.app/day-1/session-1/#composition). The `donut()` function takes an input `seed`, creates a piece of generative art using ggplot2, and writes the output to an image file. This process takes several seconds to complete on my laptop:\n\n\n\n\n::: {.cell hash='index_cache/html/my-first-donut_78cc3a9337022adc6a85a72fd51f194e'}\n\n```{.r .cell-code}\nlibrary(tictoc)\ntic()\ndonut(seed = 100)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.277 sec elapsed\n```\n:::\n:::\n\n\nHere's the piece, by the way:\n\n![](donut_100.png)\n\nThat's nice and I do like this piece, but generative art is an iterative process and I like to make many pieces at once to help me get a feel for the statistical properties of the system. Waiting five or six seconds for one piece to render is one thing: waiting 8-10 minutes for 100 pieces to render is quite another. So it's helpful if I can do this in parallel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(queue)\n```\n:::\n\n\nHere's how I might do that using queue. I designed the package using R6 classes -- more on that later -- so we'll be working in the \"encapsulated\" object oriented programming style that is more common in other programming languages. The first step is to initialise a [`Queue`](https://queue.djnavarro.net/reference/Queue.html) object, specifying the number of workers we want to use. I'll use six:\n\n\n::: {.cell hash='index_cache/html/my-first-queue_dfc1ff39dc3ddb607ec985d5339378c1'}\n\n```{.r .cell-code}\nqueue <- Queue$new(workers = 6)\n```\n:::\n\n\nWhen I do this, the queue package starts six R sessions for us, and all my computations will be done in those R sessions. Under the hood, all the hard work of managing the R sessions is being done by the wonderful callr package by Gábor Csárdi^[Longtime readers will have noticed that I have become a bit of a fangirl. I swear I'm not stalking him, but like, every time I think... gosh this is a really handy bit of infrastructure tooling, who do I have to thank for this... oh, of course it's bloody Gábor again. Anyway.] -- the only thing that queue does is provide a layer of abstraction and automation to the whole process. \n\nNext, I'll add some tasks to the queue. `Queue` objects have an `add()` method that take a function and a list of arguments, so I can do this to push a task to the queue:\n\n\n::: {.cell hash='index_cache/html/my-first-task_e9d06a818d4aab8856c997131ca80f42'}\n\n```{.r .cell-code}\nqueue$add(donut, args = list(seed = 100))\n```\n:::\n\n\nWhen the queue executes, it will be in a \"first in, first out\" order,^[I am a country girl, so FIFO means \"fly-in fly-out\", and I shan't be listening to any of you computer nerds who claim it has another meaning] so this task will be the first one to be assigned to a worker. Though of course that's no guarantee that it will be the first one to finish!\n\nAnyway, let's load up several more tasks. There's some weird aversion out there to using loops in R, but this isn't one of those situations where we need to worry about unnecessary copying, so I'm going to use a loop:\n\n\n::: {.cell hash='index_cache/html/load-several-tasks_5cc68af5a47beff90603fa0c398907e3'}\n\n```{.r .cell-code}\nfor(s in 101:108) queue$add(donut, list(seed = s))\n```\n:::\n\n\nSo now we have nine tasks loaded onto a queue with six workers. To start it running I call the `run()` method for the queue. By default, all you'd see while the queue is running is a spinner with a progress message telling you how many tasks have completed so far, how many are currently running, and how many are still waiting. But I'll ask it to be a bit more chatty. I'll call it setting `message = \"verbose\"` so that we can see a log showing the order in which the tasks completed and time each task took to complete, in addition to the total time elapsed on my system while the queue was running:\n\n\n::: {.cell hash='index_cache/html/run-my-queue_f0e1b58ef56570b65d67c0ec4ae0c11c'}\n\n```{.r .cell-code}\nout <- queue$run(message = \"verbose\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_5 finished in 3.18 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_2 finished in 5.78 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_6 finished in 5.78 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_4 finished in 7.34 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_3 finished in 8.09 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_1 finished in 9.46 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_7 finished in 7.76 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_9 finished in 6.09 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: task_8 finished in 6.92 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ Queue complete: 9 tasks done in 12.7 secs\n```\n:::\n:::\n\n\nHere are the nine pieces that popped off the queue in 13 seconds: \n\n::: {.column-screen-inset}\n\n::: {layout-ncol=3}\n\n![](donut_100.png)\n\n![](donut_101.png)\n\n![](donut_102.png)\n\n![](donut_103.png)\n\n![](donut_104.png)\n\n![](donut_105.png)\n\n![](donut_106.png)\n\n![](donut_107.png)\n\n![](donut_108.png)\n\n:::\n:::\n\nSo it's a three-step process: (1) create the queue, (2) load up the tasks, (3) execute the tasks. In practice I would probably simplify the code to this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqueue <- Queue$new(workers = 6)\nfor(s in 100:108) queue$add(donut, list(seed = s))\nout <- queue$run()\n```\n:::\n\n\nTrue, I could simplify it further. For example, if I know that I'm always calling the same function and always passing the same the same arguments -- just with different values -- this could be wrapped up in [purrr](https://purrr.tidyverse.org/) style syntax, but honestly I'm not sure why I would bother doing that when [furrr](https://furrr.futureverse.org/) already exists? I'm not planning to reinvent the wheel, especially not when Davis Vaughn already offers a fully-operational mass-transit system free of charge.\n\n## What does it store?\n\nThe output object `out` stores quite a lot of information about the tasks, the results, and the events that occurred during task execution, but most of it isn't immediately interesting to us (especially when things actually work!) So let's keep things simple for the moment and just look at the first five columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout[, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  task_id worker_id state        result       runtime\n1  task_1    577202  done donut_100.png 9.457713 secs\n2  task_2    577226  done donut_101.png 5.782191 secs\n3  task_3    577239  done donut_102.png 8.087054 secs\n4  task_4    577251  done donut_103.png 7.336802 secs\n5  task_5    577263  done donut_104.png 3.183247 secs\n6  task_6    577275  done donut_105.png 5.780861 secs\n7  task_7    577263  done donut_106.png 7.763061 secs\n8  task_8    577226  done donut_107.png 6.921016 secs\n9  task_9    577275  done donut_108.png 6.093996 secs\n```\n:::\n:::\n\n\nThe columns are pretty self-explanatory I think?\n\n- `task_id` is a unique identifier for the task itself\n- `worker_id` is a unique identifier for the worker that completed the task (it's also the process id for the R session)\n- `state` summarises the current state of the task (they're all `\"done\"` because the queue is finished)\n- `result` is a list column containing the output from each task\n- `runtime` is a difftime column telling you how long each task took to finish \n\nAs for the the full output... well... here it is...\n\n\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\nout\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  task_id worker_id state        result       runtime                                                                          fun args\n1  task_1    577202  done donut_100.png 9.457713 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  100\n2  task_2    577226  done donut_101.png 5.782191 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  101\n3  task_3    577239  done donut_102.png 8.087054 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  102\n4  task_4    577251  done donut_103.png 7.336802 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  103\n5  task_5    577263  done donut_104.png 3.183247 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  104\n6  task_6    577275  done donut_105.png 5.780861 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  105\n7  task_7    577263  done donut_106.png 7.763061 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  106\n8  task_8    577226  done donut_107.png 6.921016 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  107\n9  task_9    577275  done donut_108.png 6.093996 secs function (seed) , {,     source(\"donut.R\", local = TRUE),     donut(seed), }  108\n              created              queued            assigned             started            finished code\n1 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:03  200\n2 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00  200\n3 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:02  200\n4 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:01  200\n5 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:57  200\n6 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00  200\n7 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:27:57 2022-12-23 12:27:57 2022-12-23 12:28:05  200\n8 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00 2022-12-23 12:28:00 2022-12-23 12:28:06  200\n9 2022-12-23 12:27:54 2022-12-23 12:27:54 2022-12-23 12:28:00 2022-12-23 12:28:00 2022-12-23 12:28:06  200\n                             message stdout stderr error\n1 done callr-rs-result-8ce3e320ef539                NULL\n2 done callr-rs-result-8ce3e6e032153                NULL\n3 done callr-rs-result-8ce3e5d32c7ba                NULL\n4  done callr-rs-result-8ce3e72346af                NULL\n5 done callr-rs-result-8ce3e4193129d                NULL\n6 done callr-rs-result-8ce3e42c3653c                NULL\n7 done callr-rs-result-8ce3e6ecedbfa                NULL\n8 done callr-rs-result-8ce3e41e0f9e6                NULL\n9 done callr-rs-result-8ce3e5a3c4630                NULL\n```\n:::\n:::\n\n\nOkay so there's a bit more to unpack here. Let's take a look...\n\n- The `fun` and `args` columns contain the functions and arguments that were originally used to specify the task\n- The `created`, `queued`, `assigned`, `started`, and `finished` columns contain POSIXct timestamps indicating when the task was created, added to a queue, assigned to a worker, started running on a worker, and returned from the worker\n- `code` is a numeric code returned by the callr R session: of particular note 200 means it returned successfully, 500 means the session exited cleanly, and 501 means the session crashed\n- `message` is a message returned by callr\n- `stdout` and `stderr` are the contents of the output and error streams from the worker session while the task was running\n- `error` currently is `NULL` because I haven't implemented that bit yet lol.\n\n\n\n\n\n\n## Surviving a crash\n\nI'm going to be honest. Sometimes^[Often] I write bad code when I am exploring a new generative art system. Code that crashes the R session unpredictably. So it would be nice if the queue had a little bit of robustness for that. To be honest, the queue package isn't very sophisticated in detecting sessions that have crashed,^[I mean, it was just a fun side project I did over the weekend because I have found myself quite unexpectedly unemployed, and my self-confidence is utterly shattered at the moment, and Stella needs to get her groove back slowly okay?] but it does have some ability to recover when a task crashes its thread. Let's keep this simple. I'll define a perfectly safe function that waits for a moment and then returns, and another function that always crashes the R session as soon as it is called:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwait <- function(x) {\n  Sys.sleep(x)\n  x\n}\ncrash <- function(x) .Call(\"abort\")\n```\n:::\n\n\nNow let's define a queue that has only two workers, but has no less than three tasks that are guaranteed to crash the worker the moment the tasks are started:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqueue <- Queue$new(workers = 2)\nqueue$add(wait, list(x = .1))\nqueue$add(crash)\nqueue$add(crash)\nqueue$add(crash)\nqueue$add(wait, list(x = .1))\n```\n:::\n\n\nThe queue allocates task in a first-in first-out order, so the three \"crash tasks\" are guaranteed to be allocated before the final \"wait task\". Let's take a look at what happens when the queue runs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqueue$run()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ Queue complete: 5 tasks done in 4.3 secs\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 17\n  task_id worker_id state result    runtime        fun    args            \n  <chr>       <int> <chr> <list>    <drtn>         <list> <list>          \n1 task_1     401728 done  <dbl [1]> 0.1239407 secs <fn>   <named list [1]>\n2 task_2     401740 done  <NULL>    2.1264157 secs <fn>   <list [0]>      \n3 task_3     401728 done  <NULL>    3.0233221 secs <fn>   <list [0]>      \n4 task_4     401773 done  <NULL>    1.9341383 secs <fn>   <list [0]>      \n5 task_5     401792 done  <dbl [1]> 0.1577439 secs <fn>   <named list [1]>\n# ℹ 10 more variables: created <dttm>, queued <dttm>, assigned <dttm>,\n#   started <dttm>, finished <dttm>, code <dbl>, message <chr>,\n#   stdout <list>, stderr <list>, error <list>\n```\n:::\n:::\n\n\nIt's a little slower than we'd hope, but it does finish both valid tasks and returns nothing for the tasks that crashed their R sessions. What has happened in the background is that the queue runs a simple check to see if any of the R sessions have crashed, and attempts to replace them with a new worker whenever it detects that this has happened. It's not in any sense optimised, but it does sort of work.\n\n## Design\n\nAlthough my confidence in my ability to have a career in tech is at an all-time low, I have to admit that the work I've done over the last year has made me a better programmer. I didn't much effort into writing queue, but the code feels cleaner and more modular than the code I was writing a year ago. Good practices have become habits, I suppose. That's a nice feeling. I automatically write proper unit tests as I go, knowing that those tests will save me when I need to make changes later. I document properly as I go, knowing that I won't remember a bloody thing about how my own code works six hours later -- never mind six months. And, maybe most importantly of all, my code now seems to have this habit of organising itself into small, manageable abstractions. I have no idea when that happened, because I wasn't actually part of a software engineering team. I was just the girl who wrote some docs and few little blog posts.^[For the record, dear potential future employer, this is what is known as \"self-deprecation\". Mistake not my awareness of the absurd cultural norms to which women are expected to conform with a literal claim about competence. In point of fact I am rather good at what I do.] \n\nHere's what I mean. If you take a look at the [source code for the `Queue`](https://github.com/djnavarro/queue/blob/4c70aad373fd518250c6bd6c29cebccb6d16dc65/R/queue.R) object, it's actually not very long: the file is mostly devoted to the documentation, and the object doesn't have very many methods. Honestly, we've already seen most of them:\n\n- `new()` creates a new queue\n- `add()` adds a task to a queue\n- `run()` sets the queue running\n\nIf everything works smoothly you don't need anything else, so why burden the user with extra details? Sure, there's a little complexity to these methods which is of course documented on the [relevant pkgdown page](https://queue.djnavarro.net/reference/Queue.html) because I'm not a jerk, but this isn't a complicated package... \n\n...when it's working.\n\nOf course, when things start to break, you start to care a lot more about the internals. Fair enough. There are two important data structures within the `Queue`:\n\n- Internally, a `Queue` manages a [`WorkerPool`](https://queue.djnavarro.net/reference/WorkerPool.html) comprised of one or more [`Worker`](https://queue.djnavarro.net/reference/Worker.html) objects. As you'd expect given the names, these provide abstractions for managing the R sessions. A `Worker` object provides a wrapper around a callr R session, and tools that automate the interaction between that session and a task. \n- The `Queue` also holds a [`TaskList`](https://queue.djnavarro.net/reference/TaskList.html) comprised of one or more [`Task`](https://queue.djnavarro.net/reference/Task.html) objects. Again, as you might expect from the names, these are the storage classes. A `Task` object is a container that holds a function, its arguments, any results it might have returned, and any logged information about the process of its execution. \n\nIn some situations it can be awfully handy to have access to these constituent data structures, particularly because those objects expose additional tools that I deliberately chose not to make available at the `Queue` level. From the `Queue` itself what you can do is return the objects:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkers <- queue$get_workers()\ntasks <- queue$get_tasks()\n```\n:::\n\n\nThese objects are R6 classes: they have reference semantics so anything I do with `workers` and `tasks` will have corresponding effects on `queue`. For this blog post I don't intend to dive into details of what I did when designing the `WorkerPool` and `TaskList` classes -- especially because queue is only at version 0.0.2 and I don't yet know what I'm going to do with this cute little package -- but I'll give one example.\n\nLet's take the workers. By default, a `Queue` cleans up after itself and closes any R sessions that it started. The `WorkerPool` object associated with a `Queue` has a `get_pool_state()` method that I can use to check the state of the workers, and some other methods to modify the workers if I so choose. Let's have a go. I ask `workers` to report on the status of the R sessions, this is what I get:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkers$get_pool_state()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    401792     401804 \n\"finished\" \"finished\" \n```\n:::\n:::\n\n\nYes, as expected the workers have stopped. But I can replace them with live R sessions by calling the `refill_pool()` method:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkers$refill_pool()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n401820 401832 \n\"idle\" \"idle\" \n```\n:::\n:::\n\n\nAnd I can shut them down again by calling `shutdown_pool()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkers$shutdown_pool()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    401820     401832 \n\"finished\" \"finished\" \n```\n:::\n:::\n\n\nAlong similar lines the `TaskList` object has some methods that let me manipulate the data storage associated with my `Queue`. Normally I don't need to. Sometimes I do. It's handy to have those tools lying around. At the moment the toolkit feels a little light, but the nice thing about writing your own package is that I can always add more if I need them :-) \n\n## Epilogue\n\n\n::: {.cell hash='index_cache/html/austen-joke_faf2b96ff686ee96563e01788b849faf'}\n\n```{.r .cell-code}\nqueue <- Queue$new(workers = 6)\nqueue$add(wait, list(x = 1.3), id = toupper(\"multithreading\"))\nqueue$add(wait, list(x = 0.1), id = toupper(\"it is\"))\nqueue$add(wait, list(x = 0.7), id = toupper(\"acknowledged\"))\nqueue$add(wait, list(x = 1.0), id = toupper(\"post\"))\nqueue$add(wait, list(x = 0.5), id = toupper(\"universally\"))\nqueue$add(wait, list(x = 0.1), id = toupper(\"a truth\"))\nqueue$add(wait, list(x = 1.2), id = toupper(\"must be\"))\nqueue$add(wait, list(x = 0.9), id = toupper(\"about\"))\nqueue$add(wait, list(x = 1.6), id = toupper(\"trick\"))\nqueue$add(wait, list(x = 0.1), id = toupper(\"that a\"))\nqueue$add(wait, list(x = 0.5), id = toupper(\"in want of\"))\nqueue$add(wait, list(x = 1.0), id = toupper(\"an async\"))\nout <- queue$run(message = \"verbose\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: IT IS finished in 0.172 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: A TRUTH finished in 0.169 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: UNIVERSALLY finished in 0.536 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: ACKNOWLEDGED finished in 0.776 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: THAT A finished in 0.173 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: POST finished in 1.07 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: ABOUT finished in 0.957 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: MULTITHREADING finished in 1.37 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: MUST BE finished in 1.25 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: IN WANT OF finished in 0.582 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: AN ASYNC finished in 1.06 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n→ Done: TRICK finished in 1.66 secs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ Queue complete: 12 tasks done in 2.21 secs\n```\n:::\n:::\n\n\n<!--------------- appendices go here ----------------->\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}