{
  "hash": "84ccdd0f26b6a21d51bcf30db310bc1b",
  "result": {
    "markdown": "---\ntitle: \"Pins and needles\"\ndescription: \"Learning my lessons the hard way\"\ndate: \"2023-06-12\"\ncategories: [\"R\"]\n---\n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\n## Creating and configuring the storage buckets\n\nI'm familiar enough with the gcloud command line that I feel comfortable creating the bucket there. There's some [relevant documentation](https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-cli) to help out too, which is nice. Everything in google cloud takes place within a project, specified by project ID (in this case `pins-389407`). For my own purposes I have two buckets in my pins project: `djnavarro-pins` is where I store publicly accessible data, and `djnavarro-private-pins` is where I keep private pins. Rather than set defaults, I have a tendency to do everything explicitly, so the `--project` flag is set in each command, as is the `--location` flag used to specify that I want my data to be stored in Sydney (also known as `australia-southeast1`). Anyway:\n\n```bash\ngcloud storage buckets create gs://djnavarro-pins/ \\\n  --project pins-389407 \\\n  --location australia-southeast1 \\\n  --uniform-bucket-level-access\n```\n\nThe `--uniform-bucket-level-access` flag is used to indicate that I'm not doing fancy file-specific access control. I'm too lazy or simple-minded for that: I want one bucket to be public, and another bucket to be private. To make all files in the bucket publicly readable ([relevant documentation](https://cloud.google.com/storage/docs/access-control/making-data-public#command-line_1)) the command I want is this:\n\n```bash\ngcloud storage buckets add-iam-policy-binding gs://djnavarro-pins/ \\\n  --member=allUsers \\\n  --role=roles/storage.objectViewer\n```\n\n## A terrible horrible no good very bad hack\n\nLet's say I want to pin the `diamonds` data from the ggplot2 package as a csv file. The first thing I need is an authentication token, which I can obtain with the help of the gargle package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gargle)\nscope <- \"https://www.googleapis.com/auth/cloud-platform\"\ntoken <- token_fetch(scopes = scope)\n```\n:::\n\n\nThis workflow is designed for interactive use so there's a confirmation process to follow. Once that's done I can authenticate with the googleCloudStorageR package, and I can confirm it's working by listing the contents of the bucket:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(googleCloudStorageR)\ngcs_auth(token = token)\ngcs_list_objects(bucket = \"gs://djnavarro-pins\")\n```\n:::\n\n\n::: {.column-page-inset-right}\n\n```\n                                                      name      size             updated\n1                                               _pins.yaml 161 bytes 2023-06-12 07:33:04\n2              warfpk_data/20230610T142554Z-b8888/data.txt 190 bytes 2023-06-10 14:26:11\n3       warfpk_data/20230610T142554Z-b8888/warfpk_data.csv      8 Kb 2023-06-10 14:26:11\n4             warfpk_draws/20230610T142202Z-5bd80/data.txt 200 bytes 2023-06-10 14:23:05\n5     warfpk_draws/20230610T142202Z-5bd80/warfpk_draws.csv  281.4 Mb 2023-06-10 14:25:26\n6           warfpk_summary/20230610T083635Z-340c1/data.txt 200 bytes 2023-06-10 08:38:44\n7 warfpk_summary/20230610T083635Z-340c1/warfpk_summary.csv    1.2 Mb 2023-06-10 08:38:44\n```\n\n:::\n\nNow we can use the pins package as a more convenient interface:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pins)\nboard <- board_gcs(\"gs://djnavarro-pins\")\n```\n:::\n\n\nI can write pins directly to the board like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npin_write(\n  board, \n  ggplot2::diamonds, \n  name = \"diamonds\", \n  type = \"csv\"\n)\n```\n:::\n\n\nUnder the hood the work is done by googleCloudStorageR, which whines a little about needing `predefinedAcl = \"bucketLevel\"`, but does get the job done. In principle I could pass this argument to `pin_write()` via the dots, but unfortunately `pin_write()` is a bit trigger happy and throws an error if I do, incorrectly guessing that the argument is misspelled. We can verify that the files have been written as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngcs_list_objects(bucket = \"gs://djnavarro-pins\")\n```\n:::\n\n\n::: {.column-page-inset-right}\n\n```\n                                                      name      size             updated\n1                                               _pins.yaml 161 bytes 2023-06-12 07:33:04\n2                 diamonds/20230612T073405Z-c9e9b/data.txt 189 bytes 2023-06-12 07:34:05\n3             diamonds/20230612T073405Z-c9e9b/diamonds.csv    2.6 Mb 2023-06-12 07:34:14\n4              warfpk_data/20230610T142554Z-b8888/data.txt 190 bytes 2023-06-10 14:26:11\n5       warfpk_data/20230610T142554Z-b8888/warfpk_data.csv      8 Kb 2023-06-10 14:26:11\n6             warfpk_draws/20230610T142202Z-5bd80/data.txt 200 bytes 2023-06-10 14:23:05\n7     warfpk_draws/20230610T142202Z-5bd80/warfpk_draws.csv  281.4 Mb 2023-06-10 14:25:26\n8           warfpk_summary/20230610T083635Z-340c1/data.txt 200 bytes 2023-06-10 08:38:44\n9 warfpk_summary/20230610T083635Z-340c1/warfpk_summary.csv    1.2 Mb 2023-06-10 08:38:44\n```\n\n:::\n\nThat works: the files for the diamonds pin have been written, but notice that the `_pins.yaml` manifest file is still 161 bytes in size. It hasn't been update to add an entry for the diamonds data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngcs_get_object(\"gs://djnavarro-pins/_pins.yaml\") |> \n  yaml::as.yaml() |>\n  cat()\n```\n:::\n\n\n```\n✔ Downloaded and parsed _pins.yaml into R object of class: character\n|\n  warfpk_data:\n  - warfpk_data/20230610T142554Z-b8888/\n  warfpk_draws:\n  - warfpk_draws/20230610T142202Z-5bd80/\n  warfpk_summary:\n  - warfpk_summary/20230610T083635Z-340c1/\n```\n\nThere's a bit of a painful thing that follows because pins doesn't currently have working `pin_list()` method for google cloud storage. This in turn means that I can't currently use `write_board_manifest()` to write a manifest file for my board. That's a huge pain. A little browsing on github issues reassures that the devs are well aware of the problem, and addressing this is indeed on the to-do list. Unfortunately that doesn't solve my problem in the here-and-now, so while I'm waiting I decided to put together some helper functions that will be good enough for my purposes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npin_list_gcs <- function(board, ...) {\n  googleCloudStorageR::gcs_list_objects(bucket = board$bucket)$name |> \n    grep(pattern = \"/\", x = _, value = TRUE) |> \n    gsub(pattern = \"/.*\", replacement = \"\", x = _) |>\n    unique()\n}\n```\n:::\n\n\nNow a little bit of evil, in which I do the thing you should never ever do:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunlockBinding(as.symbol(\"pin_list.pins_board_gcs\"), getNamespace(\"pins\"))\nassignInNamespace(\"pin_list.pins_board_gcs\", pin_list_gcs, \"pins\")\n```\n:::\n\n\nNext write an S3 method that allows me to write the manifest file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_board_manifest_yaml.pins_board_gcs <- function(board, manifest, ...) {\n  temp_file <- withr::local_tempfile()\n  yaml::write_yaml(manifest, file = temp_file)\n  googleCloudStorageR::gcs_upload(\n    file = temp_file, \n    bucket = board$bucket, \n    type = \"text/yaml\",\n    name = \"_pins.yaml\"\n  )\n}\n```\n:::\n\n\nNow this works:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_board_manifest_yaml(board, manifest = pins:::make_manifest(board))\n```\n:::\n\n\nWe can verify that we've written the updated file. For reasons that escape me, this won't work unless you start a new session (and reauthenticate in the process), or specify the `generation` argument to `gcs_get_object()`. Otherwise you just get the old version of the manifest file. Anyway here's the result:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngcs_get_object(\"gs://djnavarro-pins/_pins.yaml\") |> \n  yaml::as.yaml() |>\n  cat()\n```\n:::\n\n\n```\n✔ Downloaded and parsed _pins.yaml into R object of class: character\n|\n  diamonds:\n  - diamonds/20230612T071111Z-c9e9b/\n  warfpk_data:\n  - warfpk_data/20230610T142554Z-b8888/\n  warfpk_draws:\n  - warfpk_draws/20230610T142202Z-5bd80/\n  warfpk_summary:\n  - warfpk_summary/20230610T083635Z-340c1/\n```\n\nSimilarly, if we now list the contents of the bucket we can see that it's all been updated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngcs_list_objects(bucket = \"gs://djnavarro-pins\")\n```\n:::\n\n\n::: {.column-page-inset-right}\n\n```\n                                                      name      size             updated\n1                                               _pins.yaml 206 bytes 2023-06-12 07:39:53\n2                 diamonds/20230612T073405Z-c9e9b/data.txt 189 bytes 2023-06-12 07:34:05\n3             diamonds/20230612T073405Z-c9e9b/diamonds.csv    2.6 Mb 2023-06-12 07:34:14\n4              warfpk_data/20230610T142554Z-b8888/data.txt 190 bytes 2023-06-10 14:26:11\n5       warfpk_data/20230610T142554Z-b8888/warfpk_data.csv      8 Kb 2023-06-10 14:26:11\n6             warfpk_draws/20230610T142202Z-5bd80/data.txt 200 bytes 2023-06-10 14:23:05\n7     warfpk_draws/20230610T142202Z-5bd80/warfpk_draws.csv  281.4 Mb 2023-06-10 14:25:26\n8           warfpk_summary/20230610T083635Z-340c1/data.txt 200 bytes 2023-06-10 08:38:44\n9 warfpk_summary/20230610T083635Z-340c1/warfpk_summary.csv    1.2 Mb 2023-06-10 08:38:44\n```\n\n:::\n\n## The read-only workflow\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nread_only_board <- board_url(\n  \"https://storage.googleapis.com/djnavarro-pins/_pins.yaml\"\n)\npin_search(read_only_board)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 6\n  name           type  title        created             file_size meta      \n  <chr>          <chr> <chr>        <dttm>              <fs::byt> <list>    \n1 diamonds       csv   diamonds: a… 2023-06-12 17:34:05     2.64M <pins_met>\n2 warfpk_data    csv   warfpk_data… 2023-06-11 00:25:54     8.01K <pins_met>\n3 warfpk_draws   csv   warfpk_draw… 2023-06-11 00:22:02   281.39M <pins_met>\n4 warfpk_summary csv   warfpk_summ… 2023-06-10 18:36:35     1.15M <pins_met>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npin_read(read_only_board, \"diamonds\") |>\n  tibble::as_tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <chr>     <chr> <chr>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n```\n:::\n:::\n\n\n## Epilogue\n\nAs a general long-term strategy, this workflow is *terrible* and I have no intention whatsoever of relying on it. Under no circumstances is it a good idea to rely on a method that fucks around with the internals of a package. This is only a temporary hack I'm relying on while waiting for the pins package to support google cloud buckets more completely.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}