{
  "hash": "b012d34a79a9c86428b39e9ba2f2b0d5",
  "result": {
    "markdown": "---\ntitle: \"Deploying R with kubernetes\"\nauthor:\n  - name: Danielle Navarro\n    url: https://djnavarro.net\n    affiliation: I'm on smoko\n    affiliation-url: https://www.youtube.com/watch?v=j58V2vC9EPc\n    orcid: 0000-0001-7648-6578\ndescription: \"In which it is painfully clear that the author is trying to figure it all out as she goes\"\ndate: \"2023-01-10\"\ncategories: [R, Docker, Kubernetes, plumber]\nimage: \"donut.png\"\n---\n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\n> Me: ooh I made a kubernetes app <br>\n> 10yo: I made a paper dragon <br>\n> Me: yeah... yours is cooler\n\nStory time. There was a very weird moment in machine learning history, about 20 years ago, when the probabilistic AI folks were completely obsessed with Bayesian nonparametrics, and a disproportionate number of papers at NeurIPS had titles like \"[Cutesy prefix]: An infinite dimensional model of [something really boring]\". In most cases, you'd dig into the paper and discover that they hadn't done anything very special. All they'd done is implement a Bayesian model of [boring thing] that was ambiguous about the number of [components], and instead of thinking about what prior constraints make sense for the problem they were trying to solve, the authors used a [Chinese restaurant process](https://en.wikipedia.org/wiki/Chinese_restaurant_process) (CRP) to specify the conditional prior distribution over allocations of observations to components. The CRP has the mildly-interesting property that for any finite sample size there is a non-negligible conditional probability that the next observation belongs to a hitherto unobserved component, and asymptotically the partitions over observations it generates have a countably infinite number of components. Alas, exactly zero of these papers happened to have an infinitely large data set to train the model on, and without fail the results in the papers didn't appear to have anything \"infinite dimensional\" about them whatsoever.\n\nI say this with love and gentleness, dear reader, because I wrote quite a few of those papers myself.\n\nWhy do I tell this story in a blog post that has absolutely nothing to do with machine learning, statistics, or Bayesian inference? Because in a fit of pique, somewhere around 2006, I decided to do the damned reading myself and learned quite a lot of Bayesian nonparametrics. Not because I thought it would be useful, but because I was curious and I was getting extremely irritated at overconfident machine learning boys telling me that as a mere psychologist I couldn't possibly understand the depth of their thinking.\n\nWhich brings me, naturally enough, to [kubernetes](https://kubernetes.io/).\n\n## ggplot2 on kubernetes\n\nLet's start at the ending, shall we? The art shown below is generated at [donut.djnavarro.net](https://donut.djnavarro.net), and it is more-or-less unique. The site is designed to serve a different image every time it is accessed, using the timestamp as the seed to a generative art system written in R with ggplot2. If you refresh this page, the artwork will change:\n\n\n```{=html}\n<a href=\"https://donut.djnavarro.net\"><img width=\"100%\" src=\"https://donut.djnavarro.net\" title=\"donut.djnavarro.net\"></a>\n```\n\n\n<br>\n\nUnder the hood, the site is a kubernetes app running containerised R code with google kubernetes engine. Sounds fancy, right? \n\nWell, maybe. Shall we take a look at how it works?\n\n## Write the R code\n\nDefine a function that samples a palette randomly:\n\n\n::: {.cell filename='server.R'}\n\n```{.r .cell-code .numberLines startFrom=\"4\" code-line-numbers=\"true\"}\nsample_canva <- function(seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]]\n}\n```\n:::\n\n::: {.cell filename='server.R'}\n\n```{.r .cell-code .numberLines startFrom=\"10\" code-line-numbers=\"true\"}\nsample_data <- function(seed = NULL, n = 100){\n  if(!is.null(seed)) set.seed(seed)\n  dat <- tibble::tibble(\n    x0 = stats::runif(n),\n    y0 = stats::runif(n),\n    x1 = x0 + stats::runif(n, min = -.2, max = .2),\n    y1 = y0 + stats::runif(n, min = -.2, max = .2),\n    shade = stats::runif(n),\n    size = stats::runif(n),\n    shape = factor(sample(0:22, size = n, replace = TRUE))\n  )\n}\n```\n:::\n\n::: {.cell filename='server.R'}\n\n```{.r .cell-code .numberLines startFrom=\"24\" code-line-numbers=\"true\"}\ndonut_style <- function(data = NULL, palette) {\n  ggplot2::ggplot(\n    data = data,\n    mapping = ggplot2::aes(\n      x = x0,\n      y = y0,\n      xend = x1,\n      yend = y1,\n      colour = shade,\n      linewidth = size\n    )) +\n    ggplot2::coord_polar(clip = \"off\") +\n    ggplot2::scale_y_continuous(\n      expand = c(0, 0),\n      limits = c(-1, 1),\n      oob = scales::oob_keep\n    ) +\n    ggplot2::scale_x_continuous(\n      expand = c(0, 0),\n      limits = c(0, 1),\n      oob = scales::oob_keep\n    ) +\n    ggplot2::scale_colour_gradientn(colours = palette) +\n    ggplot2::scale_linewidth(range = c(0, 6)) +\n    ggplot2::theme_void() +\n    ggplot2::theme(\n      panel.background = ggplot2::element_rect(\n        fill = palette[1], colour = palette[1]\n      )\n    ) +\n    ggplot2::guides(\n      colour = ggplot2::guide_none(),\n      linewidth = ggplot2::guide_none(),\n      fill = ggplot2::guide_none(),\n      shape = ggplot2::guide_none()\n    )\n}\n```\n:::\n\n::: {.cell filename='server.R'}\n\n```{.r .cell-code .numberLines startFrom=\"63\" code-line-numbers=\"true\"}\ndonut <- function(seed) {\n\n  dat <- sample_data(n = 200, seed = seed) |>\n    dplyr::mutate(y1 = y0, size = size / 3)\n\n  line_spec <- sample(c(\"331311\", \"11\", \"111115\"), 1)\n\n  pic <- donut_style(palette = sample_canva(seed = seed)) +\n    ggplot2::geom_segment(data = dat, linetype = line_spec)\n\n  if(stats::runif(1) < .5) {\n    pic <- pic +\n      ggplot2::geom_segment(\n        data = dat |> dplyr::mutate(y1 = y1 - .2, y0 = y0 - .2),\n        linetype = line_spec\n      )\n  }\n  if(stats::runif(1) < .5) {\n    pic <- pic +\n      ggplot2::geom_segment(\n        data = dat |> dplyr::mutate(y1 = y1 - .4, y0 = y0 - .4),\n        linetype = line_spec\n      )\n  }\n\n  pic\n}\n```\n:::\n\n\n\n## Expose an API\n\nwith plumber\n\n\n::: {.cell filename='server.R'}\n\n```{.r .cell-code .numberLines startFrom=\"91\" code-line-numbers=\"true\"}\n#* draws a donut plot\n#* @serializer svg list(width = 10, height = 10)\n#* @get /\nfunction(seed = NA) {\n  if(is.na(seed)) {\n    seed <- as.integer(Sys.time())\n  }\n  print(donut(seed))\n}\n```\n:::\n\n\n\n## Containerise it\n\n:::{.column-page-right}\n\n\n::: {.cell filename='Dockerfile'}\n\n```{.dockerfile .cell-code  code-line-numbers=\"true\"}\nFROM rocker/r-ver:4.2.2\n\nLABEL org.opencontainers.image.source \"https://github.com/djnavarro/donut\"\nLABEL org.opencontainers.image.authors \"Danielle Navarro <djnavarro@protonmail.com>\"\nLABEL org.opencontainers.image.description DESCRIPTION\nLABEL org.opencontainers.image.licenses \"MIT\"\n\nRUN Rscript -e 'install.packages(c(\"ggplot2\", \"scales\", \"tibble\", \"dplyr\", \"plumber\", \"ggthemes\"))'\nCOPY server.R /home/server.R\nEXPOSE 80\nCMD Rscript -e 'plumber::plumb(file=\"/home/server.R\")$run(host=\"0.0.0.0\", port = 80)'\n```\n:::\n\n\n:::\n\nhttps://docs.docker.com/engine/reference/builder/#expose\n\nhttps://nickjanetakis.com/blog/docker-tip-59-difference-between-exposing-and-publishing-ports\n\n## Push it to the registry\n\nhttps://github.com/djnavarro/donut/pkgs/container/donut\n\n\n:::{.column-page-right}\n\n\n::: {.cell filename='.github/workflows/build-image.yaml'}\n\n```{.yaml .cell-code  code-line-numbers=\"true\"}\nname: publish donut image\n\non:\n  push:\n    branches: ['main']\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build-and-push-image:\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - dockerfile: ./Dockerfile\n            image: ghcr.io/djnavarro/donut\n\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - name: checkout repository\n        uses: actions/checkout@v2\n\n      - name: login to the container registry\n        uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: extract metadata (tags, labels) for docker\n        id: meta\n        uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38\n        with:\n          images: ${{ matrix.image }}\n\n      - name: build and push docker image\n        uses: docker/build-push-action@ad44023a93711e3deb337508980b4b5e9bcdc5dc\n        with:\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n\n```\n:::\n\n\n:::\n\n## Create a project\n\nFirst create a project from the console https://console.cloud.google.com/\n\nGive it a fancy name like `donut-art`\n\nYour project will need to enable google kubernetes engine\n\n\n## Set up the tools!\n\nThis is a bit of a digression but I promise it's a useful one. click on the \"connect\" button and it will reveal a command you can use to connect to your cluster from the command line. you can do it right away by selecting the \"run in cloud shell\" option: that will execute the fancy little command in a terminal that google has already configured to have the tools you need to directly interact with your kubernetes cluster. however, there's nothing stopping you from doing it yourself from the pretty little bash terminal on your machine.\n\nThe tools you need to install first are gcloud (the google cloud software development kit) and kubectl (tools for interacting with kubernetes). you'll also need the \"google kubernetes engine gcloud auth plugin\":\n\n- install gcloud sdk (on ubuntu: https://cloud.google.com/sdk/docs/install#deb)\n- install gke-gcloud-auth-plugin (`sudo apt-get install google-cloud-sdk-gke-gcloud-auth-plugin`)\n- install kubectl (you can install with snap or apt-get); https://kubernetes.io/docs/reference/kubectl/\n\nhttps://kubernetes.io/docs/reference/kubectl/\n\nhttps://kubernetes.io/docs/tasks/tools/install-kubectl-linux/\n\nFootnote: Autocompletion for kubectl https://kubernetes.io/docs/reference/kubectl/cheatsheet/\n(thank you to @jan@toot.io for the hint)\n\ndon't forget: \n\n\n::: {.cell}\n\n```{.bash .cell-code}\ngcloud auth login\n```\n:::\n\n\nto authenticate \n\n## Create your cluster \n\nusing autopilot\n\nI called mine `donut-cluster`, region `australia-southeast1`\n\nnow connect:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nexport USE_GKE_GCLOUD_AUTH_PLUGIN=True\ngcloud container clusters get-credentials donut-cluster \\\n  --zone australia-southeast1 \\\n  --project donut-art\n```\n:::\n\n\ncheck that we can connect:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl cluster-info\n```\n:::\n\n\n## Create a deployment\n\n\n\n::: {.cell filename='deployment.yaml'}\n\n```{.yaml .cell-code  code-line-numbers=\"true\"}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: donut-example\n  name: donut\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: donut-example\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: donut-example\n    spec:\n      containers:\n        - name: donut\n          image: ghcr.io/djnavarro/donut:main\n          imagePullPolicy: Always\n          resources:\n            requests:\n              memory: \"64Mi\"\n              cpu: \"250m\"\n            limits:\n              memory: \"128Mi\"\n              cpu: \"500m\"\n          ports:\n            - containerPort: 80\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl apply -f deployment.yaml\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl get deployments\n```\n:::\n\n\nhttps://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/\n\nhttps://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/\n\nhttps://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n\n## Expose the deployment (no https)\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl expose deployment donut --type=LoadBalancer --name=donut-service\n```\n:::\n\n\nthen over in my website create a DNS record that points donut.djnavarro.net at the IP address\n\nmore detail:\n\nhttps://kubernetes.io/docs/concepts/services-networking/service/\n\n## Expose the deployment (with https)\n\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/managed-certs\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ngcloud compute addresses create donut-ip-address --global --project donut-art\n```\n:::\n\n\n```\nCreated [https://www.googleapis.com/compute/v1/projects/donut-art/global/addresses/donut-ip-address]\n```\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ngcloud compute addresses describe donut-ip-address --global --project donut-art\n```\n:::\n\n\nThis prints out the IP address and some other details.\n\n\nNow create the managed certificate:\n\n\n::: {.cell filename='managed-cert.yaml'}\n\n```{.yaml .cell-code  code-line-numbers=\"true\"}\napiVersion: networking.gke.io/v1\nkind: ManagedCertificate\nmetadata:\n  name: managed-cert\nspec:\n  domains:\n    - donut.djnavarro.net\n```\n:::\n\n\nApply it to your cluster:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl apply -f managed-cert.yaml\n```\n:::\n\n\nSometimes when they say \"it might take an hour to...\" it only takes like 20 seconds. Yeah nah this is one where it actually took about an hour. We'll come back to it.\n\nNodePort: https://kubernetes.io/docs/concepts/services-networking/service/\n\nImportant bit: notice that under `spec.selector` I'm referring to the name of my deployment (donut-example). That's what the kubernetes docs tell you to do when setting up a NodePort service, but the help docs on the corresponding GKE page that I linked to at the start of the page are misleading: they make it look like you're supposed to use the name of the service not the app. \n\nProbably less important bit: I'm doing everything on port 80 regardless of what the GKE docs suggest because there was an issue at some point with hardcoding port 80 somewhere. Pretty certain that's been properly resolved now but it was one of the tweaks I made on the way to figuring out the problem with spec.selector and fuck it this works so I'm not changing it\n\n\n::: {.cell filename='mc-service.yaml'}\n\n```{.yaml .cell-code  code-line-numbers=\"true\"}\napiVersion: v1\nkind: Service\nmetadata:\n  name: mc-service\nspec:\n  selector:\n    app.kubernetes.io/name: donut-example\n  type: NodePort\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n```\n:::\n\n\nApply it to your cluster:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl apply -f mc-service.yaml\n```\n:::\n\n\nPoint the DNS record to the right place then...\n\nCreate the ingress:\n\n\n::: {.cell filename='mc-ingress.yaml'}\n\n```{.yaml .cell-code  code-line-numbers=\"true\"}\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: mc-ingress\n  annotations:\n    kubernetes.io/ingress.global-static-ip-name: donut-ip-address\n    networking.gke.io/managed-certificates: managed-cert\n    kubernetes.io/ingress.class: \"gce\"\nspec:\n  defaultBackend:\n    service:\n      name: mc-service\n      port:\n        number: 80\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl apply -f mc-ingress.yaml \n```\n:::\n\n\nNow let's get the results:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl get ingress\n```\n:::\n\n\n```\nNAME         CLASS    HOSTS   ADDRESS         PORTS   AGE\nmc-ingress   <none>   *       34.149.195.33   80      98s\n```\n\nMight have to wait a bit for provisioning to finish:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nkubectl describe managedcertificate managed-cert\n```\n:::\n\n\nRelevant bit of the output once it's all working:\n\n```\nSpec:\n  Domains:\n    donut.djnavarro.net\nStatus:\n  Certificate Name:    mcrt-b2204ff4-ad92-4811-a56d-f007190bb659\n  Certificate Status:  Active\n  Domain Status:\n    Domain:     donut.djnavarro.net\n    Status:     Active\n```\n\n\n\n\n## Where next?\n\n- enabling https: https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/ https://medium.com/avmconsulting-blog/how-to-secure-applications-on-kubernetes-ssl-tls-certificates-8f7f5751d788 https://snyk.io/blog/setting-up-ssl-tls-for-kubernetes-ingress/\n- storage: the app generates a new image every time it is called. that's wasteful, especially if you're going to reuse images. enable google cloud storage and have the plumber app check for the relevant file on gcs before trying to generate a new one https://cloud.google.com/kubernetes-engine/docs/concepts/volumes  https://cloud.google.com/kubernetes-engine/docs/how-to/volumes\n- fancier things like spark-on-kubernetes already have helm charts. so you'd want to install helm and learn how to create deployments from that https://bitnami.com/stack/spark/helm\n\n<!--------------- appendices go here ----------------->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}