{
  "hash": "13f948658d4fff749c0f4fe67cd8b85c",
  "result": {
    "markdown": "---\ntitle: \"Playing with docker and the github container registry\"\nauthor:\n  - name: Danielle Navarro\n    url: https://djnavarro.net\n    affiliation: I'm on smoko\n    affiliation-url: https://www.youtube.com/watch?v=j58V2vC9EPc\n    orcid: 0000-0001-7648-6578\ndescription: \"There is no reason for this.\"\ndate: \"2023-01-01\"\ncategories: [Linux, R, Docker]\nimage: \"whales.png\"\n---\n\n\n<!-- image credit: \n  Teng Yuhong\n  https://unsplash.com/photos/qMehmIyaXvY\n-->\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\nDocker docker docker baby. This is a post about docker, and on the off chance that you've been living under a rock for the last several years, docker^[Look, I know it's technically supposed to be \"Docker\" not \"docker\" and it's supposed to be \"GitHub\" not \"github\". But my body was \"supposed\" to use testosterone as its primary sex hormone too, and we've all seen how little regard I had for that. Sometimes conventions are worth breaking out of sheer bloody-mindedness.] allows you to run your code within a \"container\" that isolates it from other processes running on your machine. Containers are a bit like virtual machines, but smaller, more portable, and don't require you to have a complete copy of a second operating system running on your machine. They're... actually, you know what? Why don't I quote the relevant paragraphs from [the docker website](https://www.docker.com/resources/what-container/):\n\n> **CONTAINERS**: Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel^[STEM people need to find new words for things. What is a \"kernel\"? Is it the bits of an operating system that run essential processes? Is it a specialised function that applies only to input arguments of specific types (i.e., what R folks would call a \"method\" in the functional object oriented programming sense, as opposed to the encapsulated object-oriented programming paradigm that dominates in other languages)? Or is it the thing the governs the transformation from data space to feature space in a support vector machine or other inferential systems built on reproducing kernel Hilbert spaces? For fuck's sake people LEARN A NEW WORD.] ^[I'd like to propose using \"egg\" in lieu of \"kernel\" for any new tech nomenclature. Not only does it show you have some wit and know your audience.] ^[Your audience consists of queers. Nobody else reads this far into a nested footnote series.] with other containers, each running as isolated processes in user space. Containers take up less space than VMs (container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems.\n>\n> **VIRTUAL MACHINES**: Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries and libraries – taking up tens of GBs. VMs can also be slow to boot.\n\nThey even have pretty pictures on the website. I thought about reproducing their figures for this blog post but why bother? If you want to look at their pictures you can go look at the website and in any case I think we can all agree that making these cute whale graphics with ggplot2 was a much better use of my time, yes?\n\n\n::: {.cell .column-screen-inset layout-align=\"center\" fig.dpi='200'}\n::: {.cell-output-display}\n![](index_files/figure-html/whale-row-1-1.png){fig-align='center' width=1536}\n:::\n:::\n\n\nAnyway. I've been meaning to teach myself docker for a few years now. It's one of those \"things\" that has this weird aura of being difficult when it... doesn't seem to be all that difficult? For a long time I've had this feeling of dread or insecurity about it, thinking that it must be \"too technical\" for me.^[Sometimes I think that the \"not technical enough\" concept is just straight up misogyny, both internalised and... external. I mean, I taught myself Bayesian nonparametrics and algorithmic information theory and even wrote respected academic papers in both those fields in addition to my own discipline of mathematical psychology. I was an editor at Science (yes, the journal). I wrote a quite successful statistics textbook. I'm an author on the ggplot2 book. I was a successful tenured academic in a mathematical science with no formal training in mathematics. I've taught myself several programming languages. Last year I wrote quite a lot of Apache Arrow content that everyone seems to like. So, um, yeah. Perhaps I should stop paying attention to the opinions of boys who condescend to me and tell me I'm not technical enough because... I'm stronger in R than in Python or C++? Tiresome.] I have no doubt that the internals to docker are complicated, and there are subtleties to using docker well that will take a while to grasp, but when I managed to set aside my fears and read the documentation it turned out that the basics were surprisingly easy. \n\n## Installing docker\n\nThe [installation guides](https://docs.docker.com/get-docker/) on the docker website are good, and have information for various operating systems. I'm doing this on my ubuntu laptop^[Yes I know [I use Arch now](https://blog.djnavarro.net/posts/2022-12-31_btw-i-use-arch/), hush. you'll see why I'm doing this from ubuntu in a moment...] so I followed the [ubuntu install guide](https://docs.docker.com/engine/install/ubuntu/). I also went a little further and followed the [post-install instructions for linux](https://docs.docker.com/engine/install/linux-postinstall/) so that I could run docker commands without requiring superuser privileges: that's the reason you won't see any `sudo` commands in this post. Obviously, that's something that will be a bit different on different operating systems and I'm not trying to write a tutorial here, but if you are using this post as a resource you can check that everything is working on your own installation by running this command:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker run hello-world\n```\n:::\n\n\n```\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n2db29710123e: Pull complete \nDigest: sha256:c77be1d3a47d0caf71a82dd893ee61ce01f32fc758031a6ec4cf1389248bb833\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n```\n\nOkay that looks good. Docker^[I suppose, for the sake of precision, I should draw attention to the part of the output that refers to the **docker client** and the **docker daemon**. Docker takes a client-server approach. When I'm typing these commands I'm interacting with the docker client, which passes my requests over to the docker daemon. The daemon is the process that does most of the work. It pulls images from registries (e.g., [docker hub](https://hub.docker.com/), [github container registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry), etc), it builds images, it creates containers, etc. In this case, the client and the daemon are both running on the same machine, but they don't actually have to. The daemon could totally run on a remote system. However, the distinction between the client and the daemon isn't important for this post so I'm going to ignore it and collectively refer to both of them working together as \"docker\".] seems to be running on my machine. As an aside, as long as you are online you don't need to have a copy `hello-world` itself for this to work: docker will download it for you when you run the command. \n\n## Terminology\n\nBefore diving in and using docker, it helps to disambiguate three terms:\n\n- **Container**. A container is an executable. It runs on your machine isolated from other processes, has a namespace on the kernel, etc. Setting the particulars aside, it *is* a computing environment.\n- **Image**. An image is a read-only template that contains the instruction to build a container. It's a \"snapshot\" of a computing environment, constructed from one or more \"layers\" of build steps. Images are binaries that are stored locally and hosted on various registries. More on that later! \n- **Dockerfile**. Finally, there's the dockerfile.^[I'm sure that's supposed to be \"Docker file\". Per my earlier footnote, I don't care.] That's a plain text file that you as the user write. It contains the instructions for how to construct an image. They supply, in a (very!) abstract sense, the source code for an image. \n\nSo it works like this. You use a dockerfile to **build** an image, the image contains the instructions to **run** a container, and the corresponding commands are quite sensibly called `docker build` and `docker run`. Or if you like diagrams with labelled arrows... \n\n$$\n\\mbox{dockerfile} \\xrightarrow{\\mbox{build}} \\mbox{image} \\xrightarrow{\\mbox{run}} \\mbox{container}\n$$\n\nAt any point you can get a summary of the images on your system by running `docker image list`. If you're doing this with a fresh installation and you run the command after running the \"hello world\" example above,^[As a little aside. In order to create this output with the \"appearance\" of starting with a fresh docker installation I -- quite nobly -- cleared out all my cached containers and images so that I could start from a clean system. Should you ever want to do the same, it's a two step process. Assuming you don't have any containers running, your first step is to delete any containers on your system that aren't running (i.e., all of them) with `docker container prune`. Then you can delete any \"dangling\" images that aren't associated with a container (i.e., all of them) with `docker image prune --all`. You're welcome.] you'd get output that looks like this:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker image list\n```\n:::\n\n\n```\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    feb5d9fea6a5   15 months ago   13.3kB\n```\n\nYou can do the same thing for containers with `docker container ls`,^[No I don't know why they use `list` for images and `ls` for containers. That seems unhelpful.] which by default will show you currently-running containers. To see all containers, running or not, add the `--all` parameter:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker container ls --all\n```\n:::\n\n\n```\nCONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\nefcf7186776f   hello-world   \"/hello\"   6 minutes ago   Exited (0) 6 minutes ago             bold_davinci\n```\n\nNotice the difference in the \"CREATED\" time! The *image* for hello-world is something that someone else created 15 months ago and kindly placed online so I could pull it onto my machine without building it myself. The *container* is the executable that I created from that image a mere 6 minutes ago when I called `docker run`. They're both currently on my laptop, but they are quite different things.\n\nAh, but I am rambling again, aren't I? Sorry. Shall we have a go at this then?\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![This was my first attempt at plotting something that looks a bit like the docker whale. It's nothing fancy: I created a data frame with coordinates corresponding to a circle and then distorted it in two different ways. One distortion produces the whale body, another makes the tail. They are rendered in ggplot2 with `geom_polygon()`. Later in the process I tweaked the tail a bit.](index_files/figure-html/whale-0-1.png){width=672}\n:::\n:::\n\n\n\n## Motivating problem\n\nIn my [last post](https://blog.djnavarro.net/posts/2022-12-31_btw-i-use-arch/) I mentioned that, [btw I use arch](https://knowyourmeme.com/memes/btw-i-use-arch) now.^[I strongly feel there is qualitative dissertation to be written mapping the btw-i-use-arch guy onto the [men-explain-things-to-me](https://en.wikipedia.org/wiki/Men_Explain_Things_to_Me) guy from the Rebecca Solnit essay. As far as I can tell they are essentially the same person, just inhabiting different semantic domains. One day I will write the story of the guy at a conference who breathlessly explained a paper to me and how my work would be improved considerably if I'd read it while I was quietly wondering how to explain to him that it was my paper... sigh. *Men*.] Well. Sort of. A more accurate statement would be to say that I installed arch linux on a secondary laptop as something to play with and I'm still using ubuntu for my day to day coding. At the moment I'm still getting used to the quirks of arch and encountering odd behaviour when -- for example -- one of my scripts that ran perfectly well on my ubuntu machine caused RStudio to crash when I ran it on the arch box. The \"it works on my machine\" problem strikes again... sigh. \n\nIn an effort to isolate the problem I started reran the unit tests for the package that I thought might be responsible for the crash and they all passed on both machines, but since that package is my [queue](https://blog.djnavarro.net/posts/2022-12-22_queue/) package and the unit test aren't as comprehensive as I'd like I would not be at all surprised if there's an exotic bug that makes it fail only on arch. \n\nAll this made me think a little about how I typically use CI.^[Am I the only one who still thinks that CI should stand for \"confidential informant\" rather than \"continuous integration\"?] Like many R developers I'll use github actions to run my unit tests on mac os, ubuntu, and windows. I'll run the tests with multiple versions of R including R-devel. If I'm thinking about a CRAN submission I'll expand the scope and run my tests using other services also.\n\nI've never tested on arch though.\n\nI've never tested on arch because I've never had an arch machine to test on before. Or... [docker enters from stage left]... I've never had an arch image that I can use to containerise my unit tests before...\n\nOoh... a side project! Why don't I try creating some docker images with R running on arch linux? In other words, why don't I do a really lazy, half-arsed version of the thing that the [rocker project](https://rocker-project.org/) has already done to an extremely high standard with ubuntu and debian... except with arch?^[Quite obviously, I do not actually recommend anyone use the images I've set up. I mean, surely my phrasing here makes 1000% clear that this is a cute project I threw together in a couple of days for my own amusement. If you are looking to do reproducible computing in R you should be using the images provided by rocker. If you use my images and something goes wrong then to be perfectly frank you only have yourself to blame.]\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Adding the boxes was conceptually easy: the `expand_grid()` function from tidyr creates the necessary data structure, and `geom_tile()` plots it. One thing I really like about this iteration is that the spacing of the boxes creates a [Hermann grid illusion](https://en.wikipedia.org/wiki/Grid_illusion). It's not as cool as the scintillating grid version, but I used to teach it in introductory cognitive science classes and I have a soft spot for it.](index_files/figure-html/whale-1-1.png){width=672}\n:::\n:::\n\n\n\n## Minimal example\n\nSometimes the easiest way to tell a story is to begin at the ending, and -- spoiler! -- I did in fact succeed in my attempt,^[Set your sights low enough and it is very easy to achieve your goals.] and I am now the proud^[No. Just no.] maintainer of two hastily-constructed images hosted on the github container repository. Now that I have these things, it should be really easy for us to put together a simple project that will run R code using these images and -- even though I'm going to be using my ubuntu laptop -- have it be executed by a container that is running arch. \n\nOh. The. Thrill.\n\nBe. Still. My. Beating. Heart.\n\nOkay, so here it is. Accompanying this post is a project called [`system-check`](https://github.com/djnavarro/quarto-blog/tree/main/posts/2023-01-01_playing-with-docker/system-check) that consists of a three-line dockerfile and a two-line R script. Let's ignore the dockerfile for a moment and focus on the R code. Here's the script:\n\n\n::: {.cell filename='./system-check/script.R'}\n\n```{.r .cell-code}\ncat(c(\"Running on:\", osVersion), sep = \"\\n  \")\ncat(c(\"With locale:\", strsplit(Sys.getlocale(), \";\")[[1]]), sep = \"\\n  \")\n```\n:::\n\n\nIf we ignore the parts the code dedicated to making the output pretty, we can see that all it's doing is printing the `osVersion` and calling `Sys.getlocale()`. Here's what happens when I run the script on my ubuntu laptop, without using docker in any way:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nRscript ./system-check/script.R\n```\n:::\n\n\n```\nRunning on:\n  Ubuntu 22.04.1 LTS\nWith locale:\n  LC_CTYPE=en_AU.UTF-8\n  LC_NUMERIC=C\n  LC_TIME=en_AU.UTF-8\n  LC_COLLATE=en_AU.UTF-8\n  LC_MONETARY=en_AU.UTF-8\n  LC_MESSAGES=en_AU.UTF-8\n  LC_PAPER=en_AU.UTF-8\n  LC_NAME=C\n  LC_ADDRESS=C\n  LC_TELEPHONE=C\n  LC_MEASUREMENT=en_AU.UTF-8\n  LC_IDENTIFICATION=C\n```\n\nThe first part of the output tells me my operating system (ubuntu), and the second part specifies the locale. I'm in Australia so for most things my locale is `en_AU.UTF-8`. That makes sense, but of course this output is specific to my machine: an arch user running R in the United States should expect to see something very different. \n\nThat's where docker comes in.\n\nThe docker images that I built and am hosting on github simulate exactly that. The computing environments specified by the `arch-r-base` and `arch-r-test` images use arch linux as the operating system and have the system locale set to `en_US.UTF-8`. So if I were to execute this script from within a container running the `arch-r-base`^[It's an open question how long I'm going to last in this post before making an Archer joke.] image, I should expect to see different results even though my laptop is running ubuntu and my system locale is `en_AU.UTF-8`.\n\nHere's a dockerfile specifying an image that does exactly that:\n\n\n::: {.cell filename='./system-check/Dockerfile'}\n\n```{.dockerfile .cell-code}\nFROM ghcr.io/djnavarro/arch-r-base:release\nCOPY script.R /home/script.R\nCMD Rscript /home/script.R\n```\n:::\n\n\nIt's a sequence of three **docker instructions**. \n\n- Like all dockerfiles, it begins with a [`FROM`](https://docs.docker.com/engine/reference/builder/#from)^[Technically it's possible for an `ARG` instruction to precede a `FROM` instruction but I'm yet to actually see that in the wild.] ^[Much like SQL clauses, docker instructions are written in uppercase by convention. They don't actually *have* to be uppercase, but again, I've never seen a dockerfile written any other way. Along the same lines, your dockerfile doesn't actually have to be called \"Dockerfile\", but it's the default and everyone uses it.] instruction that specifies the name of a preexisting docker image to use as a starting point. I've been very explicit here and [referenced the image](https://windsock.io/referencing-docker-images/) using a fully qualified name that consists of a container repository (`ghcr.io`), a username (`djnavarro`), the image name `arch-r-base`, and an optional tag (`release`). You don't always need to be that precise, especially if you're using an image that you know exists locally. \n\n- The second step is a [`COPY`](https://docs.docker.com/engine/reference/builder/#copy) instruction that copies the R script to a specific file path within the image. This takes place at build time. This step is necessary because when the container starts up it will be isolated from other processes on the system. It doesn't have access to the host file system. If you want the container to have access to a file you need to copy it at build time.^[Alternatively, you can use the [`VOLUME`](https://docs.docker.com/engine/reference/builder/#volume) instruction to create a mount point and use that as a way to share a folder between the host and the container at run time, but that's more fiddly and there's really no need for that in this simple example. But if you want an easy-to-follow example using the `VOLUME` instruction in an R project, Colin Fay uses it in his [docker for R users](https://colinfay.me/docker-r-reproducibility/) post.]\n\n- The third step is a [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd) instruction. Every dockerfile must have a `CMD` instruction (and much like highlanders there can be only one) specifying a default for what the container should do when it is launched.^[The user can override the default by when calling `docker run` but I'm not going to cover that in this post]\n\nLater on, when you're starting to feel comfortable with the basic idea of writing dockerfiles, its worth reading the official guide on [dockerfile best practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/\n). Lots of little things started to make sense to me when I did that. For now, let's just acknowledged that yes Virginia we have a dockerfile. \n\n### Building the image\n\nOur next step is to build it to an image. The way we do that from the terminal is with the [`docker build`](https://docs.docker.com/engine/reference/commandline/build/) command. For the purposes of this post -- which I am writing in quarto and thus has a code execution engine blah blah blah -- I am going to assume^[Correctly.] that the working directory is set to the folder containing the post, and that it contains a subfolder called `system-check` in which the dockerfile and the R script are stored. In other words, `system-check` is the directory holding the docker project.\n\nThe simplest way to build an image from this project is like this:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build system-check\n```\n:::\n\n\nThis command tells docker to look for a dockerfile in the `system-check` folder, and make an image using whatever it finds there. That's a perfectly fine way to do it, but my personal preference is to give the resulting image a name, using the `--tag` flag. So the command, which I've broken over a few lines to highlight its structure, now looks like this:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag my-system-check \\\n  system-check\n```\n:::\n\n\nThe reason I've done this is that later on when I call the `docker run` command I can refer to the image by name, which does make life simpler. Under normal circumstances I'd probably have called the image `system-check` rather than `my-system-check` (why create new names when I don't need to?) but for the purposes of this post I think it's helpful to be clear that when I refer to the image name I'm referring to the thing I created using `--tag`, not the name of the folder that holds the dockerfile!\n\nOkay, enough talk. Let's run it this time:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag my-system-check \\\n  system-check\n```\n:::\n\n\n```\nSending build context to Docker daemon  3.072kB\nStep 1/3 : FROM ghcr.io/djnavarro/arch-r-base:release\nrelease: Pulling from djnavarro/arch-r-base\n597018910566: Pull complete \n8150bcc6bc64: Pull complete \ne49e8a34689c: Pull complete \nc14eff78251d: Pull complete \n42b358854199: Pull complete \nbabcc0d99cfd: Pull complete \nDigest: sha256:f9ff0f7b431ed1b975823c871949ccbc15c3e3d7dce23775f793f9f64bb2779e\nStatus: Downloaded newer image for ghcr.io/djnavarro/arch-r-base:release\n ---> 0a9929e54a6b\nStep 2/3 : COPY script.R /home/script.R\n ---> b9913096b118\nStep 3/3 : CMD Rscript /home/script.R\n ---> Running in 1314ee0ff2fb\nRemoving intermediate container 1314ee0ff2fb\n ---> 489003ffb5d0\nSuccessfully built 489003ffb5d0\nSuccessfully tagged my-system-check:latest\n```\n\nThe output here shows you that the build process unfolds as a sequence of three steps: one for each of our docker instructions. It also gives you the impression (correctly!) that the first step is considerably more complex than the other two. That makes sense: the `arch-r-base` image is itself constructed from a sequence of steps, and those steps have produced an image that is built from several \"layers\". Each of those hexadecimal hashes refers to one of the layers.^[To a first approximation you can imagine that every docker instruction produces a layer, and it is my understanding that this is how it used to be. But for efficiency reasons more recent versions of docker only produce persistent layers from `RUN`, `COPY`, and `ADD` instructions. Other instructions produce temporary intermediate images, but do not create persistent layers in the final image.]\n\nWhen you run this on your own system you'll see little progress bars as the different layers of the image are downloaded. For example, that line that says `597018910566: Pull complete`? That's referring to the very first layer in the `arch-r-base` image (which is arch linux itself) and that layer is about 280MB or something like that, so you get a little progress bar to let you know how its going. That's super helpful if you ever find yourself using the `arch-r-test` image, because one of the layers in that image includes a texlive installation (ugh) so that layer is (I'm so sorry) about 2GB in size. \n\nDownloading large images is a huge pain, and generally I would try to avoid creating an image with a layer that large. Thankfully, docker is smart enough to check the local cache before trying to download anything.^[Or, as Sterling would phrase it, \"I swear I had something for this.\"] We can see this in action if we repeat the exact same command:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag my-system-check \\\n  system-check\n```\n:::\n\n\n```\nSending build context to Docker daemon  3.072kB\nStep 1/3 : FROM ghcr.io/djnavarro/arch-r-base:release\n ---> 0a9929e54a6b\nStep 2/3 : COPY script.R /home/script.R\n ---> Using cache\n ---> b9913096b118\nStep 3/3 : CMD Rscript /home/script.R\n ---> Using cache\n ---> 489003ffb5d0\nSuccessfully built 489003ffb5d0\nSuccessfully tagged my-system-check:latest\n```\n\nThis finishes instantaneously because docker^[Now that I've started making Archer jokes, it's very hard not to turn \"docker\" into a euphemism. Hm. I should call him.] ^[Look all I'm saying is that \"Queering the dock: images as tops, containers as bottoms\" would make a terrible thesis and I would read the hell out of it.] notices that I already have a copy of this image so it uses the cache for everything. \n\nWe can confirm that this has worked by running `docker image list`:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker image list\n```\n:::\n\n\n```\nREPOSITORY                      TAG       IMAGE ID       CREATED          SIZE\nmy-system-check                 latest    489003ffb5d0   26 minutes ago   955MB\nghcr.io/djnavarro/arch-r-base   release   0a9929e54a6b   13 hours ago     955MB\nhello-world                     latest    feb5d9fea6a5   15 months ago    13.3kB\n```\n\nNow, you might be wondering about those image sizes. Did I really just create *two* 955MB images? That seems a bit much. It's certainly true that the image is 955MB in size: after all, the image does have to describe an entire operating system running R, so it's not surprising that it isn't tiny. But it looks as if I just wasted an entire GB of space by making two of them. Thankfully, docker is not that silly. The `my-system-check` image is almost identical to `arch-r-base`. In fact, it's just one very small layer added on top of the layers that comprise the `arch-r-base` image. If you dig into the documentation on [storage](https://docs.docker.com/storage/storagedriver/) you discover that docker quite sensibly allows images to share layers, so even though `arch-r-base` and `my-system-check` are individually 955MB in size, they are also *collectively* 955MB in size thanks to layer sharing. \n\nThe sheer excitement of working with computers is just too much for me to bear sometimes.\n\n### Run in a container\n\nOkay, we are ready to go baby! The image is set up, and all we have to do is run it in a container using [`docker run`](https://docs.docker.com/engine/reference/commandline/run/). The `docker run` command is quite powerful, and has a lot of arguments you can use to control how the image executes.^[In truth I didn't actually need to construct the `my-system-check` image at all: I could have just run `arch-r-base` in a container with a few arguments tweaked. But that would defeat the point of the exposition, obviously.] I'm not going to use any of that flexibility here. This is just a vanilla command asking docker to run the `my-system-check` image:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker run my-system-check\n```\n:::\n\n\n```\nRunning on:\n  Arch Linux\nWith locale:\n  LC_CTYPE=en_US.UTF-8\n  LC_NUMERIC=C\n  LC_TIME=en_US.UTF-8\n  LC_COLLATE=en_US.UTF-8\n  LC_MONETARY=en_US.UTF-8\n  LC_MESSAGES=en_US.UTF-8\n  LC_PAPER=en_US.UTF-8\n  LC_NAME=C\n  LC_ADDRESS=C\n  LC_TELEPHONE=C\n  LC_MEASUREMENT=en_US.UTF-8\n  LC_IDENTIFICATION=C\n````\n\nIt's an awfully elaborate way to say \"btw I use arch\", but yes... the image does what we hoped it would. It's executed the R script on arch linux with a `en_US.UTF-8` locale. I have successfully faked it^[Phrasing.] as an arch user.\n\n::: {.cell .column-screen-inset layout-align=\"center\" fig.dpi='200'}\n::: {.cell-output-display}\n![](index_files/figure-html/whale-row-2-1.png){fig-align='center' width=1536}\n:::\n:::\n\n## Fancier example\n\nFor the next example I'll add a little bit of extra complexity. The real reason I wanted the `arch-r` images in the first place was to make it easier to run unit tests for an R package on a system running arch linux. If I were going to do this properly I'd set it up in a way that could be incorporated into a CI workflow with github actions, but I'm not going to be that fancy for this blog post. Instead, I'll set it up so that I can generate containers running arch linux that can clone a package repository from github into the container, and then run the unit tests. I'll even give it a bit of flexibility so that the user can decide at build time^[Okay yeah I could do this at runtime too, but I want an excuse to talk about the `ARG` instruction.] which github repository the container points to.\n\nAs before the project -- which I've called `test-on-arch` -- consists of two files. There's an R script that executes at run time, and the dockerfile executed at build time. Here they are:\n\n\n::: {.cell filename='./test-on-arch/Dockerfile'}\n\n```{.dockerfile .cell-code}\nFROM ghcr.io/djnavarro/arch-r-test:release\n\n# copy the testing script\nCOPY clone-and-check.R /home/clone-and-check.R\n\n# pass args through environment variables\nARG user\nARG repo\nARG cran=https://cloud.r-project.org\nENV user=$user\nENV repo=$repo\nENV cran=$cran\n\n# run the testing script\nCMD Rscript /home/clone-and-check.R\n```\n:::\n\n::: {.cell filename='./test-on-arch/clone-and-check.R'}\n\n```{.r .cell-code}\n# get the system environment variables\nuser <- Sys.getenv(\"user\")\nrepo <- Sys.getenv(\"repo\")\ncran <- Sys.getenv(\"cran\")\n\n# define github url and a path for the local package install\nurl <- paste(\"https://github.com\", user, repo, sep = \"/\")\ndir <- paste(\"/home/project\", repo, sep=\"/\")\n\n# clone repo, install dependencies, and run checks\ngert::git_clone(url, dir, verbose = TRUE)\nremotes::install_deps(dir, dependencies = TRUE, repos = cran)\nrcmdcheck::rcmdcheck(dir)\n```\n:::\n\n\nLike last time, the place to start is with the R script. It expects to find `user`, `repo`, and `cran` values as environment variables. Once it finds those, it clones the `user/repo` repository from github, installs any dependencies of the pacakge from `cran`, and then uses rcmdcheck to check the downloaded package. \n\nNow let's look at how the dockerfile sets up the computing environment to enable this script to be run on arch linux: \n\n- Just like we saw in the last example, the dockerfile begins with a `FROM` instruction. This time around though I'm using the `arch-r-test` image rather than the `arch-r-base` image. Much like the base image, the test image runs arch linux and installs R in the environment. However, it also installs several other system dependencies and R packages that come in handy when running `R CMD check`, which makes it a bit more useful in this context. \n\n- The next step in the dockerfile is the `COPY` instruction that ensures that the image has a copy of the R script. There's nothing new here so we can move on. \n\n- The next two steps use the [`ARG`](https://docs.docker.com/engine/reference/builder/#arg) instruction. This is a new one for us: it's a mechanism for allowing the user to specify arguments that will be passed to docker when building the image. That's handy because it means I can customise the image that gets built. The obvious use here is that I can specify the `user` and the `repo` for the package that I want to check! (Later on we'll see how this is done using the `--build-arg` argument to `docker build`)\n\n- Next up is another `ARG` step, used to specify the url for the `cran` repository that the container should use to download any R packages. Notice, however, that this time I've specified a default value, so you don't actually have to specify `cran` when you call `docker build`: if you don't it will just use the default url\n\n- The `ARG` steps pass the user input to docker, but they don't set any environment variables (remember, our R script is expecting to find environment variables). That's the job of the [`ENV`](https://docs.docker.com/engine/reference/builder/#env) instructions that appear in the next three steps.^[Okay yes, clever person, I could have chosen to pass environment variables at run time using the `--env` argument to `docker run`. I didn't need to do this at build time using `ARG`. But that would defeat the point of the exposition wouldn't it? I wanted to use `ARG` and `ENV` in the main text, and quietly mention the `--env` argument to `docker run` in an aside. And I have now accomplished exactly that, haven't I?] \n\n- Finally, we have the `CMD` instruction, which specifies a default action for the container: run the script.\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![I need a different plot here](index_files/figure-html/whale-2-1.png){width=672}\n:::\n:::\n\n\n### Building the image\n\nSetting aside the fact that our `test-on-arch` project has a lot of flaws and limitations, it will serve the purposes we need it to. Let's say I want to create an image that will check the queue package hosted at [github.com/djnavarro/queue](https://github.com/djnavarro/queue/). To do that I'll need to set `user=djnavarro` and `repo=queue` when I build the image, which I can do with the `--build-arg` argument:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag test-queue \\\n  --build-arg user=djnavarro \\\n  --build-arg repo=queue \\\n  test-on-arch\n```\n:::\n\n\nNotice that I've chosen to call this image `test-queue`. A nice thing about being able to name the images independently from the dockerfile is that it's easy to create multiple images using the same dockerfile (just with different arguments) and give them meaningful names. And sure, this particular example is very silly because literally everything I'm doing here at the build stage could be done just as efficiently at the run stage. But whatever. \n\nLet's see what happens when I try to execute this build command. The `arch-r-test` image is considerably larger than `arch-r-base`. This one isn't a frugal image! It takes a while, so I'm going to go have a smoke while I wait^[I am, after all, \"on smoko\" (which in my case means I am unemployed and bored out of my mind) but incidentally if you want to see the most fabulous cover ever (Wet Leg covering The Chats), [here it is](https://www.youtube.com/watch?v=P_dza9y6cg0).] but the nice thing is that if you've done it once you don't have to do it again. Anyway...\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag test-queue \\\n  --build-arg user=djnavarro \\\n  --build-arg repo=queue \\\n  test-on-arch\n```\n:::\n\n\n```\nSending build context to Docker daemon  3.072kB\nStep 1/9 : FROM ghcr.io/djnavarro/arch-r-test:release\nrelease: Pulling from djnavarro/arch-r-test\n597018910566: Already exists \n8150bcc6bc64: Already exists \n198fc6066fb9: Pull complete \nb1600153860f: Pull complete \ned6330815f89: Pull complete \nfb2d11f79510: Pull complete \nff05f09f5a58: Pull complete \n9abaa14ad138: Pull complete \nDigest: sha256:f4605c32e18168589bd32248f5af97f8f1b57bd4de5fa6e1b54e53db13ab9514\nStatus: Downloaded newer image for ghcr.io/djnavarro/arch-r-test:release\n ---> 4f873f316861\nStep 2/9 : COPY clone-and-check.R /home/clone-and-check.R\n ---> d7c276834cf8\nStep 3/9 : ARG user\n ---> Running in efeeb43f874d\nRemoving intermediate container efeeb43f874d\n ---> d5d055328ea4\nStep 4/9 : ARG repo\n ---> Running in 75f6d1ff1502\nRemoving intermediate container 75f6d1ff1502\n ---> 7edce4d95863\nStep 5/9 : ARG cran=https://cloud.r-project.org\n ---> Running in 3f620871b0d7\nRemoving intermediate container 3f620871b0d7\n ---> 51a7ec6700ba\nStep 6/9 : ENV user=$user\n ---> Running in c7a7811e374e\nRemoving intermediate container c7a7811e374e\n ---> b8e01e708a08\nStep 7/9 : ENV repo=$repo\n ---> Running in 2f01c723898c\nRemoving intermediate container 2f01c723898c\n ---> 0939221c1a35\nStep 8/9 : ENV cran=$cran\n ---> Running in 37399a0bbe70\nRemoving intermediate container 37399a0bbe70\n ---> ccba9748fdd2\nStep 9/9 : CMD Rscript /home/clone-and-check.R\n ---> Running in 5d3eb7184e21\nRemoving intermediate container 5d3eb7184e21\n ---> 76926d5616d7\nSuccessfully built 76926d5616d7\nSuccessfully tagged test-queue:latest\n```\n\nNotice that during the first step when downloading `arch-r-test`, I didn't have to download the whole thing. Two of the layers in `arch-r-test` are shared with the `arch-r-base` image, and docker is smart enough to notice that I already have those layers in my cache. That's what the `Already exists` part of the output indicates. Admittedly it doesn't save us much in this case because its the texlive installation that causes pain, but it's a nice feature nevertheless. \n\nAs a little sanity check -- because, dear reader, I have been sitting here waiting very patiently while a large image downloaded over a slow connection and would like to confirm that I don't have to do that again -- let's repeat the exercise from earlier and try building it a second time just to reassure ourselves that the cache is doing its job:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag test-queue \\\n  --build-arg user=djnavarro \\\n  --build-arg repo=queue \\\n  test-on-arch \n```\n:::\n\n\n```\nSending build context to Docker daemon  3.072kB\nStep 1/9 : FROM ghcr.io/djnavarro/arch-r-test:release\n ---> 4f873f316861\nStep 2/9 : COPY clone-and-check.R /home/clone-and-check.R\n ---> Using cache\n ---> d7c276834cf8\nStep 3/9 : ARG user\n ---> Using cache\n ---> d5d055328ea4\nStep 4/9 : ARG repo\n ---> Using cache\n ---> 7edce4d95863\nStep 5/9 : ARG cran=https://cloud.r-project.org\n ---> Using cache\n ---> 51a7ec6700ba\nStep 6/9 : ENV user=$user\n ---> Using cache\n ---> b8e01e708a08\nStep 7/9 : ENV repo=$repo\n ---> Using cache\n ---> 0939221c1a35\nStep 8/9 : ENV cran=$cran\n ---> Using cache\n ---> ccba9748fdd2\nStep 9/9 : CMD Rscript /home/clone-and-check.R\n ---> Using cache\n ---> 76926d5616d7\nSuccessfully built 76926d5616d7\nSuccessfully tagged test-queue:latest\n```\n\nNot going to lie, I breathed a little sigh of relief. Docker used the cached layers, and that all happened instantaneously. Okay cool. I'm going to stop doing these checks from now on, but one last time let's take a peek at the list of images I have stored locally:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker image list\n```\n:::\n\n\n```\nREPOSITORY                      TAG       IMAGE ID       CREATED              SIZE\ntest-queue                      latest    76926d5616d7   About a minute ago   4.99GB\nmy-system-check                 latest    b7426ffb1484   12 minutes ago       955MB\nghcr.io/djnavarro/arch-r-test   release   4f873f316861   17 hours ago         4.99GB\nghcr.io/djnavarro/arch-r-base   release   0a9929e54a6b   17 hours ago         955MB\nhello-world                     latest    feb5d9fea6a5   15 months ago        13.3kB\n```\n\n### Run in a container\n\nOkay where were we? Ah yes, we've built our image so now it's time to run it. Does my little queue package build cleanly and pass its unit tests on arch? Let's find out...\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker run test-queue\n```\n:::\n\n\n```\nTransferred 766 of 766 objects...done!\nChecked out 34 of 34 commits... done!\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file ‘.../DESCRIPTION’ ... OK\n* preparing ‘queue’:\n* checking DESCRIPTION meta-information ... OK\n* installing the package to build vignettes\n* creating vignettes ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building ‘queue_0.0.2.tar.gz’\n\n── R CMD check ─────────────────────────────────────────────────────────────────\n* using log directory ‘/tmp/Rtmp1Nld2I/file131069108/queue.Rcheck’\n* using R version 4.2.2 (2022-10-31)\n* using platform: x86_64-pc-linux-gnu (64-bit)\n* using session charset: UTF-8\n* checking for file ‘queue/DESCRIPTION’ ... OK\n* this is package ‘queue’ version ‘0.0.2’\n* package encoding: UTF-8\n* checking package namespace information ... OK\n* checking package dependencies ... OK\n* checking if this is a source package ... OK\n* checking if there is a namespace ... OK\n* checking for executable files ... OK\n* checking for hidden files and directories ... OK\n* checking for portable file names ... OK\n* checking for sufficient/correct file permissions ... OK\n* checking whether package ‘queue’ can be installed ... OK\n* checking installed package size ... OK\n* checking package directory ... OK\n* checking ‘build’ directory ... OK\n* checking DESCRIPTION meta-information ... OK\n* checking top-level files ... OK\n* checking for left-over files ... OK\n* checking index information ... OK\n* checking package subdirectories ... OK\n* checking R files for non-ASCII characters ... OK\n* checking R files for syntax errors ... OK\n* checking whether the package can be loaded ... OK\n* checking whether the package can be loaded with stated dependencies ... OK\n* checking whether the package can be unloaded cleanly ... OK\n* checking whether the namespace can be loaded with stated dependencies ... OK\n* checking whether the namespace can be unloaded cleanly ... OK\n* checking loading without being on the library search path ... OK\n* checking dependencies in R code ... NOTE\nNamespaces in Imports field not imported from:\n  ‘callr’ ‘cli’ ‘R6’ ‘tibble’\n  All declared Imports should be used.\n* checking S3 generic/method consistency ... OK\n* checking replacement functions ... OK\n* checking foreign function calls ... OK\n* checking R code for possible problems ... OK\n* checking Rd files ... OK\n* checking Rd metadata ... OK\n* checking Rd cross-references ... OK\n* checking for missing documentation entries ... OK\n* checking for code/documentation mismatches ... OK\n* checking Rd \\usage sections ... OK\n* checking Rd contents ... OK\n* checking for unstated dependencies in examples ... OK\n* checking installed files from ‘inst/doc’ ... OK\n* checking files in ‘vignettes’ ... OK\n* checking examples ... OK\n* checking for unstated dependencies in ‘tests’ ... OK\n* checking tests ...\n  Running ‘testthat.R’\n OK\n* checking for unstated dependencies in vignettes ... OK\n* checking package vignettes in ‘inst/doc’ ... OK\n* checking running R code from vignettes ...\n  ‘queue.Rmd’ using ‘UTF-8’... OK\n NONE\n* checking re-building of vignette outputs ... OK\n* checking PDF version of manual ... OK\n* DONE\n\nStatus: 1 NOTE\nSee\n  ‘/tmp/Rtmp1Nld2I/file131069108/queue.Rcheck/00check.log’\nfor details.\nSystem has not been booted with systemd as init system (PID 1). Can't operate.\nFailed to connect to bus: Host is down\nWarning: Your system is mis-configured: ‘/var/db/timezone/localtime’ is not a symlink\nWarning: ‘/var/db/timezone/localtime’ is not identical to any known timezone file\nWarning message:\nIn system(\"timedatectl\", intern = TRUE) :\n  running command 'timedatectl' had status 1\n── R CMD check results ──────────────────────────────────────── queue 0.0.2 ────\nDuration: 38.5s\n\n❯ checking dependencies in R code ... NOTE\n  Namespaces in Imports field not imported from:\n    ‘callr’ ‘cli’ ‘R6’ ‘tibble’\n    All declared Imports should be used.\n\n0 errors ✔ | 0 warnings ✔ | 1 note ✖\n```\n\nOkay yes, this is the expected result. That note would of course get me in trouble on CRAN, but it's what I was expecting to see: I get the same note on ubuntu. I just haven't gotten around to fixing it yet. The only part that is different to what I see on ubuntu is this:\n\n```\nSystem has not been booted with systemd as init system (PID 1). Can't operate.\nFailed to connect to bus: Host is down\nWarning: Your system is mis-configured: ‘/var/db/timezone/localtime’ is not a symlink\nWarning: ‘/var/db/timezone/localtime’ is not identical to any known timezone file\nWarning message:\nIn system(\"timedatectl\", intern = TRUE) :\n  running command 'timedatectl' had status 1\n```\n\nYeah. This is interesting. I deliberately didn't try to faff about with [systemd](https://en.wikipedia.org/wiki/Systemd) in these images, so this is an expected warning. It's not a problem with queue or with arch, just a consequence of how I built the images. That would have some consequences for testing a lot of packages, but I'm not trying to recreate the rocker project here so I'm not too fussed about it in this little exercise.\n\n### Two images, one dockerfile\n\nThe advantage to passing arguments is that you can build many images from the same dockerfile, and docker will reuse the cached layers intelligently. We've seen this already, but here's another example. Let's try using the `test-on-arch` dockerfile to build an image that checks the [praise](https://github.com/rladies/praise) package. Up to this point I've never tried testing the praise package on arch before, but (of course????) this builds immediately and without downloading anything, because everything that actually matters about this build was already done when I built the `test-queue` image earlier:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag test-praise \\\n  --build-arg user=rladies \\\n  --build-arg repo=praise \\\n  test-on-arch \n```\n:::\n\n\n```\nSending build context to Docker daemon  3.072kB\nStep 1/9 : FROM ghcr.io/djnavarro/arch-r-test:release\n ---> 4f873f316861\nStep 2/9 : COPY clone-and-check.R /home/clone-and-check.R\n ---> Using cache\n ---> d7c276834cf8\nStep 3/9 : ARG user\n ---> Using cache\n ---> d5d055328ea4\nStep 4/9 : ARG repo\n ---> Using cache\n ---> 7edce4d95863\nStep 5/9 : ARG cran=https://cloud.r-project.org\n ---> Using cache\n ---> 51a7ec6700ba\nStep 6/9 : ENV user=$user\n ---> Running in 3a9b1843d5b4\nRemoving intermediate container 3a9b1843d5b4\n ---> aa2578d71155\nStep 7/9 : ENV repo=$repo\n ---> Running in 1d15632dd6ca\nRemoving intermediate container 1d15632dd6ca\n ---> 057a61970d7c\nStep 8/9 : ENV cran=$cran\n ---> Running in e5586a32b05a\nRemoving intermediate container e5586a32b05a\n ---> 48852232e4b7\nStep 9/9 : CMD Rscript /home/clone-and-check.R\n ---> Running in 0fb9a526210c\nRemoving intermediate container 0fb9a526210c\n ---> a02feea26152\nSuccessfully built a02feea26152\nSuccessfully tagged test-praise:latest\n```\n\nOnce again, we can take a look at the list of images:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker image list\n```\n:::\n\n\n```\nREPOSITORY                      TAG       IMAGE ID       CREATED          SIZE\ntest-praise                     latest    a02feea26152   20 seconds ago   4.99GB\ntest-queue                      latest    76926d5616d7   4 minutes ago    4.99GB\nmy-system-check                 latest    b7426ffb1484   14 minutes ago   955MB\nghcr.io/djnavarro/arch-r-test   release   4f873f316861   17 hours ago     4.99GB\nghcr.io/djnavarro/arch-r-base   release   0a9929e54a6b   17 hours ago     955MB\nhello-world                     latest    feb5d9fea6a5   15 months ago    13.3kB\n```\n\nAgain note the value of layer sharing. If these were all independent images we'd be looking at 17GB on disk. In fact, because `arch-r-test` reuses the layers from `arch-r-base` and all the other images are trivial additions to one of these two images, the *total* size of all these images is in fact \"only\" 5GB... i.e., the size of the `arch-r-test` image. And again, the only reason that one is so big is that I was really fussy about tex installations and bundled an entire texlive distribution with extra fonts and everything because I have no desire deal with tests whining about missing tex stuff.  \n\nAnyway, let's get back on track and run the `test-praise` image in a container:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker run test-praise\n```\n:::\n\n\n```\nTransferred 431 of 431 objects...done!\nChecked out 26 of 26 commits... done!\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file ‘.../DESCRIPTION’ ... OK\n* preparing ‘praise’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘praise_1.0.0.tar.gz’\n\n── R CMD check ─────────────────────────────────────────────────────────────────\n* using log directory ‘/tmp/Rtmpi7Ngun/file12ad64a83/praise.Rcheck’\n* using R version 4.2.2 (2022-10-31)\n* using platform: x86_64-pc-linux-gnu (64-bit)\n* using session charset: UTF-8\n* checking for file ‘praise/DESCRIPTION’ ... OK\n* this is package ‘praise’ version ‘1.0.0’\n* checking package namespace information ... OK\n* checking package dependencies ... OK\n* checking if this is a source package ... OK\n* checking if there is a namespace ... OK\n* checking for executable files ... OK\n* checking for hidden files and directories ... OK\n* checking for portable file names ... OK\n* checking for sufficient/correct file permissions ... OK\n* checking whether package ‘praise’ can be installed ... OK\n* checking installed package size ... OK\n* checking package directory ... OK\n* checking DESCRIPTION meta-information ... OK\n* checking top-level files ... OK\n* checking for left-over files ... OK\n* checking index information ... OK\n* checking package subdirectories ... OK\n* checking R files for non-ASCII characters ... OK\n* checking R files for syntax errors ... OK\n* checking whether the package can be loaded ... OK\n* checking whether the package can be loaded with stated dependencies ... OK\n* checking whether the package can be unloaded cleanly ... OK\n* checking whether the namespace can be loaded with stated dependencies ... OK\n* checking whether the namespace can be unloaded cleanly ... OK\n* checking dependencies in R code ... OK\n* checking S3 generic/method consistency ... OK\n* checking replacement functions ... OK\n* checking foreign function calls ... OK\n* checking R code for possible problems ... OK\n* checking Rd files ... OK\n* checking Rd metadata ... OK\n* checking Rd cross-references ... OK\n* checking for missing documentation entries ... OK\n* checking for code/documentation mismatches ... OK\n* checking Rd \\usage sections ... OK\n* checking Rd contents ... OK\n* checking for unstated dependencies in examples ... OK\n* checking examples ... OK\n* checking for unstated dependencies in ‘tests’ ... OK\n* checking tests ...\n  Running ‘testthat.R’\n OK\n* checking PDF version of manual ... OK\n* DONE\n\nStatus: OK\n\nSystem has not been booted with systemd as init system (PID 1). Can't operate.\nFailed to connect to bus: Host is down\nWarning: Your system is mis-configured: ‘/var/db/timezone/localtime’ is not a symlink\nWarning: ‘/var/db/timezone/localtime’ is not identical to any known timezone file\nWarning message:\nIn system(\"timedatectl\", intern = TRUE) :\n  running command 'timedatectl' had status 1\n── R CMD check results ─────────────────────────────────────── praise 1.0.0 ────\nDuration: 25.1s\n\n0 errors ✔ | 0 warnings ✔ | 0 notes ✔\n```\n\nOnce again we see the warning about systemd, and once again I am ignoring it. The thing that matters here, as far as I'm concerned, is that the unit tests for the praise package pass on arch. \n\n### A small caution\n\nBefore we move onto the third project I want to talk about one more example using this one, as a way of cautioning anyone who might feel inclined to use it without fixing its many deficiencies. Let's try using `test-on-arch` to run the unit tests for ggplot2, shall we? Unlike praise and queue, ggplot2 is a large and complicated package with substantial dependencies and a lot of unit tests. That's going to be a problem given that `test-on-arch` clones the entire repository from scratch every time it's called. Building the image is easy, because the build stage for `test-on-arch` doesn't do anything except copy the script and pass a few arguments...\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker build \\\n  --tag test-ggplot2 \\\n  --build-arg user=tidyverse \\\n  --build-arg repo=ggplot2 \\\n  test-on-arch \n```\n:::\n\n\nBut when we call `docker run` things become unpleasant for us even before we've had a chance to start running the unit tests, because the git clone operation is very time consuming...\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker run test-ggplot2 \n```\n:::\n\n```\nTransferred 15676 of 74694 objects...\n```\n\n<br>\n\n...uh, right. Look this is going to take a while, so maybe we should move on? \n\nThe main reason I wanted to point to this is to highlight that the clone step occurs at run time, and the entire clone operation is repeated every time we call it. That's not a smart way to do this. If you really wanted to design a docker workflow for testing packages on arch, you'd want to make some smarter design choices than this! The `test-on-arch` project I've used in this blog post is a toy, nothing more.^[I know the mystery will be too much for some people so I'd better resolve it: no, the ggplot2 tests didn't pass on the arch image. Some of the dependencies didn't install properly, and then eventually it threw an error trying to build the vignettes. If I had the energy I'd dig into it and figure out why... but I don't.]\n\n\n::: {.cell .column-screen-inset layout-align=\"center\" fig.dpi='200'}\n::: {.cell-output-display}\n![](index_files/figure-html/whale-row-3-1.png){fig-align='center' width=1536}\n:::\n:::\n\n\n\n## Hosting images\n\nFor the third example, let's look at the [`ghcr.io/djnavarro/arch-r-base:release`](https://github.com/djnavarro/arch-r/tree/base) image. In addition to the dockerfile there are two small text files used to specify locale information. The two locale files aren't very interesting and could easily have been included as strings in the dockerfile, but I found it neater to keep them separate. The `locale-gen` file specifies locales that the image understands, and `locale.conf` specifies configuration details. (Both are configuration files on linux). In any case, here's the whole thing:\n\nlabels explained \nhttps://github.com/opencontainers/image-spec/blob/main/annotations.md\n\nhttps://snyk.io/blog/how-and-when-to-use-docker-labels-oci-container-annotations/\n\n\n\n\n::: {.cell filename='base/Dockerfile'}\n\n```{.dockerfile .cell-code}\nFROM archlinux:base-devel\n\nLABEL org.opencontainers.image.source \"https://github.com/djnavarro/arch-r/base\" \nLABEL org.opencontainers.image.authors \"Danielle Navarro <djnavarro@protonmail.com>\" \nLABEL org.opencontainers.image.description DESCRIPTION\nLABEL org.opencontainers.image.licenses \"GPL-3.0\"\n\n# set the locale\nCOPY base/locale.gen /etc/locale.gen\nCOPY base/locale.conf /etc/locale.conf\nRUN locale-gen\nENV LANG=en_US.UTF-8\nENV LC_ALL=en_US.UTF-8\n\n# install R and set default command\nRUN pacman -Syu --noconfirm r\nCMD R --no-save\n```\n:::\n\n::: {.cell filename='base/locale.gen'}\n\n```{.bash .cell-code}\nC.UTF8 UTF-8\nen_US.UTF-8 UTF-8\n```\n:::\n\n::: {.cell filename='base/locale.conf'}\n\n```{.bash .cell-code}\nLANG=en_US.UTF-8\nLC_ALL=en_US.UTF-8\n```\n:::\n\n\nTruly exciting. \n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Again, I need something more interesting than this](index_files/figure-html/whale-3-1.png){width=672}\n:::\n:::\n\n\nI'm not in any way an expert on github actions, but I do know a little bit. Just enough to be dangerous, I expect. Here's the [workflow](https://github.com/djnavarro/arch-r/blob/main/.github/workflows/publish-docker-image.yaml) I'm using:\n\n\n::: {.cell filename='.github/workflows/build-image.yaml'}\n\n```{.yaml .cell-code}\nname: publish arch-r images\n\non:\n  push:\n    branches: ['release']\n    \nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build-and-push-image:\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - dockerfile: ./base/Dockerfile\n            image: ghcr.io/djnavarro/arch-r-base\n          - dockerfile: ./test/Dockerfile\n            image: ghcr.io/djnavarro/arch-r-test\n            \n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - name: checkout repository\n        uses: actions/checkout@v2\n\n      - name: login to the container registry\n        uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: extract metadata (tags, labels) for docker\n        id: meta\n        uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38\n        with:\n          images: ${{ matrix.image }}\n\n      - name: build and push docker image\n        uses: docker/build-push-action@ad44023a93711e3deb337508980b4b5e9bcdc5dc\n        with:\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n```\n:::\n\n\nFor this workflow to run, I needed to edit the permissions associated with my github PAT to include some additional scopes. If, like me, you've created your PAT using the default scopes provided by `usethis::create_github_token()`, you'll need a few more to run workflows that build and modify docker images:\n\n- `read:packages` scope to download container images and read metadata.\n- `write:packages` scope to download and upload container images and read and write metadata.\n- `delete:packages` scope to delete container images.\n\nThis workflow triggers an automatic deployment to the github container registry whenever there is a new push to the base or test branches. This is what creates the `ghcr.io/djnavarro/arch-r-base:release` and `ghcr.io/djnavarro/arch-r-test:release` images. It's not as  sophisticated workflows used by the rocker project -- you can browse [github.com/rocker-org/rocker](https://github.com/rocker-org/rocker) if you want to see a nicer set up -- but it does work, and that was my main goal for this post.\n\n\n\n::: {.cell .column-screen-inset layout-align=\"center\" fig.dpi='200'}\n::: {.cell-output-display}\n![](index_files/figure-html/whale-row-4-1.png){fig-align='center' width=1536}\n:::\n:::\n\n\n## Resources\n\n- The docker reference documentation: [docs.docker.com/reference](https://docs.docker.com/reference/)\n\n- Dockerfile best practices [docs.docker.com/develop/develop-images/dockerfile_best-practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)\n\n- Instructions on giving docker sudo privileges for linux users: [docs.docker.com/engine/install/linux-postinstall](https://docs.docker.com/engine/install/linux-postinstall/)\n\n- The rocker project by Carl Boettiger, Dirk Eddelbuettel, Noam Ross, and Shima Tatsuya: [rocker-project.org](https://rocker-project.org/)\n\n- Source code for the rocker repositories: [github.com/rocker-org/rocker](https://github.com/rocker-org/rocker)\n\n- Blog post on docker by Colin Fay: [colinfay.me/docker-r-reproducibility](https://colinfay.me/docker-r-reproducibility/)\n\n- Slides on docker by Noam Ross: [github.com/noamross/nyhackr-docker-talk](https://github.com/noamross/nyhackr-docker-talk)\n\n- Docker for beginners by Prakhar Srivastav: [docker-curriculum.com](https://docker-curriculum.com/)\n\n- Referencing docker images by Nigel Brown [windsock.io/referencing-docker-images](https://windsock.io/referencing-docker-images/)\n\n- Working with the github container registry:\n[docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry)\n\n\n## Postscript: Making \"dockerplots\" in ggplot2\n\nI had a lot of fun making the whales. They're cute, and they make me happy. The function that generates these is called `sample_whales()`, and you can find the source code by expanding the folded code block below. Enjoy!\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Source code for `sample_whales()`\"}\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(dplyr)\n\nsample_whales <- function(seed = NULL, nrow = 4, ncol = 6) {\n\n  if(is.null(seed)) seed <- sample(1000, 1)\n  set.seed(seed)\n\n  nwhales <- nrow * ncol\n\n  # define a circle\n  circle <- tibble(\n    th = seq(0, 2*pi, length.out = 1000),\n    x = cos(th),\n    y = sin(th)\n  )\n\n  # distort a circle to create the whale body\n  whale_body <- circle |>\n    mutate(\n      y = if_else(y > 0, 0, y),\n      y = if_else(x < 0, -abs(y) ^ .6, -abs(y) ^ 1.7)\n    )\n\n  # distort a circle to create the whale tail\n  whale_tail <- circle |>\n    mutate(\n      weight = (abs(th - pi)/pi) ^ 1.3,\n      angle = pi * 1.2,\n      x = x * weight + .35 * (1 - weight),\n      x_scaled = x * .6,\n      y_scaled = y * .4,\n      x = x_scaled * cos(angle) - y_scaled * sin(angle),\n      y = x_scaled * sin(angle) + y_scaled * cos(angle),\n      x = x + 1.35,\n      y = y + 0.25\n    )\n\n  # bind the body to the tail to make a whale\n  whale <- bind_rows(whale_body, whale_tail)\n\n  # fully stacked set of boxes\n  box_stack <- expand_grid(\n    x = seq(-.7, .5, .3),\n    y = seq(.25, 1.5, .3)\n  )\n\n  # sample names using babynames package\n  names <- unique(sample(\n    x = babynames::babynames$name,\n    size = ceiling(nwhales * 1.2)\n  ))\n\n  # sample colours using a blue palette from ggthemes\n  shades <- sample(\n    x = ggthemes::canva_palettes$`Cool blues`,\n    size = nrow * ncol,\n    replace = TRUE\n  )\n\n  boxes <- list()\n  whales <- list()\n  for(i in 1:(nrow * ncol)) {\n\n    # assign the whales a name and a look\n    whales[[i]] <- whale |>\n      mutate(\n        name = names[[i]],\n        look = shades[[i]]\n      )\n\n    # assign the whales a name and colour,\n    # and randomly remove boxes off the stack\n    boxes[[i]] <- box_stack |>\n      mutate(\n        name = names[[i]],\n        look = shades[[i]]\n      ) |>\n      group_by(x) |>\n      mutate(max_height = runif(1, min = .05, max = 1.8)) |>\n      filter(y < max_height)\n  }\n\n  # collapse lists to data frames\n  boxes <- bind_rows(boxes)\n  whales <- bind_rows(whales)\n\n  # last minute tinkering... :-)\n  boxes <- boxes |> mutate(y = y - .3, x = x + .01)\n  whales <- whales |> mutate(y = y - .31)\n\n  # draw the plot\n  ggplot(mapping = aes(x, y, fill = look, colour = look)) +\n    geom_polygon(data = whales, linewidth = 2) +\n    geom_tile(\n      data = boxes,\n      width = .18,\n      height = .18,\n      linewidth = 2,\n      linejoin = \"bevel\"\n    ) +\n    facet_wrap(vars(name), nrow = nrow, ncol = ncol) +\n    coord_equal(xlim = c(-1.5, 1.5), ylim = c(-1.5, 1.5)) +\n    scale_x_continuous(labels = NULL, name = NULL) +\n    scale_y_continuous(labels = NULL, name = NULL) +\n    scale_fill_identity() +\n    scale_color_identity() +\n    theme_minimal(base_size = 14) +\n    theme(\n      axis.ticks = element_blank(),\n      panel.border = element_rect(fill = NA, colour = \"grey90\")\n    )\n}\n```\n:::\n\n::: {.cell .column-screen-inset layout-align=\"center\" fig.dpi='200'}\n::: {.cell-output-display}\n![](index_files/figure-html/whale-grid-1.png){fig-align='center' width=1536}\n:::\n:::\n\n\n\n<!--------------- appendices go here ----------------->\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}